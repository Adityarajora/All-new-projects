{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwPL0hIlGKoA"
   },
   "source": [
    "# <font color='red'>**Sequence to sequence implementation**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyfZo8fmLOec"
   },
   "source": [
    "##   Simple Encoder and Decoder\n",
    "Implement simple Encoder-Decoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvNSZXNkkOkO"
   },
   "source": [
    "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
    "\n",
    "2. You will find **ita.txt** file in that ZIP, \n",
    "you can read that data using python and preprocess that data this way only: \n",
    "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
    " \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3k_AlAuKJqVA"
   },
   "source": [
    "<font color='blue'>**Load the data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "id": "fU80Ao-AGaob"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353281, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corri!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corra!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Correte!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english   italian\n",
       "0     Hi.     Ciao!\n",
       "1     Hi.     Ciao.\n",
       "2    Run!    Corri!\n",
       "3    Run!    Corra!\n",
       "4    Run!  Correte!"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ita-eng/ita.txt', 'r', encoding=\"utf8\") as f:\n",
    "    eng=[]\n",
    "    ita=[]\n",
    "    for i in f.readlines():\n",
    "        eng.append(i.split(\"\\t\")[0])\n",
    "        ita.append(i.split(\"\\t\")[1])\n",
    "data = pd.DataFrame(data=list(zip(eng, ita)), columns=['english','italian'])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmGWTdRmKRph"
   },
   "source": [
    "<font color='blue'>**Preprocess data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9QqElB_nKZos"
   },
   "outputs": [],
   "source": [
    "def decontractions(phrase):\n",
    "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
    "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def preprocess(text):\n",
    "    # convert all the text into lower letters\n",
    "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
    "    # remove all the spacial characters: except space ' '\n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_ita(text):\n",
    "    # convert all the text into lower letters\n",
    "    # remove the words betweent brakets ()\n",
    "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
    "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
    "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
    "    # you are free to do more proprocessing\n",
    "    # note that the model will learn better with better preprocessed data \n",
    "    \n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
    "    text = re.sub('\\u200b', ' ', text)\n",
    "    text = re.sub('\\xa0', ' ', text)\n",
    "    text = re.sub('-', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "data['english'] = data['english'].apply(preprocess)\n",
    "data['italian'] = data['italian'].apply(preprocess_ita)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_lengths = data['italian'].str.split().apply(len)\n",
    "eng_lengths = data['english'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0\n",
      "10 3.0\n",
      "20 4.0\n",
      "30 4.0\n",
      "40 5.0\n",
      "50 5.0\n",
      "60 6.0\n",
      "70 6.0\n",
      "80 7.0\n",
      "90 8.0\n",
      "100 92.0\n",
      "90 8.0\n",
      "91 8.0\n",
      "92 8.0\n",
      "93 9.0\n",
      "94 9.0\n",
      "95 9.0\n",
      "96 9.0\n",
      "97 10.0\n",
      "98 11.0\n",
      "99 12.0\n",
      "100 92.0\n",
      "99.1 12.0\n",
      "99.2 12.0\n",
      "99.3 13.0\n",
      "99.4 13.0\n",
      "99.5 13.0\n",
      "99.6 14.0\n",
      "99.7 15.0\n",
      "99.8 16.0\n",
      "99.9 22.0\n",
      "100 92.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,101,10):\n",
    "    print(i,np.percentile(ita_lengths, i))\n",
    "for i in range(90,101):\n",
    "    print(i,np.percentile(ita_lengths, i))\n",
    "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
    "    print(i,np.percentile(ita_lengths, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max number of words taking 22 as its at 99.9th percentile(Italian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0\n",
      "10 4.0\n",
      "20 4.0\n",
      "30 5.0\n",
      "40 5.0\n",
      "50 6.0\n",
      "60 6.0\n",
      "70 7.0\n",
      "80 7.0\n",
      "90 8.0\n",
      "100 101.0\n",
      "90 8.0\n",
      "91 9.0\n",
      "92 9.0\n",
      "93 9.0\n",
      "94 9.0\n",
      "95 9.0\n",
      "96 10.0\n",
      "97 10.0\n",
      "98 11.0\n",
      "99 12.0\n",
      "100 101.0\n",
      "99.1 12.0\n",
      "99.2 13.0\n",
      "99.3 13.0\n",
      "99.4 13.0\n",
      "99.5 14.0\n",
      "99.6 14.0\n",
      "99.7 15.0\n",
      "99.8 16.0\n",
      "99.9 25.0\n",
      "100 101.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,101,10):\n",
    "    print(i,np.percentile(eng_lengths, i))\n",
    "for i in range(90,101):\n",
    "    print(i,np.percentile(eng_lengths, i))\n",
    "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
    "    print(i,np.percentile(eng_lengths, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max number of words taking 25 as its at 99.9th percentile(English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ciao</td>\n",
       "      <td>&lt;start&gt; hi</td>\n",
       "      <td>hi &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ciao</td>\n",
       "      <td>&lt;start&gt; hi</td>\n",
       "      <td>hi &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corri</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corra</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>correte</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   italian  english_inp english_out\n",
       "0     ciao   <start> hi    hi <end>\n",
       "1     ciao   <start> hi    hi <end>\n",
       "2    corri  <start> run   run <end>\n",
       "3    corra  <start> run   run <end>\n",
       "4  correte  <start> run   run <end>"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['italian_len'] = data['italian'].str.split().apply(len)\n",
    "data = data[data['italian_len'] < 22]\n",
    "\n",
    "data['english_len'] = data['english'].str.split().apply(len)\n",
    "data = data[data['english_len'] < 25]\n",
    "\n",
    "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
    "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
    "\n",
    "data = data.drop(['english','italian_len','english_len'], axis=1)\n",
    "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352878, 3)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
    "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38846</th>\n",
       "      <td>questa è la sua penna</td>\n",
       "      <td>&lt;start&gt; is this your pen &lt;end&gt;</td>\n",
       "      <td>is this your pen &lt;end&gt; &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>state fermi</td>\n",
       "      <td>&lt;start&gt; stay put</td>\n",
       "      <td>stay put &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     italian                     english_inp  \\\n",
       "38846  questa è la sua penna  <start> is this your pen <end>   \n",
       "1038             state fermi                <start> stay put   \n",
       "\n",
       "                        english_out  \n",
       "38846  is this your pen <end> <end>  \n",
       "1038                 stay put <end>  "
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11683</th>\n",
       "      <td>loro sono alte</td>\n",
       "      <td>&lt;start&gt; are they tall</td>\n",
       "      <td>are they tall &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11815</th>\n",
       "      <td>gli uccelli possono volare</td>\n",
       "      <td>&lt;start&gt; birds can fly</td>\n",
       "      <td>birds can fly &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          italian            english_inp          english_out\n",
       "11683              loro sono alte  <start> are they tall  are they tall <end>\n",
       "11815  gli uccelli possono volare  <start> birds can fly  birds can fly <end>"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape:(40000, 3)\n",
      "validation.shape:(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train.shape:{train.shape}\")\n",
    "print(f\"validation.shape:{validation.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# joblib.dump(train, \"train\")\n",
    "# joblib.dump(validation, \"validation\")\n",
    "train = joblib.load(\"train\")\n",
    "validation = joblib.load(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknizer_ita = Tokenizer()\n",
    "tknizer_ita.fit_on_texts(train['italian'].values)\n",
    "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tknizer_eng.fit_on_texts(train['english_inp'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13079\n",
      "26681\n"
     ]
    }
   ],
   "source": [
    "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
    "print(vocab_size_eng)\n",
    "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
    "print(vocab_size_ita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10289)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove vectors for eng data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 13079/13079 [00:00<00:00, 345316.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 12834 words (245 misses)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "hits, misses = 0, 0\n",
    "embedding_matrix = np.zeros((vocab_size_eng+1, 100))\n",
    "for word, i in tqdm(tknizer_eng.word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        \n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len_eng, max_len_ita):\n",
    "        self.encoder_inps = data['italian'].values\n",
    "        self.decoder_inps = data['english_inp'].values\n",
    "        self.decoder_outs = data['english_out'].values\n",
    "        self.tknizer_eng = tknizer_eng\n",
    "        self.tknizer_ita = tknizer_ita\n",
    "        self.max_len_eng = max_len_eng\n",
    "        self.max_len_ita = max_len_ita\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len_ita, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len_eng, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len_eng, dtype='int32', padding='post')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 22) (128, 25) (128, 25)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 25, 22)\n",
    "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 25, 22)\n",
    "\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=128)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=128)\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## <font color='blue'>**Implement custom encoder decoder**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A45uc0JILMlV"
   },
   "source": [
    "<font color='blue'>**Encoder**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder model inherited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "9cex2XfCLOew"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        super().__init__(name=\"encode_model\")\n",
    "        self.inp_vocab_size = inp_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        self.embedding = Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size,input_length=self.input_length,\\\n",
    "                  mask_zero=True, name=\"embedding_layer_encoder\")\n",
    "        self.LSTM = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "\n",
    "\n",
    "    def call(self,input_sequence,training=True):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- encoder_output, last time step's hidden and cell state\n",
    "        '''\n",
    "        input_embeddings = self.embedding(input_sequence)\n",
    "        self.lstm_output, self.lstm_state_h, self.lstm_state_c = self.LSTM(input_embeddings)\n",
    "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "        '''\n",
    "        Given a batch size it will return intial hidden state and intial cell state.\n",
    "        If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "        '''\n",
    "        lstm_state_h = tf.zeros([batch_size, self.lstm_size])\n",
    "        lstm_state_c = tf.zeros([batch_size, self.lstm_size])\n",
    "      \n",
    "        return lstm_state_h, lstm_state_c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder model inherited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "x1ES1-sJLOe4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Decoder LSTM layer\n",
    "        super().__init__(name=\"decode_model\")\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_size,input_length=self.input_length,\\\n",
    "                  mask_zero=True, weights=[embedding_matrix], trainable=False, name=\"embedding_layer_decoder\")\n",
    "        self.LSTM = LSTM(self.lstm_size, return_sequences=True, return_state=True, name=\"Dncoder_LSTM\")\n",
    "        \n",
    "\n",
    "    def call(self,input_sequence,initial_states):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
    "        \n",
    "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
    "        '''\n",
    "        state_h, state_c = initial_states[0], initial_states[1]\n",
    "        input_embeddings = self.embedding(input_sequence)\n",
    "        lstm_output, _, _  = self.LSTM(input_embeddings, initial_state=[state_h, state_c])\n",
    "        return lstm_output, _, _\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode_decoder model containing two inherited models Encode and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "BXrIj4scLOe_"
   },
   "outputs": [],
   "source": [
    "class Encoder_decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,lstm_size,en_input_length,de_input_length):\n",
    "        super().__init__(name=\"Encoder_Decoder_model\")\n",
    "        #Create encoder object\n",
    "        #Create decoder object\n",
    "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
    "        \n",
    "        \n",
    "        self.encoder = Encoder(vocab_size_ita+1,embedding_size=50,lstm_size=lstm_size,input_length=en_input_length)\n",
    "        self.decoder = Decoder(vocab_size_eng+1,embedding_size=100,lstm_size=lstm_size,input_length=de_input_length)\n",
    "        self.dense   = Dense(vocab_size_eng+1, activation='softmax')\n",
    "    def call(self, data):\n",
    "        '''\n",
    "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
    "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
    "        C. Pass the decoder_outputs into Dense layer \n",
    "        \n",
    "        Return decoder_outputs\n",
    "        '''\n",
    "        \n",
    "        input_italian, input_english = data[0], data[1]\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input_italian)\n",
    "        decoder_output , _, _                      = self.decoder(input_english, [encoder_h, encoder_c])\n",
    "        output                               = self.dense(decoder_output)\n",
    "        return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, TensorBoard, LearningRateScheduler\n",
    "from sklearn.metrics import recall_score, f1_score, roc_curve, auc\n",
    "import datetime\n",
    "\n",
    "filepath=\"model_save_non_attention/weights-{epoch:02d}-{val_loss:.2f}\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', save_format=\"tf\", save_freq=\"epoch\",  verbose=1, save_best_only=True, mode='auto')\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "kcL61dJXLOfB",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.2861\n",
      "Epoch 1: val_loss improved from inf to 0.20945, saving model to model_save_non_attention\\weights-01-0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-01-0.21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-01-0.21\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 125s 41ms/step - loss: 0.2861 - val_loss: 0.2095\n",
      "Epoch 2/20\n",
      "2939/2940 [============================>.] - ETA: 0s - loss: 0.1727\n",
      "Epoch 2: val_loss improved from 0.20945 to 0.14498, saving model to model_save_non_attention\\weights-02-0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-02-0.14\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-02-0.14\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 119s 41ms/step - loss: 0.1727 - val_loss: 0.1450\n",
      "Epoch 3/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.1209\n",
      "Epoch 3: val_loss improved from 0.14498 to 0.10975, saving model to model_save_non_attention\\weights-03-0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-03-0.11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-03-0.11\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 121s 41ms/step - loss: 0.1209 - val_loss: 0.1098\n",
      "Epoch 4/20\n",
      "2939/2940 [============================>.] - ETA: 0s - loss: 0.0899\n",
      "Epoch 4: val_loss improved from 0.10975 to 0.08968, saving model to model_save_non_attention\\weights-04-0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-04-0.09\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-04-0.09\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 120s 41ms/step - loss: 0.0899 - val_loss: 0.0897\n",
      "Epoch 5/20\n",
      "2939/2940 [============================>.] - ETA: 0s - loss: 0.0706\n",
      "Epoch 5: val_loss improved from 0.08968 to 0.07709, saving model to model_save_non_attention\\weights-05-0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-05-0.08\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-05-0.08\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 121s 41ms/step - loss: 0.0706 - val_loss: 0.0771\n",
      "Epoch 6/20\n",
      "2938/2940 [============================>.] - ETA: 0s - loss: 0.0577\n",
      "Epoch 6: val_loss improved from 0.07709 to 0.06918, saving model to model_save_non_attention\\weights-06-0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-06-0.07\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-06-0.07\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 119s 41ms/step - loss: 0.0577 - val_loss: 0.0692\n",
      "Epoch 7/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.0486\n",
      "Epoch 7: val_loss improved from 0.06918 to 0.06375, saving model to model_save_non_attention\\weights-07-0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-07-0.06\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-07-0.06\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 119s 40ms/step - loss: 0.0486 - val_loss: 0.0638\n",
      "Epoch 8/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.0418\n",
      "Epoch 8: val_loss improved from 0.06375 to 0.05959, saving model to model_save_non_attention\\weights-08-0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-08-0.06\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-08-0.06\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 121s 41ms/step - loss: 0.0418 - val_loss: 0.0596\n",
      "Epoch 9/20\n",
      "2939/2940 [============================>.] - ETA: 0s - loss: 0.0366\n",
      "Epoch 9: val_loss improved from 0.05959 to 0.05657, saving model to model_save_non_attention\\weights-09-0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-09-0.06\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-09-0.06\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 118s 40ms/step - loss: 0.0366 - val_loss: 0.0566\n",
      "Epoch 10/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.0324\n",
      "Epoch 10: val_loss improved from 0.05657 to 0.05498, saving model to model_save_non_attention\\weights-10-0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-10-0.05\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-10-0.05\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 121s 41ms/step - loss: 0.0324 - val_loss: 0.0550\n",
      "Epoch 11/20\n",
      "2939/2940 [============================>.] - ETA: 0s - loss: 0.0290\n",
      "Epoch 11: val_loss improved from 0.05498 to 0.05329, saving model to model_save_non_attention\\weights-11-0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-11-0.05\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-11-0.05\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 120s 41ms/step - loss: 0.0290 - val_loss: 0.0533\n",
      "Epoch 12/20\n",
      "2939/2940 [============================>.] - ETA: 0s - loss: 0.0262\n",
      "Epoch 12: val_loss improved from 0.05329 to 0.05264, saving model to model_save_non_attention\\weights-12-0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-12-0.05\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-12-0.05\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 118s 40ms/step - loss: 0.0262 - val_loss: 0.0526\n",
      "Epoch 13/20\n",
      "2939/2940 [============================>.] - ETA: 0s - loss: 0.0239\n",
      "Epoch 13: val_loss improved from 0.05264 to 0.05154, saving model to model_save_non_attention\\weights-13-0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-13-0.05\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-13-0.05\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 121s 41ms/step - loss: 0.0239 - val_loss: 0.0515\n",
      "Epoch 14/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.0218\n",
      "Epoch 14: val_loss improved from 0.05154 to 0.05129, saving model to model_save_non_attention\\weights-14-0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-14-0.05\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-14-0.05\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 118s 40ms/step - loss: 0.0218 - val_loss: 0.0513\n",
      "Epoch 15/20\n",
      "2939/2940 [============================>.] - ETA: 0s - loss: 0.0201\n",
      "Epoch 15: val_loss improved from 0.05129 to 0.05061, saving model to model_save_non_attention\\weights-15-0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-15-0.05\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_non_attention\\weights-15-0.05\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 121s 41ms/step - loss: 0.0201 - val_loss: 0.0506\n",
      "Epoch 16/20\n",
      "2939/2940 [============================>.] - ETA: 0s - loss: 0.0186\n",
      "Epoch 16: val_loss did not improve from 0.05061\n",
      "2940/2940 [==============================] - 106s 36ms/step - loss: 0.0186 - val_loss: 0.0510\n",
      "Epoch 17/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 17: val_loss did not improve from 0.05061\n",
      "2940/2940 [==============================] - 105s 36ms/step - loss: 0.0172 - val_loss: 0.0508\n",
      "Epoch 18/20\n",
      "2939/2940 [============================>.] - ETA: 0s - loss: 0.0160\n",
      "Epoch 18: val_loss did not improve from 0.05061\n",
      "2940/2940 [==============================] - 105s 36ms/step - loss: 0.0160 - val_loss: 0.0511\n",
      "Epoch 19/20\n",
      "2938/2940 [============================>.] - ETA: 0s - loss: 0.0150\n",
      "Epoch 19: val_loss did not improve from 0.05061\n",
      "2940/2940 [==============================] - 105s 36ms/step - loss: 0.0150 - val_loss: 0.0511\n",
      "Epoch 20/20\n",
      "2939/2940 [============================>.] - ETA: 0s - loss: 0.0141\n",
      "Epoch 20: val_loss did not improve from 0.05061\n",
      "2940/2940 [==============================] - 105s 36ms/step - loss: 0.0141 - val_loss: 0.0512\n",
      "Model: \"Encoder_Decoder_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encode_model (Encoder)      multiple                  1648468   \n",
      "                                                                 \n",
      " decode_model (Decoder)      multiple                  1673568   \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  3361560   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,683,596\n",
      "Trainable params: 5,375,596\n",
      "Non-trainable params: 1,308,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create an object of encoder_decoder Model class, \n",
    "# Compile the model and fit the model\n",
    "\n",
    "model = Encoder_decoder(256,22,25)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,loss=loss_function)\n",
    "train_steps=train.shape[0]//96\n",
    "valid_steps=validation.shape[0]//96\n",
    "history = model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=20, validation_data=test_dataloader, validation_steps=valid_steps,\n",
    "                   callbacks=[checkpoint])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST loss: 0.0512 in 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1de74410b20>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "# acc = history.history['acc']\n",
    "val_loss = history.history['val_loss'] \n",
    "epoch = 20\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/val_loss')\n",
    "plt.title('Learning')\n",
    "plt.plot(range(epoch), loss, label = \"loss\")\n",
    "plt.plot(range(epoch), val_loss, label = \"val_loss\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18663520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001DC18032AC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# model.save('model',save_format='tf')\n",
    "# loaded_model = tf.keras.models.load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "italian_dict = {v:k for k,v in tknizer_ita.word_index.items()}\n",
    "english_dict = {v:k for k,v in tknizer_eng.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['english_dict']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(italian_dict, \"italian_dict\")\n",
    "# joblib.dump(english_dict, \"english_dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load(\"english_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "SkARSlZgLOfE"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "    '''\n",
    "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
    "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
    "         pass the predicted_out to the dense layer\n",
    "         update the states=[state_h,state_c]\n",
    "         And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
    "         Update the input_to_decoder with current predictions\n",
    "    F. Return the predicted sentence\n",
    "    '''\n",
    "    ENCODER_SEQ_LEN = 22\n",
    "    DECODER_SEQ_LEN = 25\n",
    "    loaded_model = model\n",
    "#     print(\"=\" * 30, \"Inference\", \"=\" * 30)\n",
    "    \n",
    "    nums = tknizer_ita.texts_to_sequences([input_sentence])\n",
    "    nums_padded = pad_sequences(nums, maxlen=max_len_ita, dtype='int32', padding='post')\n",
    " \n",
    "    encoder_output, enc_state_h, enc_state_c = loaded_model.layers[0](nums_padded)\n",
    "    pred, alphas = [], []\n",
    "     \n",
    "    states_values = [enc_state_h, enc_state_c]\n",
    "    pred = []\n",
    "    cur_vec = np.zeros((1, 1))\n",
    "#     print('-'*20,\"started predition\",\"-\"*20) \n",
    "    for i in range(DECODER_SEQ_LEN):\n",
    "        cur_emb = loaded_model.layers[1].embedding(cur_vec)\n",
    "        infe_output, state_h, state_c = loaded_model.layers[1].LSTM(cur_emb, initial_state=states_values)\n",
    "        infe_output=loaded_model.layers[2](infe_output)\n",
    "        states_values = [state_h, state_c]\n",
    "        # np.argmax(infe_output) will be a single value, which represents the the index of predicted word\n",
    "        # but to pass this data into next time step embedding layer, we are reshaping it into (1,1) shape\n",
    "        cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
    "        print(f\"at time step {i} the word is \", cur_vec)\n",
    "        \n",
    "        if english_dict[cur_vec[0][0]] == '<end>':\n",
    "            break\n",
    "        pred.append(cur_vec)\n",
    " \n",
    "\n",
    "    pred_string = \" \".join([ english_dict[i[0][0]] for i in pred])\n",
    "    \n",
    "    print(\"PREDICTED STRING:\",pred_string) \n",
    "    \n",
    "    return  input_sentence, pred_string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at time step 0 the word is  [[3363]]\n",
      "at time step 1 the word is  [[11]]\n",
      "at time step 2 the word is  [[8]]\n",
      "at time step 3 the word is  [[193]]\n",
      "at time step 4 the word is  [[4]]\n",
      "at time step 5 the word is  [[6]]\n",
      "at time step 6 the word is  [[10289]]\n",
      "PREDICTED STRING: steady are the father tom is\n",
      "Input_sentence: è il padre di tom\n",
      "English predict: steady are the father tom is\n",
      "English actual: that is tom is father\n"
     ]
    }
   ],
   "source": [
    "index = 200\n",
    "input_test_sentence = validation[\"italian\"].values[index]\n",
    "actual = validation[\"english_out\"].values[index]\n",
    "input_sentence, pred_string = predict(input_test_sentence)\n",
    "import re\n",
    "print(f\"Input_sentence: {input_sentence}\")\n",
    "print(f\"English predict: {pred_string}\")\n",
    "print(f\"English actual: {re.sub('<end>', '', actual).strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLUE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "996pFO8BLOfG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady are you a teacher\n",
      "ACTUAL STRING: you are a teacher\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady do not you what would he\n",
      "ACTUAL STRING: are not you going to eat it\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady i would like to drastically decrease than the amount of the way where i take it off the rest\n",
      "ACTUAL STRING: i would like to drastically decrease the amount of time it takes me to clean the house\n",
      "BL880EU score: \u001b[1m\u001b[31m0.32\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady think i am selfish\n",
      "ACTUAL STRING: i think you are selfish\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady there was a trick who can play with trick\n",
      "ACTUAL STRING: it will be fun to have somebody to play with\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady tell tom i do not care for me\n",
      "ACTUAL STRING: tell tom i do not care\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5873949094699213\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady put your toys\n",
      "ACTUAL STRING: pick your toys up\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady tom is not interested\n",
      "ACTUAL STRING: tom is not interested\n",
      "BL880EU score: \u001b[1m\u001b[32m0.668740304976422\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady both tom and mary are canadians\n",
      "ACTUAL STRING: tom and mary are not canadians\n",
      "BL880EU score: \u001b[1m\u001b[31m0.43\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady do you think i think i am hearing\n",
      "ACTUAL STRING: how do you think i feel\n",
      "BL880EU score: \u001b[1m\u001b[31m0.3\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady i do not want to run out\n",
      "ACTUAL STRING: i do not want to take risks\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5169731539571706\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady i thought tom was going to answer\n",
      "ACTUAL STRING: i thought tom would find that interesting\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady did tom ring mary is death\n",
      "ACTUAL STRING: tom broke mary is clarinet\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady do you play tennis next sunday\n",
      "ACTUAL STRING: he will play golf next sunday\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady police almost of tom changed\n",
      "ACTUAL STRING: everyone but tom laughed\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady mind are unfounded\n",
      "ACTUAL STRING: we are ruined\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady i was defeated\n",
      "ACTUAL STRING: i was dazzled\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady two students are absent today\n",
      "ACTUAL STRING: two students are absent today\n",
      "BL880EU score: \u001b[1m\u001b[32m0.7598356856515925\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady i have a lot of questions\n",
      "ACTUAL STRING: i have got a lot of questions\n",
      "BL880EU score: \u001b[1m\u001b[31m0.49\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady did tom your which from work\n",
      "ACTUAL STRING: tom is absorbed in his work\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady do not have them\n",
      "ACTUAL STRING: do not mess things up\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady can you answer something like me\n",
      "ACTUAL STRING: can you explain something to me\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady i am not able to do it\n",
      "ACTUAL STRING: i am unable to do it\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady do it still do you are\n",
      "ACTUAL STRING: do it again\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTED STRING: steady my uncle lived a beautiful father and a strong body died\n",
      "ACTUAL STRING: my uncle lived a happy life and died a peaceful death\n",
      "BL880EU score: \u001b[1m\u001b[31m0.24\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady have a lot of books two hours\n",
      "ACTUAL STRING: i have a lot more books than you do\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady still are not you sure\n",
      "ACTUAL STRING: we are still not sure\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady students did completely any rice\n",
      "ACTUAL STRING: the students all laughed\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady have met tom a friend of the party\n",
      "ACTUAL STRING: i met tom at a party\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "============================== Inference ==============================\n",
      "-------------------- started predition --------------------\n",
      "PREDICTED STRING: steady are you interested in computers\n",
      "ACTUAL STRING: you are interested in computers\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import nltk.translate.bleu_score as bleu\n",
    "test_it = validation[\"italian\"].values[30:60]\n",
    "test_eng = validation[\"english_out\"].apply(lambda a:re.sub('<end>', '', a).strip()).values[30:60]\n",
    "for i in range(30):\n",
    "    input_test_sentence = test_it[i]\n",
    "    input_sentence, pred_string = predict(input_test_sentence)\n",
    "    print(f\"ACTUAL STRING: {test_eng[i]}\")\n",
    "    reference = [test_eng[i].split()] # the original\n",
    "    translation = pred_string.split() # trasilated using model\n",
    "    bs = bleu.sentence_bleu(reference, translation)\n",
    "    print(f'BL880EU score: {colored(bs, \"green\", attrs=[\"bold\"]) if 0.5<=bs<=1 else colored(round(bs, 2), \"red\", attrs=[\"bold\"])}')\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxWFDxZXLOfJ"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:44<00:00, 22.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "test_it = validation[\"italian\"].values[:1000]\n",
    "test_eng = validation[\"english_out\"].apply(lambda a:re.sub('<end>', '', a).strip()).values[:1000]\n",
    "bss = []\n",
    "for i in tqdm(range(1000)):\n",
    "    input_test_sentence = test_it[i]\n",
    "    input_sentence, pred_string = predict(input_test_sentence)\n",
    "    reference = [test_eng[i].split()] # the original\n",
    "    translation = pred_string.split() # trasilated using model\n",
    "    bs = bleu.sentence_bleu(reference, translation)\n",
    "    bss.append(bs)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AVG. BLUE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1781403652170443"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----ATTENTION MODELS-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL-1 DOT SCORE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZhX3K9GLOfJ"
   },
   "source": [
    "##  Including Attention mechanisum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU4KIsGxLOfK"
   },
   "source": [
    "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMm3ADQDLOfK"
   },
   "source": [
    "<font color='blue'>**Encoder**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder model inherited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Lx_5NA24KzRp"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "\n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        super().__init__(name=\"encode_model_Attention\")\n",
    "        self.inp_vocab_size = inp_vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.input_length = input_length\n",
    "        self.embedding = Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size,input_length=self.input_length,\\\n",
    "                  mask_zero=True, name=\"embedding_layer_encoder\")\n",
    "        self.LSTM = LSTM(self.lstm_size, return_state=True, return_sequences=True, \\\n",
    "                          name=\"Encoder_LSTM\")\n",
    "\n",
    "    def call(self,input_sequence):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- All encoder_outputs, last time steps hidden and cell state\n",
    "        '''\n",
    "        input_embeddings = self.embedding(input_sequence)\n",
    "        self.lstm_output, self.lstm_state_h, self.lstm_state_c = self.LSTM(input_embeddings)\n",
    "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
    "\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "        '''\n",
    "        Given a batch size it will return intial hidden state and intial cell state.\n",
    "        If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "        '''\n",
    "        lstm_state_h = tf.zeros([batch_size, self.lstm_size])\n",
    "        lstm_state_c = tf.zeros([batch_size, self.lstm_size])\n",
    "\n",
    "        return lstm_state_h, lstm_state_c\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXn278lhLYRM"
   },
   "source": [
    "<font color='blue'>**Attention**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Attention layer interited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ab5SNdPZLlur"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
    "    '''\n",
    "    def __init__(self,scoring_function, att_units):\n",
    "\n",
    "        super().__init__(name=\"Attention\")\n",
    "        # Please go through the reference notebook and research paper to complete the scoring functions\n",
    "        self.scoring_function = scoring_function\n",
    "        self.att_units = att_units\n",
    "        if self.scoring_function=='dot':\n",
    "          # Intialize variables needed for Dot score function here\n",
    "          pass\n",
    "        if scoring_function == 'general':\n",
    "          # Intialize variables needed for General score function here\n",
    "            self.dense = Dense(self.att_units, activation='relu')\n",
    "        elif scoring_function == 'concat':\n",
    "          # Intialize variables needed for Concat score function here\n",
    "      \n",
    "            self.K = 100\n",
    "            self.dense_1 = Dense(self.K, activation='relu')\n",
    "            self.dense_2 = Dense(self.K, activation='relu')\n",
    "            self.dense_3 = Dense(1, activation='relu')\n",
    "  \n",
    "\n",
    "    def call(self,decoder_hidden_state,encoder_output):\n",
    "        '''\n",
    "          Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
    "          * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
    "            Multiply the score function with your encoder_outputs to get the context vector.\n",
    "            Function returns context vector and attention weights(softmax - scores)\n",
    "        '''\n",
    "\n",
    "        if self.scoring_function == 'dot':\n",
    "            # Implement Dot score function here \n",
    "            ei = tf.keras.layers.Dot(axes = (-1,-1))([decoder_hidden_state, encoder_output])\n",
    "            alphas = Softmax()(ei)\n",
    "            alphas = tf.expand_dims(alphas, axis=-1)\n",
    "            mull = tf.keras.layers.Multiply()([encoder_output, alphas])\n",
    "            context_vec = tf.reduce_mean(mull, axis=-2)\n",
    "            return context_vec, alphas\n",
    "        elif self.scoring_function == 'general':\n",
    "            # Implement General score function here\n",
    "            encoder_output_shrinked = self.dense(encoder_output)\n",
    "            ei = tf.keras.layers.Dot(axes = (-1,-1))([decoder_hidden_state, encoder_output_shrinked])\n",
    "            alphas = Softmax()(ei)\n",
    "            alphas = tf.expand_dims(alphas, axis=-1)\n",
    "            mull = tf.keras.layers.Multiply()([encoder_output, alphas])\n",
    "            context_vec = tf.reduce_mean(mull, axis=-2)\n",
    "            return context_vec, alphas\n",
    "            \n",
    "            \n",
    "        elif self.scoring_function == 'concat':\n",
    "            \n",
    "            k1 = self.dense_1(encoder_output)\n",
    "            k2 =  self.dense_2(decoder_hidden_state)\n",
    "            add = tf.keras.layers.Add()([k1, k2])\n",
    "            tanh = tf.keras.layers.Activation(activation=\"tanh\")(add)\n",
    "            ei = self.dense_3(tanh)\n",
    "            ei = tf.squeeze(ei,-1)\n",
    "            alphas = Softmax()(ei) \n",
    "            alphas = tf.expand_dims(alphas, axis=-1)\n",
    "            mull = tf.keras.layers.Multiply()([encoder_output, alphas])\n",
    "            context_vec = tf.reduce_mean(mull, axis=-2)                \n",
    "            return context_vec, alphas\n",
    "    \n",
    "  #!@  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26681"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_ita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Decoder Main component -- One step ecoder inhertited from Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Kc8m7lmOL097"
   },
   "outputs": [],
   "source": [
    "class OneStepDecoder(tf.keras.Model):\n",
    "    def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "        super().__init__(name=\"OneStepDecoder\")\n",
    "        # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "        \n",
    "        self.dec_units = dec_units\n",
    "        self.score_fun = score_fun\n",
    "        self.att_units = att_units\n",
    "        self.attention = Attention(score_fun,att_units)\n",
    "        self.embedding = Embedding(input_dim = tar_vocab_size, output_dim = embedding_dim, input_length = input_length, mask_zero=True,\\\n",
    "                weights=[embedding_matrix], trainable=False )\n",
    "        \n",
    "        self.lstm = LSTM(self.dec_units, \\\n",
    "                         return_sequences=True, return_state=True, \\\n",
    "                          name=\"OneStepDecoder_LSTM\")\n",
    "        self.bn = BatchNormalization()\n",
    "        self.dense = Dense(tar_vocab_size, activation='softmax')\n",
    "        \n",
    "\n",
    "    def call(self, input_to_decoder, encoder_output, state_h, state_c):\n",
    "        '''\n",
    "             One step decoder mechanisim step by step:\n",
    "          A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
    "          B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
    "          C. Concat the context vector with the step A output\n",
    "          D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
    "          E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
    "          F. Return the states from step D, output from Step E, attention weights from Step -B\n",
    "        '''\n",
    "        #adding attention information to embeddings now\n",
    "        embeddings = self.embedding(input_to_decoder)\n",
    "        context_vector, attention_weights = self.attention(state_h, encoder_output)\n",
    "        attention_embeddings = tf.concat([tf.expand_dims(context_vector, 1), embeddings], axis=-1)\n",
    "        \n",
    "        x, state_h, state_c = self.lstm(attention_embeddings, initial_state=[state_h, state_c])\n",
    "        \n",
    "        output = self.dense(x)\n",
    "        output = self.bn(output)\n",
    "        output = tf.squeeze(output,1)\n",
    "        return output, state_h, state_c, attention_weights, context_vector\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FHrurjUMGAi"
   },
   "source": [
    "<font color='blue'>**Decoder**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder used for calling OneStepDecoder Model for each english word(num form) inherited from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NV-x31rj6Hc4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "        #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "        super().__init__(name=\"Decode_Attention\")\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_length = input_length\n",
    "        self.dec_units = dec_units\n",
    "        self.score_fun = score_fun \n",
    "        self.att_units = att_units\n",
    "        self.onestepdecoder = OneStepDecoder(self.out_vocab_size, self.embedding_dim, self.input_length, self.dec_units, self.score_fun, self.att_units)\n",
    "        \n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
    "\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        #Create a tensor array as shown in the reference notebook\n",
    "        \n",
    "        #Iterate till the length of the decoder input\n",
    "            # Call onestepdecoder for each token in decoder_input\n",
    "            # Store the output in tensorarray\n",
    "        # Return the tensor array\n",
    "        \n",
    "        all_outputs = tf.TensorArray(tf.float32, size=25, name=\"output_arrays\")\n",
    "        for timestep in range(25):\n",
    "            output,decoder_hidden_state,decoder_cell_state,attention_weights,context_vector = self.onestepdecoder(\\\n",
    "                                input_to_decoder[:, timestep:timestep+1],encoder_output,\\\n",
    "                                decoder_hidden_state,decoder_cell_state\n",
    "                               )\n",
    "            \n",
    "            all_outputs = all_outputs.write(timestep, output)\n",
    "        all_outputs = tf.transpose(all_outputs.stack(), [1,0,2])\n",
    "        return all_outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC1T1EOoMTqC"
   },
   "source": [
    "<font color='blue'>**Encoder Decoder model**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final encoder_deocder inherited Model\n",
    "* Take italian language for all timestep and preserves each LSTM layer hidden state an final cell state=>Encoder Model,\n",
    "  We stop its execution for input 1(or batch), from now onwards **DECODER** will take care\n",
    "\n",
    "* Decoder consumes ENCODER's returned values and pass it to ONESTEPDECODER (its backbone)\n",
    "* ONESTEPDECODER will use encoder's output given to it by DECODER and will calculate summary of Encoders each timestep hidden\n",
    "  state by giving more importance to a word which is more responsible to predict the upcoming predicted word those importance\n",
    "  is nothing but **ATTENTIONS** should given to each input Italian word\n",
    "* Then ONESTEPDECODER consumes that weighted summary and concatenate with input english word at the timestep only and\n",
    "  pass it to LSTM and then dense layer gives us the num value of the predict word.\n",
    "  - This is done for each timestep and DECODER is responsible for one by one calling for each word\n",
    "\n",
    "**ENCODER** **=>** [ **DECODER**=>loop**(** **ONESTEPDECODER**=>Attention+LSTM+dense**)** ] **=>** List of integers representing predicted sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FfqBIe20MT3D"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "    def __init__(self,inp_vocab_size, out_vocab_size, en_input_length,de_input_length, dec_units ,score_fun ,att_units):\n",
    "    #Intialize objects from encoder decoder\n",
    "        super().__init__(name=\"Encoder_Decoder_Attention_model\")\n",
    "        #Create encoder object\n",
    "        #Create decoder object\n",
    "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
    "        \n",
    "\n",
    "         \n",
    "        \n",
    "        self.encoder = Encoder(inp_vocab_size, 50,dec_units, en_input_length)\n",
    "        self.decoder = Decoder(out_vocab_size, 100, de_input_length, dec_units, score_fun, att_units)\n",
    "#         self.dense   = Dense(vocab_size_eng+1, activation='softmax')\n",
    "                             \n",
    "    def call(self,data):\n",
    "        #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
    "        # Decoder initial states are encoder final states, Initialize it accordingly\n",
    "        # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
    "        # return the decoder output\n",
    "        input_italian, input_english = data[0], data[1]\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input_italian)\n",
    "        decoder_output = self.decoder(input_english,encoder_output, encoder_h, encoder_c)\n",
    "        return decoder_output\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVRxB-FDMJWL"
   },
   "source": [
    "<font color='blue'>**Custom loss function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QY_3izrXMs8y"
   },
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
    "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
    "    can use simple sparse categorical crossentropy as loss like we did . But in this loss function we are ignoring the loss\n",
    "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
    "    during preprocessing to make equal length for all the sentences.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QlbWAqNNlqe"
   },
   "source": [
    "<font color='blue'>**Training**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqtZUQF2NuZE"
   },
   "source": [
    "Implement dot function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, TensorBoard, LearningRateScheduler\n",
    "from sklearn.metrics import recall_score, f1_score, roc_curve, auc\n",
    "import datetime\n",
    "\n",
    "filepath=\"model_save_attention_general/weights-{epoch:02d}-{val_loss:.2f}\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', save_format=\"tf\", save_freq=\"epoch\",  verbose=1, save_best_only=True, mode='auto')\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 1.5499\n",
      "Epoch 1: val_loss improved from inf to 1.20464, saving model to model_save_attention_dot\\weights-01-1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-01-1.20\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-01-1.20\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 457s 194ms/step - loss: 1.5499 - val_loss: 1.2046\n",
      "Epoch 2/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.9016\n",
      "Epoch 2: val_loss improved from 1.20464 to 0.98323, saving model to model_save_attention_dot\\weights-02-0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-02-0.98\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-02-0.98\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 424s 192ms/step - loss: 0.9016 - val_loss: 0.9832\n",
      "Epoch 3/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.7428\n",
      "Epoch 3: val_loss improved from 0.98323 to 0.82875, saving model to model_save_attention_dot\\weights-03-0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-03-0.83\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-03-0.83\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 412s 187ms/step - loss: 0.7428 - val_loss: 0.8287\n",
      "Epoch 4/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.6496\n",
      "Epoch 4: val_loss improved from 0.82875 to 0.75238, saving model to model_save_attention_dot\\weights-04-0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-04-0.75\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-04-0.75\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 411s 187ms/step - loss: 0.6496 - val_loss: 0.7524\n",
      "Epoch 5/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.5892\n",
      "Epoch 5: val_loss improved from 0.75238 to 0.69024, saving model to model_save_attention_dot\\weights-05-0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-05-0.69\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-05-0.69\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 412s 187ms/step - loss: 0.5892 - val_loss: 0.6902\n",
      "Epoch 6/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.5411\n",
      "Epoch 6: val_loss improved from 0.69024 to 0.66872, saving model to model_save_attention_dot\\weights-06-0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-06-0.67\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-06-0.67\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 414s 188ms/step - loss: 0.5411 - val_loss: 0.6687\n",
      "Epoch 7/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.5022\n",
      "Epoch 7: val_loss improved from 0.66872 to 0.62590, saving model to model_save_attention_dot\\weights-07-0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-07-0.63\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-07-0.63\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 415s 188ms/step - loss: 0.5022 - val_loss: 0.6259\n",
      "Epoch 8/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.4682\n",
      "Epoch 8: val_loss improved from 0.62590 to 0.60602, saving model to model_save_attention_dot\\weights-08-0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-08-0.61\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-08-0.61\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 416s 188ms/step - loss: 0.4682 - val_loss: 0.6060\n",
      "Epoch 9/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.4388\n",
      "Epoch 9: val_loss improved from 0.60602 to 0.58371, saving model to model_save_attention_dot\\weights-09-0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-09-0.58\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-09-0.58\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 414s 188ms/step - loss: 0.4388 - val_loss: 0.5837\n",
      "Epoch 10/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.4128\n",
      "Epoch 10: val_loss improved from 0.58371 to 0.57495, saving model to model_save_attention_dot\\weights-10-0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-10-0.57\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-10-0.57\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 423s 192ms/step - loss: 0.4128 - val_loss: 0.5750\n",
      "Epoch 11/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3919\n",
      "Epoch 11: val_loss improved from 0.57495 to 0.54921, saving model to model_save_attention_dot\\weights-11-0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-11-0.55\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-11-0.55\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 418s 190ms/step - loss: 0.3919 - val_loss: 0.5492\n",
      "Epoch 12/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3748\n",
      "Epoch 12: val_loss improved from 0.54921 to 0.54819, saving model to model_save_attention_dot\\weights-12-0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-12-0.55\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-12-0.55\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 414s 188ms/step - loss: 0.3748 - val_loss: 0.5482\n",
      "Epoch 13/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3590\n",
      "Epoch 13: val_loss improved from 0.54819 to 0.53792, saving model to model_save_attention_dot\\weights-13-0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-13-0.54\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-13-0.54\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 417s 189ms/step - loss: 0.3590 - val_loss: 0.5379\n",
      "Epoch 14/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3464\n",
      "Epoch 14: val_loss did not improve from 0.53792\n",
      "2205/2205 [==============================] - 379s 172ms/step - loss: 0.3464 - val_loss: 0.5472\n",
      "Epoch 15/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3342\n",
      "Epoch 15: val_loss improved from 0.53792 to 0.52334, saving model to model_save_attention_dot\\weights-15-0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-15-0.52\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-15-0.52\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 415s 188ms/step - loss: 0.3342 - val_loss: 0.5233\n",
      "Epoch 16/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3239\n",
      "Epoch 16: val_loss did not improve from 0.52334\n",
      "2205/2205 [==============================] - 379s 172ms/step - loss: 0.3239 - val_loss: 0.5241\n",
      "Epoch 17/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3149\n",
      "Epoch 17: val_loss improved from 0.52334 to 0.51652, saving model to model_save_attention_dot\\weights-17-0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-17-0.52\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-17-0.52\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 415s 188ms/step - loss: 0.3149 - val_loss: 0.5165\n",
      "Epoch 18/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3063\n",
      "Epoch 18: val_loss improved from 0.51652 to 0.51191, saving model to model_save_attention_dot\\weights-18-0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-18-0.51\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-18-0.51\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 416s 189ms/step - loss: 0.3063 - val_loss: 0.5119\n",
      "Epoch 19/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2978\n",
      "Epoch 19: val_loss did not improve from 0.51191\n",
      "2205/2205 [==============================] - 379s 172ms/step - loss: 0.2978 - val_loss: 0.5127\n",
      "Epoch 20/20\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2900\n",
      "Epoch 20: val_loss improved from 0.51191 to 0.50012, saving model to model_save_attention_dot\\weights-20-0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-20-0.50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-20-0.50\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2205/2205 [==============================] - 417s 189ms/step - loss: 0.2900 - val_loss: 0.5001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_attention_dot = encoder_decoder(vocab_size_ita+1,vocab_size_eng+1,22,25,512,\"dot\",512)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model_attention_dot.compile(optimizer=optimizer,loss=loss_function)\n",
    "train_steps=train.shape[0]//128\n",
    "valid_steps=validation.shape[0]//128\n",
    "history_dot = model_attention_dot.fit(train_dataloader, steps_per_epoch=train_steps, epochs=20, validation_data=test_dataloader, validation_steps=valid_steps,\n",
    "                   callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2c8d3fc8190>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_dot.history['loss']\n",
    "# acc = history.history['acc']\n",
    "val_loss = history_dot.history['val_loss'] \n",
    "epoch = 20\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/val_loss')\n",
    "plt.title('Learning')\n",
    "plt.plot(range(epoch), loss, label = \"loss\")\n",
    "plt.plot(range(epoch), val_loss, label = \"val_loss\") \n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training more for 10 EPOCHS more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.1871\n",
      "Epoch 1: val_loss did not improve from 0.47269\n",
      "2205/2205 [==============================] - 386s 175ms/step - loss: 0.1871 - val_loss: 0.4768\n",
      "Epoch 2/10\n",
      "1324/2205 [=================>............] - ETA: 2:21 - loss: 0.1847"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13000/1171894609.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# train_steps=train.shape[0]//96\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# valid_steps=validation.shape[0]//96\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m history_dot_2 = model_attention_dot.fit(train_dataloader, steps_per_epoch=train_steps, epochs=10, validation_data=test_dataloader, validation_steps=valid_steps,\n\u001b[0m\u001b[0;32m      7\u001b[0m                    callbacks=[checkpoint])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# model_attention = encoder_decoder(vocab_size_ita+1,vocab_size_eng+1,22,25,256,\"dot\",256)\n",
    "# optimizer = tf.keras.optimizers.Adam()\n",
    "# model_attention.compile(optimizer=optimizer,loss=loss_function)\n",
    "# train_steps=train.shape[0]//96\n",
    "# valid_steps=validation.shape[0]//96\n",
    "history_dot_2 = model_attention_dot.fit(train_dataloader, steps_per_epoch=train_steps, epochs=10, validation_data=test_dataloader, validation_steps=valid_steps,\n",
    "                   callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1de816f1460>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_dot_2.history['loss']\n",
    "val_loss = history_dot_2.history['val_loss']\n",
    "epoch = 10\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/val_loss')\n",
    "plt.title('Learning')\n",
    "plt.plot(range(epoch), loss, label = \"loss\")\n",
    "plt.plot(range(epoch), val_loss, label = \"val_loss\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for 10 epochs more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2348\n",
      "Epoch 1: val_loss improved from 0.48636 to 0.48419, saving model to model_save_attention_dot\\weights-01-0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-01-0.48\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-01-0.48\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 447s 203ms/step - loss: 0.2348 - val_loss: 0.4842\n",
      "Epoch 2/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2315\n",
      "Epoch 2: val_loss did not improve from 0.48419\n",
      "2205/2205 [==============================] - 385s 175ms/step - loss: 0.2315 - val_loss: 0.4883\n",
      "Epoch 3/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2281\n",
      "Epoch 3: val_loss did not improve from 0.48419\n",
      "2205/2205 [==============================] - 403s 183ms/step - loss: 0.2281 - val_loss: 0.4900\n",
      "Epoch 4/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2246\n",
      "Epoch 4: val_loss did not improve from 0.48419\n",
      "2205/2205 [==============================] - 405s 184ms/step - loss: 0.2246 - val_loss: 0.4922\n",
      "Epoch 5/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2221\n",
      "Epoch 5: val_loss improved from 0.48419 to 0.48343, saving model to model_save_attention_dot\\weights-05-0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-05-0.48\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-05-0.48\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 434s 197ms/step - loss: 0.2221 - val_loss: 0.4834\n",
      "Epoch 6/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2190\n",
      "Epoch 6: val_loss did not improve from 0.48343\n",
      "2205/2205 [==============================] - 399s 181ms/step - loss: 0.2190 - val_loss: 0.4841\n",
      "Epoch 7/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2161\n",
      "Epoch 7: val_loss improved from 0.48343 to 0.47757, saving model to model_save_attention_dot\\weights-07-0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-07-0.48\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-07-0.48\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 517s 235ms/step - loss: 0.2161 - val_loss: 0.4776\n",
      "Epoch 8/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2137\n",
      "Epoch 8: val_loss did not improve from 0.47757\n",
      "2205/2205 [==============================] - 402s 182ms/step - loss: 0.2137 - val_loss: 0.4784\n",
      "Epoch 9/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2113\n",
      "Epoch 9: val_loss did not improve from 0.47757\n",
      "2205/2205 [==============================] - 392s 178ms/step - loss: 0.2113 - val_loss: 0.4861\n",
      "Epoch 10/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2090\n",
      "Epoch 10: val_loss did not improve from 0.47757\n",
      "2205/2205 [==============================] - 398s 180ms/step - loss: 0.2090 - val_loss: 0.4806\n"
     ]
    }
   ],
   "source": [
    "history_dot_3 = model_attention_dot.fit(train_dataloader, steps_per_epoch=train_steps, epochs=10, validation_data=test_dataloader, validation_steps=valid_steps,\n",
    "                   callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2c8f881db50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAl4UlEQVR4nO3deZzcdZ3n8de7u6vvTieQCxIkQZAgRA4bRpYxio4KrooII1HAkXFkUAFlRwTW0WFUdsZx1tFxWRnWAXTFAeRw43DOqGtkvdJhwhEuMXJ0wtGJuTt9f/aP36+6qzv1S7qSrlSn+/18POpRv+P7/dW3Kul61/f3/R2KCMzMzIqpqnQDzMxs4nJImJlZJoeEmZllckiYmVkmh4SZmWVySJiZWSaHhNkEIOmNkp6qdDvMRpPPkzADSc8CfxYR/17ptphNJO5JmO0Dkqor3QazPeGQMMsgqUrSlZJ+K2mDpNskHVCw/vuSXpK0WdJySUcXrLtJ0jcl3SNpO3CqpGclfVrSI2mdWyXVp+XfLKmjoH5m2XT9ZyS9KGmdpD+TFJIO30cfjU0hDgmzbJcC7wXeBBwMbASuLVh/L3AEMBt4CLh5VP0PAtcALcCD6bL3A6cBC4HXAR/exesXLSvpNOC/AH8EHJ62z6wsHBJm2f4c+GxEdERED3A1cLakGoCIuCEithasO1ZSa0H9/xMR/y8iBiOiO132jxGxLiJ+D/wQOG4Xr59V9v3AjRGxOiK6gL8el3drVoRDwizbocBdkjZJ2gQ8AQwAcyRVS/rbdFfUFuDZtM7MgvovFNnmSwXTXUDzLl4/q+zBo7Zd7HXMxoVDwizbC8DpETG94FEfEWtJdiWdQbLLpxVYkNZRQf1yHTr4IjC/YP6QMr2OmUPCrEBOUn3+AXwLuEbSoQCSZkk6Iy3bAvQAG4BG4L/tw3beBlwg6ShJjcDn9+Fr2xTjkDAbdg+wo+AxA1gGPCBpK/BL4A/Sst8BngPWAo+n6/aJiLgX+EfgJ8AzwC/SVT37qg02dfhkOrP9nKSjgMeAuojor3R7bHJxT8JsPyTpTEm1kmYAXwZ+6ICwcnBImO2f/hzoBH5LcsTVxyrbHJusvLvJzMwyuSdhZmaZairdgPE0c+bMWLBgQaWbYWa2X1m5cuX6iJhVbN2kCokFCxbQ3t5e6WaYme1XJD2Xta7su5sknSbpKUnPSLqyyPo3p1e5XJU+Pj/WumZmVl5l7Umk19C/Fngb0AGskLQsIh4fVfRnEfGuPaxrZmZlUu6exEnAMxGxJiJ6gVtIrndT7rpmZjYOyh0S8xh5hcqOdNloJ0t6WNK9BTduGVNdSRdKapfU3tnZOV7tNjMzyh8SKrJs9IkZDwGHRsSxwDeAH5RQl4i4PiLaIqJt1qyig/NmZraHyh0SHYy8jPF8YF1hgYjYEhHb0ul7SK7EOXMsdc3MrLzKHRIrgCMkLZRUCywluarmEElzJSmdPilt04ax1DUzs/Iq69FNEdEv6WLgfqAauCEiVku6KF1/HXA28DFJ/SSXZ14aybVCitYtZ3ttH4iA/m7o7YLebdDXNWp6e/LoS5dV18Gc18KcY6B5DqjYXkgzK5dJde2mtra28Ml042RwYOcv7N4u6EuXZX7Jj/7CH1WnbzvE4J61qfFAmHN0Ehj551mLIFc/vu/dbIqRtDIi2oqtm1RnXE9aA/3QvwP6upNf4f3d0LejYLq7YP0O6O8ZXt+Xzheu3+V20mWDfaW1MdeYPGqbkkd+uvHAkfND081Q2zhyurYJcmmZ2sZkuncbvPI4vLwaXno0eW6/MXkfAKqGAw9PQyMNjrnHwLR57nWYjQOHxL4yOAjdm2D7etjeWfBYP3K6a0PyK7zwy31wL24TUF0LNfXJI1cPNQ1QUwe5hmRZw4yd1+fS+aEv9absL/H8l35VmYa3ag6ABX+YPPIGB+D3v4OXH0tC4+XVsLYdVt85XKa+taDHkYbH7KOS9prZmDkk9kbv9iJf9IXz64enu9ZnfNkLGg+AplnJY/ai5Mt39Bd2Tf3wF3uxL/Si6+uhqnqffyxlV1UNMw9PHke/d3h592Z45YmR4bHqe0lvBADBAYeN2mV1NEw/tHwhZ5NX3w7Y8Nvkh920g5Pea21jpVs17hwShQb6kn/wor/yi/zq7+sqvp3aZmiamXzpTz8E5h0/HAJNs4bXNc2ChgOg2v8M46K+FV71huSRNzgIm54bDo18gDzxQ4ZOu6ltSQfHC3sdr4X6aRV5GzbB7NgI638DnU/B+qeg8+nkeeNz7HTqVsMMmDYfWuclodE6L51Pl7UcDDW1FXkbe8oD1wBdv4dvnJD8ZyimqmbnL/ed5tPpxpmT8tfEpNO7fedex8uPJb2RvOmvgjmLk+Bonp30BAcHIAbS6cGC6fzygVFl8tODyfxQmf5kAH9oenTdwuWDw+WbZsKMBTBjYfqcPppnewxmb0TAlnWw/unk0fnU8PP2V4bLVdclY2Azj4BZR8LM1yT/Jltfgs0dsGUtbF6bPncku5hHUPJvNSJA8oEyP3lumbvP9wDsauDaIQHJH+S9n8kOgvrp/gOcCiKSP+7CQfKXV8OG3+zmiCwlf9RVNclAelX6GJrOL6/KLqO0XFU1qKpgurBsFWx7BTY+m3yhFf6KzTWODI3CEJn+Kh8BljfQDxt/t3MQrP8N9G4dLlfXCrNeAzOPHBkIMxaU9gXesy35t9rSMTI8CsNkaHdoStXQclCR3khBmDTNGtfvJIeE2d7o607+kIt9eee//CvRps0vJAP4G58teKTzI3aFKtlnnhUiTTMn34+g3q4k3PO7hvKBsOG3I4/cazko+fLPh0B+el+dkxOR9F6HQiMjTAZ6Rtarrk3HQdLwaJ2fBNqx5+xRM3wIrNneyNVPvF/iufrkF+7MI3ZeF5GMm218dlSI/A5++2PY+uLI8rXNowJkwXCITD8kORpuotq+Id1FVDBW0Pk0bH5+uIyqkvcz60h4zWlpIByZHPhQ31q5tkMSRA3Tk8eco4uXiUjGSgtDY/MLw9PP/TzprRz0uj0OiV020T0Jsymmbwdsen7nAMlP93cXFFayi2PGAjhgQRochya9qIH+dNylP/l1nh9HGexPDgIZmu8bHp8Z6CuoM1Cwrn/U9kY9ir1W77aR44g1DWlwFvQMZh2ZHNE2kYNuPAwOQM+WZOB8D7gnYWbDcg3Jl+esI3deFwHbXi6+G+s3/5asK1VVLt1NV5McyZefrsoNj9kUXVeTHMZdnRvezVe4rVw9HPDq4UBoPWTqHspcVb3HAbE7DgkzGyYlR9e0zIVDT955fe/2ZBdHDO76Sz//xa6qyTfeMcU4JMxs7GqbkqN+bMqYon0zMzMbC4eEmZllckiYmVkmh4SZmWVySJiZWSaHhJmZZXJImJlZJoeEmZllckiYmVkmh4SZmWVySJiZWSaHhJmZZXJImJlZJoeEmZllKntISDpN0lOSnpF05S7KnShpQNLZBcuelfSopFWSfMs5M7N9rKz3k5BUDVwLvA3oAFZIWhYRjxcp92Xg/iKbOTUi1peznWZmVly5exInAc9ExJqI6AVuAc4oUu4S4A7glTK3x8zMSlDukJgHvFAw35EuGyJpHnAmcF2R+gE8IGmlpAuLvYCkCyW1S2rv7Owcp2abmRmUPySK3dw2Rs1/DbgiIgaKlD0lIk4ATgc+IWnJThuLuD4i2iKibdasWXvdYDMzG1bue1x3AIcUzM8H1o0q0wbcouRm6TOBd0rqj4gfRMQ6gIh4RdJdJLuvlpe5zWZmlip3T2IFcISkhZJqgaXAssICEbEwIhZExALgduDjEfEDSU2SWgAkNQFvBx4rc3vNzKxAWXsSEdEv6WKSo5aqgRsiYrWki9L1xcYh8uYAd6U9jBrgexFxXznba2ZmIyli9BDB/qutrS3a2306hZlZKSStjIi2Yut8xrWZmWVySJiZWSaHhJmZZXJImJlZJoeEmZllckiYmVkmh4SZmWVySJiZWSaHhJmZZXJImJlZJoeEmZllckiYmVkmh4SZmWVySJiZWSaHhJmZZXJImJlZJoeEmZllckiYmVkmh4SZmWVySJiZWSaHhJmZZXJImJlZJoeEmZllckiYmVkmh4SZmWUqe0hIOk3SU5KekXTlLsqdKGlA0tml1jUzs/Ioa0hIqgauBU4HXgt8QNJrM8p9Gbi/1LpmZlY+5e5JnAQ8ExFrIqIXuAU4o0i5S4A7gFf2oK6ZmZVJuUNiHvBCwXxHumyIpHnAmcB1pdY1M7PyKndIqMiyGDX/NeCKiBjYg7pIulBSu6T2zs7OPWulmZkVVVPm7XcAhxTMzwfWjSrTBtwiCWAm8E5J/WOsS0RcD1wP0NbWtlOImJnZnit3SKwAjpC0EFgLLAU+WFggIhbmpyXdBPxrRPxAUs3u6pqZWXmVNSQiol/SxSRHLVUDN0TEakkXpetHj0Pstm4522tmZiMpYvLsoWlra4v29vZKN8PMbL8iaWVEtBVb5zOuzcws05hDQtKrJdWl02+WdKmk6WVrmZmZVVwpPYk7gAFJhwP/DCwEvleWVpmZ2YRQSkgMRkQ/yYlvX4uIy4CDytMsMzObCEoJiT5JHwD+BPjXdFlu/JtkZmYTRSkhcQFwMnBNRPwuPX/hu+VplpmZTQRjPk8iIh4HLgWQNANoiYi/LVfDzMys8ko5uun/Spom6QDgYeBGSV8tX9PMzKzSStnd1BoRW4D3ATdGxOuBPypPs8zMbCIoJSRqJB0EvJ/hgWszM5vESgmJL5BcR+m3EbFC0mHAb8rTLDMzmwhKGbj+PvD9gvk1wFnlaJSZmU0MYw4JSfOBbwCnkNz850HgkxHRUaa2mZmNSV9fHx0dHXR3d1e6KRNafX098+fPJ5cb+ylupVwq/EaSy3D8cTp/XrrsbSVsw8xs3HV0dNDS0sKCBQtIb2Bmo0QEGzZsoKOjg4ULF+6+QqqUMYlZEXFjRPSnj5uAWaU21MxsvHV3d3PggQc6IHZBEgceeGDJva1SQmK9pPMkVaeP84ANJb2amVmZOCB2b08+o1JC4k9JDn99CXgRODtdZmZmk1QpRzc9D7ynjG0xM9tvNTc3s23btko3Y9ztNiQkfYPkaKaiIuLScW2RmZlNGGPZ3dQOrNzFw8zMUhHB5ZdfzjHHHMPixYu59dZbAXjxxRdZsmQJxx13HMcccww/+9nPGBgY4MMf/vBQ2X/4h3+ocOt3ttueRER8eywbkvSNiLhk75tkZrbn/vqHq3l83ZZx3eZrD57GX7376DGVvfPOO1m1ahUPP/ww69ev58QTT2TJkiV873vf4x3veAef/exnGRgYoKuri1WrVrF27Voee+wxADZt2jSu7R4PpQxc784p47gtM7P90oMPPsgHPvABqqurmTNnDm9605tYsWIFJ554IjfeeCNXX301jz76KC0tLRx22GGsWbOGSy65hPvuu49p06ZVuvk7KeVkOjOzCW+sv/jLJaL4EO6SJUtYvnw5d999N+effz6XX345H/rQh3j44Ye5//77ufbaa7ntttu44YYb9nGLd208exJmZlPekiVLuPXWWxkYGKCzs5Ply5dz0kkn8dxzzzF79mw++tGP8pGPfISHHnqI9evXMzg4yFlnncUXv/hFHnrooUo3fyfj2ZPwmSxmNuWdeeaZ/OIXv+DYY49FEn/3d3/H3Llz+fa3v81XvvIVcrkczc3NfOc732Ht2rVccMEFDA4OAvA3f/M3FW79zpTVNSp5Q9KH00t1VExbW1u0t7dXsglmVgFPPPEERx11VKWbsV8o9llJWhkRbcXKj+U8iR+y6/Mk3pM+35RR/zTg60A18K3R98WWdAbwRWAQ6Ac+FREPpuueBbYCA0B/1pswM7PyGMvupr/f041LqgauJblSbAewQtKyiHi8oNiPgGUREZJeB9wGLCpYf2pErN/TNpiZ2Z4by3kSP92L7Z8EPJPeoAhJtwBnAEMhERGF57E3sYtei5mZ7VtjPrpJ0hGSbpf0uKQ1+cduqs0DXiiY70iXjd72mZKeBO5m5EUDA3hA0kpJF2a060JJ7ZLaOzs7x/p2zMxsDEo5BPZG4Jsk4wanAt8B/vdu6hQ74mmnnkJE3BURi4D3koxP5J0SEScApwOfkLSkSN3rI6ItItpmzfLtLczMxlMpIdEQET8iOSLquYi4GnjLbup0AIcUzM8H1mUVjojlwKslzUzn16XPrwB3key+MjOzfaSUkOiWVAX8RtLFks4EZu+mzgrgCEkLJdUCS4FlhQUkHa70ThiSTgBqgQ2SmiS1pMubgLcDj5XQXjMz20ulhMSngEbgUuD1JPe4/pNdVYiIfuBi4H7gCeC2iFgt6SJJF6XFzgIek7SK5EiocyI5eWMO8KCkh4FfA3dHxH0ltNfMbEJqbm7OXPfss89yzDHH7MPW7FopZ1z3p0cibQMuGGuliLgHuGfUsusKpr8MfLlIvTXAsSW0z8zMxlkpIfFVSQcB3wduiYjVZWqTmdmeu/dKeOnR8d3m3MVw+t9mrr7iiis49NBD+fjHPw7A1VdfjSSWL1/Oxo0b6evr40tf+hJnnHFGSS/b3d3Nxz72Mdrb26mpqeGrX/0qp556KqtXr+aCCy6gt7eXwcFB7rjjDg4++GDe//7309HRwcDAAJ/73Oc455xz9uptQ2m3Lz1V0lyS+1xfL2kacGtEfGmvW2Fmth9bunQpn/rUp4ZC4rbbbuO+++7jsssuY9q0aaxfv543vOENvOc97yEdgh2Ta6+9FoBHH32UJ598kre//e08/fTTXHfddXzyk5/k3HPPpbe3l4GBAe655x4OPvhg7r77bgA2b948Lu+tpAv8RcRLwD9K+gnwGeDzgEPCzCaOXfziL5fjjz+eV155hXXr1tHZ2cmMGTM46KCDuOyyy1i+fDlVVVWsXbuWl19+mblz5455uw8++CCXXJLcy23RokUceuihPP3005x88slcc801dHR08L73vY8jjjiCxYsX8+lPf5orrriCd73rXbzxjW8cl/dWysl0R0m6WtJjwP8Afk5ySKuZ2ZR39tlnc/vtt3PrrbeydOlSbr75Zjo7O1m5ciWrVq1izpw5dHd3l7TNrAuwfvCDH2TZsmU0NDTwjne8gx//+Me85jWvYeXKlSxevJirrrqKL3zhC+PxtkrqSdwI/Avw9vz5C2Zmlli6dCkf/ehHWb9+PT/96U+57bbbmD17Nrlcjp/85Cc899xzJW9zyZIl3HzzzbzlLW/h6aef5vnnn+fII49kzZo1HHbYYVx66aWsWbOGRx55hEWLFnHAAQdw3nnn0dzczE033TQu72ssV4G9HrgXeFtEbB2XVzUzm2SOPvpotm7dyrx58zjooIM499xzefe7301bWxvHHXccixYt2v1GRvn4xz/ORRddxOLFi6mpqeGmm26irq6OW2+9le9+97vkcjnmzp3L5z//eVasWMHll19OVVUVuVyOb37zm+PyvnZ7PwlJbwBOA94K9AIPAPdFxMPj0oJx5PtJmE1Nvp/E2I37/SQi4pfAL4GrJR1IcubzX6SX9X6IJDBu2+uWm5nZhFPq0U0bSMYl/gVA0utJehlmZlaCRx99lPPPP3/Esrq6On71q19VqEXFjTkkJH2SZPB6K/C/gBOAqyLimjK1zcxszCKipHMQKm3x4sWsWrVqn77mntyuupRrN/1pRGwh2d00m+TSHBPvrt1mNuXU19ezYcOGPfoSnCoigg0bNlBfX19SvVJ2N+Uj+p3AjRHxsPan2DazSWv+/Pl0dHTgG4/tWn19PfPnl3Z6WykhsVLSA8BC4Kr0Mt6DJb2amVkZ5HI5Fi5cWOlmTEqlhMRHgOOANRHRJekASrgarJmZ7X9KGZM4GXgqIjZJOg/4S2B8riBlZmYTUikh8U2gS9KxJBf3e47kPtdmZjZJlRIS/ekd484Avh4RXwdaytMsMzObCEoZk9gq6SrgfOCNkqqBXHmaZWZmE0EpPYlzgB6S8yVeAuYBXylLq8zMbEIYc0ikwXAz0CrpXUB3RHhMwsxsEivlpkPvB34N/DHJLUx/JenscjXMzMwqr5Qxic8CJ0bEKwCSZgH/DtxejoaZmVnllTImUZUPiNSGEuubmdl+ppSexH2S7ie9TDjJQPY9498kMzObKMYcEhFxuaSzgFNILvZ3fUTcVbaWmZlZxZV606E7gDvK1BYzM5tgdjumIGmrpC1FHlslbRlD/dMkPSXpGUlXFll/hqRHJK2S1C7pD8da18zMymss97je40tvpGdlXwu8DegAVkhaFhGPFxT7EbAsIiK9b/ZtwKIx1jUzszIq99FJJwHPRMSaiOgFbiG59tOQiNgWw7eTagJirHXNzKy8yh0S84AXCuY70mUjSDpT0pPA3cCfllj3wnQ3VbvvSmVmNr7KHRLFbm+6001oI+KuiFgEvBf4Yol1r4+ItohomzVr1t601czMRil3SHQAhxTMzwfWZRWOiOXAqyXNLLWumZmNv3KHxArgCEkLJdUCS4FlhQUkHS5J6fQJQC3J2dy7rWtmZuVV0nkSpYqIfkkXA/cD1cANEbFa0kXp+uuAs4APSeoDdgDnpAPZReuWs71mZjaShg8s2v+1tbVFe3t7pZthZrZfkbQyItqKrfMF+szMLJNDwszMMjkkzMwsk0PCzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0PCzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0PCzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMjkkzMwsk0PCzMwyOSTMzCyTQ8LMzDI5JMzMLJNDwszMMpU9JCSdJukpSc9IurLI+nMlPZI+fi7p2IJ1z0p6VNIqSe3lbquZmY1UU86NS6oGrgXeBnQAKyQti4jHC4r9DnhTRGyUdDpwPfAHBetPjYj15WynmZkVV+6exEnAMxGxJiJ6gVuAMwoLRMTPI2JjOvtLYH6Z22RmZmNU7pCYB7xQMN+RLsvyEeDegvkAHpC0UtKFxSpIulBSu6T2zs7OvW6wmZkNK+vuJkBFlkXRgtKpJCHxhwWLT4mIdZJmA/8m6cmIWD5iYxHXk+yioq2trei2zcxsz5S7J9EBHFIwPx9YN7qQpNcB3wLOiIgN+eURsS59fgW4i2T3lZmZ7SPlDokVwBGSFkqqBZYCywoLSHoVcCdwfkQ8XbC8SVJLfhp4O/BYmdtrZmYFyrq7KSL6JV0M3A9UAzdExGpJF6XrrwM+DxwI/E9JAP0R0QbMAe5Kl9UA34uI+8rZXjMzG0kRk2c3fltbW7S3+3QKM7NSSFqZ/jjfic+4NjOzTA4JMzPL5JAwM7NMDgkzM8tU7pPp9gs9/QOc9rWf0dqQo7Uhx/TGHNPT6dbGWqany1qHnmtpbchRW+OMNbPJzSEB9A0Ex8xrZVNXLxu7enl2w3Y2dfWxpbuPXR381VhbzfSGHNOGgqV2OEjyodJQOxQw+XXNdTWkh/aamU1oDgmgua6Gb3zg+J2WDwwGW7v72Lyjj01dfWzakUxv7uodMb+pq4/NO3pZs37b0PLe/sHM16uuUhoghQGzc88l32spXF9T7d6Lme07DoldqK4S0xtrmd5Yy6EHlla3u28gDYzeNET62JzOF4bOlh19bNjWy287k4DZ2t2/y+221NXQ2ljQc0kDZOf5gnBpzFFXU70Xn4SZTVUOiTKpz1Uzt7Waua31JdUbGAy27EgCZFNXb9Jb6RqezgdOfn7dph1DPZqBwex9Yw256hHjKkO7wQqm84HSmobMjMYcDblq7xozm8IcEhNMdZWY0VTLjKZaoGnM9SKCbT39BSEyshezqXAXWVff8K6xrj56B7J3jdVWVw3t+hoKk8YcMxqTXsuMdPfY0HT6XJ9zz8VsMnBITBKSaKnP0VKfG3HZ3d2JCLr7BocCJT++kg+UjV29aU8mmX7+91083NHLxq5dj7vU1VQNhUZrw3CATB8KkuHxluF13i1mNtE4JKY4STTUVtNQ28BBrQ0l1e3uG2Bj2kPJh8nG/LhLuiwfPGvWb0vWdfXSN7Dr3WIzGocH8FsbcjTV1dBSX0NTXTVNdTU019XQVFtDc306XVdDc101zXW5pExtDVVV3kVmNh4cErbH6nPVHNRaWrhEBDv6BoYCIx8iwz2Z3nTd8BFj23sG2NbTz7ae/l2OuxRqrE0CpSUNkaa66oJAGQ6XsZTx+TA2lTkkbJ+SRGNtDY21NcybXlrPJSLo6R9kW08/23v62dqdPG/v7WdbzwDbe/rZ1t0/tH57b0GZngHWbepOyqZlenaxu6xQbXUVLfU1TGvIMS3/3JBjWn2OaQ016XPBuvocrQXLPT5j+zOHhO03JFGfq6Y+V83M5rq93l7fwCBdPQNs7ekb6q1szwdQwfS2ngG2dvexpbufLTuSkyzXbdoxNL+7sKmtqdploBQuby2yzuM0VkkOCZuyctVVtDZW0dqY26vtdPcNsLW7n81pgCRBMhwoW3b077S8Y2MXW9JDl3c1RgPJQQCFwZIcoJAGy9CyZL6lyLzHaGxvOCTM9lK+dzOrpfTeTX4XWj5QNhcJlKGgGSqTD5l+tnbvvidTpeSqAnsSMPl592amLoeEWQUV7kKbPa20Ey/zevqTnsyWHckZ+1u6+0bMD+0qS8Nma3cfazft4Mk0jLb19LO74wHqaqpoSYOlpSFHc3oUWeEBAM3p0WdN6dFnow8EyB8c4MDZvzgkzPZzdTXV1DXv+TjN4GAMDfKPJWC2pAcDbNjWVTCOM7DLkzIL5ao1FCTNdcOHNifBMjJsmosE0FDgpEew5Xw9s7JySJhNcVVVwydiHkxpR5wV6u0fTAf6kyPL8oP+2wsOAtjeO3yAQGHAbO3u56XN3QX1B8Z8uHNtdRVNddU0pr2XxjR88odB58+dya9vyq+rraEx7e2MWJer9oU0CzgkzGxc1NZUUVuTv6TM3hl9uPO2NEy2jwqgrp5+tvX209UzwPaC5+09/azf1pNOJ/XGesgzJLvXRgbMcG+nMV2W7800Fjw358NqRAAly6r304MHHBJmNuGM9+HOAP0Dg2zvHaArDY6u3iR8hgKmd2CoZzO0Ll3W1Zv0dl7e0j20vpRdbAD1uaqhcMmHTr5Hkw+kJGBGBU6R3tG+DB6HhJlNCTXVVbQ2VNHasHeHPBfq7R+kqzBgepPeTT6MiofQ8PrC4Mn3hEoJnoZc9VCIHHVQC/90ftu4vbc8h4SZ2R7K72Kb3jh+28wHz4jA6Sno2YzarZZfv6dHx+2OQ8LMbAIpR/DsDQ/hm5lZprKHhKTTJD0l6RlJVxZZf66kR9LHzyUdO9a6ZmZWXmUNCUnVwLXA6cBrgQ9Ieu2oYr8D3hQRrwO+CFxfQl0zMyujcvckTgKeiYg1EdEL3AKcUVggIn4eERvT2V8C88da18zMyqvcITEPeKFgviNdluUjwL2l1JV0oaR2Se2dnZ172VwzMytU7pAodqZH0XPtJZ1KEhJXlFI3Iq6PiLaIaJs1a9YeN9TMzHZW7kNgO4BDCubnA+tGF5L0OuBbwOkRsaGUumZmVj7l7kmsAI6QtFBSLbAUWFZYQNKrgDuB8yPi6VLqmplZeSlibFda3OMXkN4JfA2oBm6IiGskXQQQEddJ+hZwFvBcWqU/Itqy6u7mtToLtrMnZgLr96L+ZOLPYiR/HiP58xg2GT6LQyOi6P76sofE/kRSez6gpjp/FiP58xjJn8ewyf5Z+IxrMzPL5JAwM7NMDomRrq90AyYQfxYj+fMYyZ/HsEn9WXhMwszMMrknYWZmmRwSZmaWySGBL0leSNIhkn4i6QlJqyV9stJtqjRJ1ZL+Q9K/VrotlSZpuqTbJT2Z/h85udJtqiRJl6V/J49J+hdJ5bk9XAVN+ZDwJcl30g/8RUQcBbwB+MQU/zwAPgk8UelGTBBfB+6LiEXAsUzhz0XSPOBSoC0ijiE56XdpZVs1/qZ8SOBLko8QES9GxEPp9FaSL4FdXbl3UpM0H/jPJNcWm9IkTQOWAP8MEBG9EbGpoo2qvBqgQVIN0MgkvL6cQ6L0y5lPGZIWAMcDv6pwUyrpa8BngMEKt2MiOAzoBG5Md799S1JTpRtVKRGxFvh74HngRWBzRDxQ2VaNP4dECZczn0okNQN3AJ+KiC2Vbk8lSHoX8EpErKx0WyaIGuAE4JsRcTywHZiyY3iSZpDsdVgIHAw0STqvsq0afw4JX5J8J5JyJAFxc0TcWen2VNApwHskPUuyG/Itkr5b2SZVVAfQERH5nuXtJKExVf0R8LuI6IyIPpKrWf+nCrdp3DkkfEnyESSJZJ/zExHx1Uq3p5Ii4qqImB8RC0j+X/w4IibdL8WxioiXgBckHZkueivweAWbVGnPA2+Q1Jj+3byVSTiQX+6bDk14EdEv6WLgfoYvSb66ws2qpFOA84FHJa1Kl/3XiLinck2yCeQS4Ob0B9Ua4IIKt6diIuJXkm4HHiI5KvA/mISX6PBlOczMLJN3N5mZWSaHhJmZZXJImJlZJoeEmZllckiYmVkmh4TZBCHpzb7SrE00DgkzM8vkkDArkaTzJP1a0ipJ/5Teb2KbpP8u6SFJP5I0Ky17nKRfSnpE0l3p9X6QdLikf5f0cFrn1enmmwvu13BzeiavWcU4JMxKIOko4BzglIg4DhgAzgWagIci4gTgp8BfpVW+A1wREa8DHi1YfjNwbUQcS3K9nxfT5ccDnyK5t8lhJGfAm1XMlL8sh1mJ3gq8HliR/shvAF4huZT4rWmZ7wJ3SmoFpkfET9Pl3wa+L6kFmBcRdwFERDdAur1fR0RHOr8KWAA8WPZ3ZZbBIWFWGgHfjoirRiyUPjeq3K6ud7OrXUg9BdMD+G/UKsy7m8xK8yPgbEmzASQdIOlQkr+ls9MyHwQejIjNwEZJb0yXnw/8NL0/R4ek96bbqJPUuC/fhNlY+VeKWQki4nFJfwk8IKkK6AM+QXIDnqMlrQQ2k4xbAPwJcF0aAoVXTT0f+CdJX0i38cf78G2YjZmvAms2DiRti4jmSrfDbLx5d5OZmWVyT8LMzDK5J2FmZpkcEmZmlskhYWZmmRwSZmaWySFhZmaZ/j/Y6IfSsTNISQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_dot_3.history['loss'] \n",
    "val_loss = history_dot_3.history['val_loss'] \n",
    "epoch = 10\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/val_loss')\n",
    "plt.title('Learning')\n",
    "plt.plot(range(epoch), loss, label = \"loss\")\n",
    "plt.plot(range(epoch), val_loss, label = \"val_loss\") \n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for 10 epochs more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2065\n",
      "Epoch 1: val_loss did not improve from 0.47757\n",
      "2205/2205 [==============================] - 408s 185ms/step - loss: 0.2065 - val_loss: 0.4807\n",
      "Epoch 2/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2040\n",
      "Epoch 2: val_loss did not improve from 0.47757\n",
      "2205/2205 [==============================] - 383s 174ms/step - loss: 0.2040 - val_loss: 0.4840\n",
      "Epoch 3/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2017\n",
      "Epoch 3: val_loss did not improve from 0.47757\n",
      "2205/2205 [==============================] - 392s 178ms/step - loss: 0.2017 - val_loss: 0.4850\n",
      "Epoch 4/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.1999\n",
      "Epoch 4: val_loss did not improve from 0.47757\n",
      "2205/2205 [==============================] - 392s 178ms/step - loss: 0.1999 - val_loss: 0.4810\n",
      "Epoch 5/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.1975\n",
      "Epoch 5: val_loss improved from 0.47757 to 0.47269, saving model to model_save_attention_dot\\weights-05-0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-05-0.47\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_dot\\weights-05-0.47\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C6FF4E1B20> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C691DC74F0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C69317A3A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 431s 195ms/step - loss: 0.1975 - val_loss: 0.4727\n",
      "Epoch 6/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.1959\n",
      "Epoch 6: val_loss did not improve from 0.47269\n",
      "2205/2205 [==============================] - 413s 187ms/step - loss: 0.1959 - val_loss: 0.4774\n",
      "Epoch 7/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.1939\n",
      "Epoch 7: val_loss did not improve from 0.47269\n",
      "2205/2205 [==============================] - 407s 184ms/step - loss: 0.1939 - val_loss: 0.4791\n",
      "Epoch 8/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.1923\n",
      "Epoch 8: val_loss did not improve from 0.47269\n",
      "2205/2205 [==============================] - 425s 193ms/step - loss: 0.1923 - val_loss: 0.4820\n",
      "Epoch 9/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.1905\n",
      "Epoch 9: val_loss did not improve from 0.47269\n",
      "2205/2205 [==============================] - 383s 174ms/step - loss: 0.1905 - val_loss: 0.4760\n",
      "Epoch 10/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.1888\n",
      "Epoch 10: val_loss did not improve from 0.47269\n",
      "2205/2205 [==============================] - 382s 173ms/step - loss: 0.1888 - val_loss: 0.4770\n"
     ]
    }
   ],
   "source": [
    "history_dot_4 = model_attention_dot.fit(train_dataloader, steps_per_epoch=train_steps, epochs=10, validation_data=test_dataloader, validation_steps=valid_steps,\n",
    "                   callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST Loss:0.47 in 50 EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2c8817b9130>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_dot_4.history['loss'] \n",
    "val_loss = history_dot_4.history['val_loss'] \n",
    "epoch = 10\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/val_loss')\n",
    "plt.title('Learning')\n",
    "plt.plot(range(epoch), loss, label = \"loss\")\n",
    "plt.plot(range(epoch), val_loss, label = \"val_loss\") \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder_Decoder_Attention_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encode_model_Attention (Enc  multiple                 2487124   \n",
      " oder)                                                           \n",
      "                                                                 \n",
      " Decode_Attention (Decoder)  multiple                  10374360  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,861,484\n",
      "Trainable params: 11,527,324\n",
      "Non-trainable params: 1,334,160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_attention_dot.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_ita = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DpC9zlzMcXp"
   },
   "source": [
    "## <font color='blue'>**Inference**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5NhESYyMW_t"
   },
   "source": [
    "<font color='blue'>**Plot attention weights**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    sentence = sentence.split(\" \")\n",
    "    predicted_sentence = predicted_sentence.split(\" \")\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkEY7SsBMtrC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1IhdBrgQYJr"
   },
   "source": [
    "<font color='blue'>**Predict the sentence translation**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "MP3kLZoPMvSu"
   },
   "outputs": [],
   "source": [
    "def predict_dot(input_test_sentence):\n",
    "\n",
    "    '''\n",
    "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "    E. Call plot_attention(#params)\n",
    "    F. Return the predicted sentence\n",
    "    '''\n",
    "    ENCODER_SEQ_LEN = 22\n",
    "    DECODER_SEQ_LEN = 25\n",
    "    max_len_ita = 22\n",
    "    nums = tknizer_ita.texts_to_sequences([input_test_sentence])\n",
    "    nums_padded = pad_sequences(nums, maxlen=max_len_ita, dtype='int32', padding='post')\n",
    "    encoder_output, enc_state_h, enc_state_c = model_attention_dot.layers[0](nums_padded)\n",
    "    pred, alphas = [], []\n",
    "    cur_vec = np.zeros((1, 1))\n",
    "    osd = model_attention_dot.layers[1].onestepdecoder\n",
    "    for i in range(DECODER_SEQ_LEN):\n",
    "        \n",
    "        \n",
    "        output, state_h, state_c, attention_weights, context_vector = osd(cur_vec, encoder_output, enc_state_h, enc_state_c )\n",
    "        \n",
    "        enc_state_h, enc_state_c = state_h, state_c\n",
    "        alphas.append(attention_weights.numpy().flatten())\n",
    "        \n",
    "        \n",
    "        cur_vec = np.reshape(np.argmax(output), (1, 1))\n",
    "        print(f\"at time step {i} the word is \", cur_vec)\n",
    "        \n",
    "        if english_dict[cur_vec[0][0]] == '<end>':\n",
    "            break\n",
    "        pred.append(cur_vec)\n",
    "        \n",
    "        \n",
    "     \n",
    "    pred_string = \"\"\n",
    "\n",
    "    pred_string = \" \".join([ english_dict[i[0][0]] for i in pred])\n",
    "    \n",
    "    print(\"PREDICTED STRING:\",pred_string)\n",
    "    \n",
    "   \n",
    "    \n",
    "    plot_attention(alphas, input_test_sentence, pred_string)\n",
    "    \n",
    "    return  input_test_sentence, pred_string\n",
    "    \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at time step 0 the word is  [[4]]\n",
      "at time step 1 the word is  [[618]]\n",
      "at time step 2 the word is  [[9]]\n",
      "at time step 3 the word is  [[2381]]\n",
      "at time step 4 the word is  [[10289]]\n",
      "PREDICTED STRING: tom needed a fuji\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_sentence: tom aveva bisogno di un martello\n",
      "English predict: tom needed a fuji\n",
      "English actual: tom needed a hammer\n"
     ]
    }
   ],
   "source": [
    "index = 2010\n",
    "input_test_sentence = validation[\"italian\"].values[index]\n",
    "actual = validation[\"english_out\"].values[index]\n",
    "input_sentence, pred_string = predict_dot(input_test_sentence)\n",
    "import re\n",
    "print(f\"Input_sentence: {input_sentence}\")\n",
    "print(f\"English predict: {pred_string}\")\n",
    "print(f\"English actual: {re.sub('<end>', '', actual).strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    " from termcolor import colored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmxIVOOQPWMu"
   },
   "source": [
    "<font color='blue'>**Calculate BLEU score**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "0iHiLdROM23l",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTED STRING: she is a prude\n",
      "ACTUAL STRING: you are a teacher\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: are not you going to eat it\n",
      "ACTUAL STRING: are not you going to eat it\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i would like to clean the cold time that time takes me to waste the house\n",
      "ACTUAL STRING: i would like to drastically decrease the amount of time it takes me to clean the house\n",
      "BL880EU score: \u001b[1m\u001b[31m0.29\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i think you are selfish\n",
      "ACTUAL STRING: i think you are selfish\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: it will be fun to have somebody to play with\n",
      "ACTUAL STRING: it will be fun to have somebody to play with\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tell tom that i do not care\n",
      "ACTUAL STRING: tell tom i do not care\n",
      "BL880EU score: \u001b[1m\u001b[31m0.49\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: pick up his clothes\n",
      "ACTUAL STRING: pick your toys up\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom is not interested\n",
      "ACTUAL STRING: tom is not interested\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom and mary are not canadian\n",
      "ACTUAL STRING: tom and mary are not canadians\n",
      "BL880EU score: \u001b[1m\u001b[32m0.7598356856515925\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: how do you think me\n",
      "ACTUAL STRING: how do you think i feel\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5475182535069453\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i do not want to take the fuji\n",
      "ACTUAL STRING: i do not want to take risks\n",
      "BL880EU score: \u001b[1m\u001b[32m0.6803749333171202\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i thought that tom would find that interesting\n",
      "ACTUAL STRING: i thought tom would find that interesting\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5946035575013605\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom broke mary is record\n",
      "ACTUAL STRING: tom broke mary is clarinet\n",
      "BL880EU score: \u001b[1m\u001b[32m0.668740304976422\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: he is going to play golf next sunday\n",
      "ACTUAL STRING: he will play golf next sunday\n",
      "BL880EU score: \u001b[1m\u001b[31m0.37\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: everyone laughed but tom\n",
      "ACTUAL STRING: everyone but tom laughed\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: we are to believe\n",
      "ACTUAL STRING: we are ruined\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i was there\n",
      "ACTUAL STRING: i was dazzled\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: two students are expecting today\n",
      "ACTUAL STRING: two students are absent today\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i have a lot of questions\n",
      "ACTUAL STRING: i have got a lot of questions\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5115078115793242\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom is from his job\n",
      "ACTUAL STRING: tom is absorbed in his work\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: do not make things\n",
      "ACTUAL STRING: do not mess things up\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: can you explain something to me\n",
      "ACTUAL STRING: can you explain something to me\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i am not able to do that\n",
      "ACTUAL STRING: i am unable to do it\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: do you still do that\n",
      "ACTUAL STRING: do it again\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: my uncle lived a dead happy and died a dead of new dead\n",
      "ACTUAL STRING: my uncle lived a happy life and died a peaceful death\n",
      "BL880EU score: \u001b[1m\u001b[31m0.29\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i have a lot more books than you do\n",
      "ACTUAL STRING: i have a lot more books than you do\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: we are not sure yet\n",
      "ACTUAL STRING: we are still not sure\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: the students laughed at each other\n",
      "ACTUAL STRING: the students all laughed\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i met tom at a party\n",
      "ACTUAL STRING: i met tom at a party\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: you are interested in the computer\n",
      "ACTUAL STRING: you are interested in computers\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5081327481546147\u001b[0m\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#Create an object of your custom model.\n",
    "#Compile and train your model on dot scoring function.\n",
    "# Visualize few sentences randomly in Test data\n",
    "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
    "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "\n",
    "#Sample example\n",
    "import nltk.translate.bleu_score as bleu\n",
    "test_it = validation[\"italian\"].values[30:60]\n",
    "test_eng = validation[\"english_out\"].apply(lambda a:re.sub('<end>', '', a).strip()).values[30:60]\n",
    "for i in range(30):\n",
    "    input_test_sentence = test_it[i]\n",
    "    input_sentence, pred_string = predict_dot(input_test_sentence)\n",
    "    print(f\"ACTUAL STRING: {test_eng[i]}\")\n",
    "    reference = [test_eng[i].split()] # the original\n",
    "    translation = pred_string.split() # trasilated using model\n",
    "    bs = bleu.sentence_bleu(reference, translation)\n",
    "    print(f'BL880EU score: {colored(bs, \"green\", attrs=[\"bold\"]) if 0.5<=bs<=1 else colored(round(bs, 2), \"red\", attrs=[\"bold\"])}')\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:57<00:00, 17.26it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "test_it = validation[\"italian\"].values[:1000]\n",
    "test_eng = validation[\"english_out\"].apply(lambda a:re.sub('<end>', '', a).strip()).values[:1000]\n",
    "bss = []\n",
    "for i in tqdm(range(1000)):\n",
    "    input_test_sentence = test_it[i]\n",
    "    input_sentence, pred_string = predict_dot(input_test_sentence)\n",
    "    reference = [test_eng[i].split()] # the original\n",
    "    translation = pred_string.split() # trasilated using model\n",
    "    bs = bleu.sentence_bleu(reference, translation)\n",
    "    bss.append(bs)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVG. BLUE score : 0.498"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49806404774972274"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL-2 with general score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWg2ferDQvT3"
   },
   "source": [
    "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "4Rh9_w79M5JO",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 1.5497\n",
      "Epoch 1: val_loss improved from inf to 1.21391, saving model to model_save_attention_general\\weights-01-1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-01-1.21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-01-1.21\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 527s 224ms/step - loss: 1.5497 - val_loss: 1.2139\n",
      "Epoch 2/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.8961\n",
      "Epoch 2: val_loss improved from 1.21391 to 0.96842, saving model to model_save_attention_general\\weights-02-0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-02-0.97\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-02-0.97\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 492s 223ms/step - loss: 0.8961 - val_loss: 0.9684\n",
      "Epoch 3/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.7303\n",
      "Epoch 3: val_loss improved from 0.96842 to 0.82565, saving model to model_save_attention_general\\weights-03-0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-03-0.83\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-03-0.83\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 499s 226ms/step - loss: 0.7303 - val_loss: 0.8256\n",
      "Epoch 4/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.6382\n",
      "Epoch 4: val_loss improved from 0.82565 to 0.74394, saving model to model_save_attention_general\\weights-04-0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-04-0.74\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-04-0.74\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 495s 225ms/step - loss: 0.6382 - val_loss: 0.7439\n",
      "Epoch 5/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.5743\n",
      "Epoch 5: val_loss improved from 0.74394 to 0.68864, saving model to model_save_attention_general\\weights-05-0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-05-0.69\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-05-0.69\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 492s 223ms/step - loss: 0.5743 - val_loss: 0.6886\n",
      "Epoch 6/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.5266\n",
      "Epoch 6: val_loss improved from 0.68864 to 0.65106, saving model to model_save_attention_general\\weights-06-0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-06-0.65\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-06-0.65\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 490s 222ms/step - loss: 0.5266 - val_loss: 0.6511\n",
      "Epoch 7/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.4845\n",
      "Epoch 7: val_loss improved from 0.65106 to 0.60947, saving model to model_save_attention_general\\weights-07-0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-07-0.61\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-07-0.61\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 492s 223ms/step - loss: 0.4845 - val_loss: 0.6095\n",
      "Epoch 8/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.4471\n",
      "Epoch 8: val_loss improved from 0.60947 to 0.58340, saving model to model_save_attention_general\\weights-08-0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-08-0.58\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-08-0.58\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 490s 222ms/step - loss: 0.4471 - val_loss: 0.5834\n",
      "Epoch 9/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.4176\n",
      "Epoch 9: val_loss improved from 0.58340 to 0.57578, saving model to model_save_attention_general\\weights-09-0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-09-0.58\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-09-0.58\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 488s 222ms/step - loss: 0.4176 - val_loss: 0.5758\n",
      "Epoch 10/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3939\n",
      "Epoch 10: val_loss improved from 0.57578 to 0.55298, saving model to model_save_attention_general\\weights-10-0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-10-0.55\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-10-0.55\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 493s 223ms/step - loss: 0.3939 - val_loss: 0.5530\n",
      "Epoch 11/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3729\n",
      "Epoch 11: val_loss improved from 0.55298 to 0.53805, saving model to model_save_attention_general\\weights-11-0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-11-0.54\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-11-0.54\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 491s 223ms/step - loss: 0.3729 - val_loss: 0.5380\n",
      "Epoch 12/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3555\n",
      "Epoch 12: val_loss improved from 0.53805 to 0.51947, saving model to model_save_attention_general\\weights-12-0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-12-0.52\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-12-0.52\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 489s 222ms/step - loss: 0.3555 - val_loss: 0.5195\n",
      "Epoch 13/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3416\n",
      "Epoch 13: val_loss did not improve from 0.51947\n",
      "2205/2205 [==============================] - 455s 206ms/step - loss: 0.3416 - val_loss: 0.5221\n",
      "Epoch 14/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3279\n",
      "Epoch 14: val_loss improved from 0.51947 to 0.51134, saving model to model_save_attention_general\\weights-14-0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-14-0.51\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-14-0.51\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 516s 234ms/step - loss: 0.3279 - val_loss: 0.5113\n",
      "Epoch 15/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3162\n",
      "Epoch 15: val_loss improved from 0.51134 to 0.50922, saving model to model_save_attention_general\\weights-15-0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-15-0.51\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-15-0.51\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 525s 238ms/step - loss: 0.3162 - val_loss: 0.5092\n",
      "Epoch 16/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3058\n",
      "Epoch 16: val_loss improved from 0.50922 to 0.49716, saving model to model_save_attention_general\\weights-16-0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-16-0.50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-16-0.50\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 523s 237ms/step - loss: 0.3058 - val_loss: 0.4972\n",
      "Epoch 17/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2958\n",
      "Epoch 17: val_loss did not improve from 0.49716\n",
      "2205/2205 [==============================] - 485s 220ms/step - loss: 0.2958 - val_loss: 0.4987\n",
      "Epoch 18/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2878\n",
      "Epoch 18: val_loss did not improve from 0.49716\n",
      "2205/2205 [==============================] - 456s 207ms/step - loss: 0.2878 - val_loss: 0.5003\n",
      "Epoch 19/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2805\n",
      "Epoch 19: val_loss improved from 0.49716 to 0.48684, saving model to model_save_attention_general\\weights-19-0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-19-0.49\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-19-0.49\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 500s 227ms/step - loss: 0.2805 - val_loss: 0.4868\n",
      "Epoch 20/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2733\n",
      "Epoch 20: val_loss improved from 0.48684 to 0.48045, saving model to model_save_attention_general\\weights-20-0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-20-0.48\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-20-0.48\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 493s 224ms/step - loss: 0.2733 - val_loss: 0.4804\n",
      "Epoch 21/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2669\n",
      "Epoch 21: val_loss did not improve from 0.48045\n",
      "2205/2205 [==============================] - 468s 212ms/step - loss: 0.2669 - val_loss: 0.4886\n",
      "Epoch 22/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2616\n",
      "Epoch 22: val_loss did not improve from 0.48045\n",
      "2205/2205 [==============================] - 465s 211ms/step - loss: 0.2616 - val_loss: 0.4932\n",
      "Epoch 23/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2566\n",
      "Epoch 23: val_loss improved from 0.48045 to 0.47377, saving model to model_save_attention_general\\weights-23-0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-23-0.47\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-23-0.47\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 494s 224ms/step - loss: 0.2566 - val_loss: 0.4738\n",
      "Epoch 24/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2517\n",
      "Epoch 24: val_loss improved from 0.47377 to 0.47236, saving model to model_save_attention_general\\weights-24-0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-24-0.47\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-24-0.47\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F6E550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C8D3E8EA30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C8A99D6310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 501s 227ms/step - loss: 0.2517 - val_loss: 0.4724\n",
      "Epoch 25/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2468\n",
      "Epoch 25: val_loss did not improve from 0.47236\n",
      "2205/2205 [==============================] - 459s 208ms/step - loss: 0.2468 - val_loss: 0.4727\n",
      "Epoch 26/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2422\n",
      "Epoch 26: val_loss did not improve from 0.47236\n",
      "2205/2205 [==============================] - 478s 217ms/step - loss: 0.2422 - val_loss: 0.4839\n",
      "Epoch 27/30\n",
      "1807/2205 [=======================>......] - ETA: 1:19 - loss: 0.2379"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13000/3019707606.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mvalid_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m history_gen = model_attention_general.fit(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data=test_dataloader, validation_steps=valid_steps,\n\u001b[0m\u001b[0;32m     13\u001b[0m                    callbacks=[checkpoint])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "model_attention_general = encoder_decoder(vocab_size_ita+1,vocab_size_eng+1,22,25,512,\"general\",512)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model_attention_general.compile(optimizer=optimizer,loss=loss_function)\n",
    "train_steps=train.shape[0]//128\n",
    "valid_steps=validation.shape[0]//128\n",
    "history_gen = model_attention_general.fit(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data=test_dataloader, validation_steps=valid_steps,\n",
    "                   callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17b758d3a30>"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_gen.history['loss']\n",
    "# acc = history.history['acc']\n",
    "val_loss = history_gen.history['val_loss']\n",
    "# val_acc = history.history['val_acc'] \n",
    "# val_iou_score = history.history['val_iou_score']\n",
    "# iou_score = history.history['iou_score']\n",
    "epoch = 30\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/val_loss')\n",
    "plt.title('Learning')\n",
    "plt.plot(range(epoch), loss, label = \"loss\")\n",
    "plt.plot(range(epoch), val_loss, label = \"val_loss\")\n",
    "# plt.plot(range(epoch), acc, label = \"acc\")\n",
    "# plt.plot(range(epoch), iou_score, label = \"iou_score\")\n",
    "# plt.plot(range(epoch), val_iou_score, label = \"val_iou_score\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 20 epochs more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "history_gen_2 = model_attention_general.fit(train_dataloader, steps_per_epoch=train_steps, epochs=20, validation_data=test_dataloader, validation_steps=valid_steps,\n",
    "                   callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17842c42d30>"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_gen_2.history['loss']\n",
    "# acc = history.history['acc']\n",
    "val_loss = history_gen_2.history['val_loss']\n",
    "# val_acc = history.history['val_acc'] \n",
    "# val_iou_score = history.history['val_iou_score']\n",
    "# iou_score = history.history['iou_score']\n",
    "epoch = 20\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/val_loss')\n",
    "plt.title('Learning')\n",
    "plt.plot(range(epoch), loss, label = \"loss\")\n",
    "plt.plot(range(epoch), val_loss, label = \"val_loss\")\n",
    "# plt.plot(range(epoch), acc, label = \"acc\")\n",
    "# plt.plot(range(epoch), iou_score, label = \"iou_score\")\n",
    "# plt.plot(range(epoch), val_iou_score, label = \"val_iou_score\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 10 epochs more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3705\n",
      "Epoch 1: val_loss did not improve from 0.63198\n",
      "2940/2940 [==============================] - 399s 136ms/step - loss: 0.3705 - val_loss: 0.6346\n",
      "Epoch 2/10\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3690\n",
      "Epoch 2: val_loss improved from 0.63198 to 0.63049, saving model to model_save_attention_general\\weights-02-0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_243_layer_call_fn, lstm_cell_243_layer_call_and_return_conditional_losses, dense_753_layer_call_fn, dense_753_layer_call_and_return_conditional_losses, lstm_cell_244_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-02-0.63\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-02-0.63\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000017AA03C7AF0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x0000017AA03C7340> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000017AA0427CA0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 438s 149ms/step - loss: 0.3690 - val_loss: 0.6305\n",
      "Epoch 3/10\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3676\n",
      "Epoch 3: val_loss did not improve from 0.63049\n",
      "2940/2940 [==============================] - 403s 137ms/step - loss: 0.3676 - val_loss: 0.6367\n",
      "Epoch 4/10\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3655\n",
      "Epoch 4: val_loss improved from 0.63049 to 0.62991, saving model to model_save_attention_general\\weights-04-0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_243_layer_call_fn, lstm_cell_243_layer_call_and_return_conditional_losses, dense_753_layer_call_fn, dense_753_layer_call_and_return_conditional_losses, lstm_cell_244_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-04-0.63\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-04-0.63\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000017AA03C7AF0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x0000017AA03C7340> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000017AA0427CA0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 471s 160ms/step - loss: 0.3655 - val_loss: 0.6299\n",
      "Epoch 5/10\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3642\n",
      "Epoch 5: val_loss did not improve from 0.62991\n",
      "2940/2940 [==============================] - 415s 141ms/step - loss: 0.3642 - val_loss: 0.6318\n",
      "Epoch 6/10\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3620\n",
      "Epoch 6: val_loss did not improve from 0.62991\n",
      "2940/2940 [==============================] - 409s 139ms/step - loss: 0.3620 - val_loss: 0.6352\n",
      "Epoch 7/10\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3602\n",
      "Epoch 7: val_loss did not improve from 0.62991\n",
      "2940/2940 [==============================] - 410s 139ms/step - loss: 0.3602 - val_loss: 0.6410\n",
      "Epoch 8/10\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3588\n",
      "Epoch 8: val_loss did not improve from 0.62991\n",
      "2940/2940 [==============================] - 406s 138ms/step - loss: 0.3588 - val_loss: 0.6309\n",
      "Epoch 9/10\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3569\n",
      "Epoch 9: val_loss did not improve from 0.62991\n",
      "2940/2940 [==============================] - 407s 138ms/step - loss: 0.3569 - val_loss: 0.6330\n",
      "Epoch 10/10\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3556\n",
      "Epoch 10: val_loss improved from 0.62991 to 0.62400, saving model to model_save_attention_general\\weights-10-0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_243_layer_call_fn, lstm_cell_243_layer_call_and_return_conditional_losses, dense_753_layer_call_fn, dense_753_layer_call_and_return_conditional_losses, lstm_cell_244_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-10-0.62\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-10-0.62\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000017AA03C7AF0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x0000017AA03C7340> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000017AA0427CA0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2940/2940 [==============================] - 450s 153ms/step - loss: 0.3556 - val_loss: 0.6240\n"
     ]
    }
   ],
   "source": [
    "history_gen_3 = model_attention_general.fit(train_dataloader, steps_per_epoch=train_steps, epochs=10, validation_data=test_dataloader, validation_steps=valid_steps,\n",
    "                   callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17a371c50d0>"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_gen_3.history['loss']\n",
    "# acc = history.history['acc']\n",
    "val_loss = history_gen_3.history['val_loss']\n",
    "# val_acc = history.history['val_acc'] \n",
    "# val_iou_score = history.history['val_iou_score']\n",
    "# iou_score = history.history['iou_score']\n",
    "epoch = 10\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/val_loss')\n",
    "plt.title('Learning')\n",
    "plt.plot(range(epoch), loss, label = \"loss\")\n",
    "plt.plot(range(epoch), val_loss, label = \"val_loss\")\n",
    "# plt.plot(range(epoch), acc, label = \"acc\")\n",
    "# plt.plot(range(epoch), iou_score, label = \"iou_score\")\n",
    "# plt.plot(range(epoch), val_iou_score, label = \"val_iou_score\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now  interrupting 14/20, as its not learning anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3538\n",
      "Epoch 1: val_loss did not improve from 0.62400\n",
      "2940/2940 [==============================] - 413s 141ms/step - loss: 0.3538 - val_loss: 0.6345\n",
      "Epoch 2/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3519\n",
      "Epoch 2: val_loss did not improve from 0.62400\n",
      "2940/2940 [==============================] - 407s 138ms/step - loss: 0.3519 - val_loss: 0.6241\n",
      "Epoch 3/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3511\n",
      "Epoch 3: val_loss did not improve from 0.62400\n",
      "2940/2940 [==============================] - 427s 145ms/step - loss: 0.3511 - val_loss: 0.6266\n",
      "Epoch 4/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3498\n",
      "Epoch 4: val_loss did not improve from 0.62400\n",
      "2940/2940 [==============================] - 415s 141ms/step - loss: 0.3498 - val_loss: 0.6395\n",
      "Epoch 5/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3484\n",
      "Epoch 5: val_loss did not improve from 0.62400\n",
      "2940/2940 [==============================] - 422s 144ms/step - loss: 0.3484 - val_loss: 0.6327\n",
      "Epoch 6/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3471\n",
      "Epoch 6: val_loss did not improve from 0.62400\n",
      "2940/2940 [==============================] - 432s 147ms/step - loss: 0.3471 - val_loss: 0.6240\n",
      "Epoch 7/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3457\n",
      "Epoch 7: val_loss did not improve from 0.62400\n",
      "2940/2940 [==============================] - 434s 148ms/step - loss: 0.3457 - val_loss: 0.6273\n",
      "Epoch 8/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3445\n",
      "Epoch 8: val_loss improved from 0.62400 to 0.62217, saving model to model_save_attention_general\\weights-08-0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_243_layer_call_fn, lstm_cell_243_layer_call_and_return_conditional_losses, dense_753_layer_call_fn, dense_753_layer_call_and_return_conditional_losses, lstm_cell_244_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-08-0.62\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_general\\weights-08-0.62\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000017AA03C7AF0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x0000017AA03C7340> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000017AA0427CA0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940/2940 [==============================] - 515s 175ms/step - loss: 0.3445 - val_loss: 0.6222\n",
      "Epoch 9/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3435\n",
      "Epoch 9: val_loss did not improve from 0.62217\n",
      "2940/2940 [==============================] - 422s 143ms/step - loss: 0.3435 - val_loss: 0.6329\n",
      "Epoch 10/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3424\n",
      "Epoch 10: val_loss did not improve from 0.62217\n",
      "2940/2940 [==============================] - 433s 147ms/step - loss: 0.3424 - val_loss: 0.6356\n",
      "Epoch 11/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3415\n",
      "Epoch 11: val_loss did not improve from 0.62217\n",
      "2940/2940 [==============================] - 418s 142ms/step - loss: 0.3415 - val_loss: 0.6241\n",
      "Epoch 12/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3405\n",
      "Epoch 12: val_loss did not improve from 0.62217\n",
      "2940/2940 [==============================] - 400s 136ms/step - loss: 0.3405 - val_loss: 0.6235\n",
      "Epoch 13/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3397\n",
      "Epoch 13: val_loss did not improve from 0.62217\n",
      "2940/2940 [==============================] - 423s 144ms/step - loss: 0.3397 - val_loss: 0.6264\n",
      "Epoch 14/20\n",
      "2940/2940 [==============================] - ETA: 0s - loss: 0.3388"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6588/4000934598.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history_gen_4 = model_attention_general.fit(train_dataloader, steps_per_epoch=train_steps, epochs=20, validation_data=test_dataloader, validation_steps=valid_steps,\n\u001b[0m\u001b[0;32m      2\u001b[0m                    callbacks=[checkpoint])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1418\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1420\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1421\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1714\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1716\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1717\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_gen_4 = model_attention_general.fit(train_dataloader, steps_per_epoch=train_steps, epochs=20, validation_data=test_dataloader, validation_steps=valid_steps,\n",
    "                   callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST Loss:0.62 in 74 EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gen(input_sentence):\n",
    "\n",
    "    '''\n",
    "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "    E. Call plot_attention(#params)\n",
    "    F. Return the predicted sentence\n",
    "    '''\n",
    "    ENCODER_SEQ_LEN = 22\n",
    "    DECODER_SEQ_LEN = 25\n",
    "    max_len_ita = 22\n",
    "    nums = tknizer_ita.texts_to_sequences([input_test_sentence])\n",
    "    nums_padded = pad_sequences(nums, maxlen=max_len_ita, dtype='int32', padding='post')\n",
    "    encoder_output, enc_state_h, enc_state_c = model_attention_general.layers[0](nums_padded)\n",
    "    pred, alphas = [], []\n",
    "    cur_vec = np.zeros((1, 1))\n",
    "    osd = model_attention_general.layers[1].onestepdecoder\n",
    "    for i in range(DECODER_SEQ_LEN):\n",
    "        \n",
    "        \n",
    "        output, state_h, state_c, attention_weights, context_vector = osd(cur_vec, encoder_output, enc_state_h, enc_state_c )\n",
    "        \n",
    "        enc_state_h, enc_state_c = state_h, state_c\n",
    "        alphas.append(attention_weights.numpy().flatten())\n",
    "        \n",
    "        \n",
    "        cur_vec = np.reshape(np.argmax(output), (1, 1))\n",
    "        print(f\"at time step {i} the word is \", cur_vec)\n",
    "        \n",
    "        if english_dict[cur_vec[0][0]] == '<end>':\n",
    "            break\n",
    "        pred.append(cur_vec)\n",
    "        \n",
    "        \n",
    "     \n",
    "    pred_string = \"\"\n",
    "\n",
    "    pred_string = \" \".join([ english_dict[i[0][0]] for i in pred])\n",
    "    \n",
    "    print(\"PREDICTED STRING:\",pred_string)\n",
    "    \n",
    "    \n",
    "    plot_attention(alphas, input_sentence, pred_string)\n",
    "    \n",
    "    return  input_sentence, pred_string\n",
    "    \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at time step 0 the word is  [[4]]\n",
      "at time step 1 the word is  [[6]]\n",
      "at time step 2 the word is  [[8]]\n",
      "at time step 3 the word is  [[193]]\n",
      "at time step 4 the word is  [[23]]\n",
      "at time step 5 the word is  [[82]]\n",
      "at time step 6 the word is  [[10289]]\n",
      "PREDICTED STRING: tom is the father of her\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_sentence: è il padre di tom\n",
      "English predict: tom is the father of her\n",
      "English actual: that is tom is father\n"
     ]
    }
   ],
   "source": [
    "index = 200\n",
    "input_test_sentence = validation[\"italian\"].values[index]\n",
    "actual = validation[\"english_out\"].values[index]\n",
    "input_sentence, pred_string = predict_gen(input_test_sentence)\n",
    "import re\n",
    "print(f\"Input_sentence: {input_sentence}\")\n",
    "print(f\"English predict: {pred_string}\")\n",
    "print(f\"English actual: {re.sub('<end>', '', actual).strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTED STRING: she is a teacher\n",
      "ACTUAL STRING: you are a teacher\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: are not you going to eat\n",
      "ACTUAL STRING: are not you going to eat it\n",
      "BL880EU score: \u001b[1m\u001b[32m0.846481724890614\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i would like to see up the world the world it must continue to clean myself\n",
      "ACTUAL STRING: i would like to drastically decrease the amount of time it takes me to clean the house\n",
      "BL880EU score: \u001b[1m\u001b[31m0.19\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i think you are right\n",
      "ACTUAL STRING: i think you are selfish\n",
      "BL880EU score: \u001b[1m\u001b[32m0.668740304976422\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: it will be fun to have somebody to play with\n",
      "ACTUAL STRING: it will be fun to have somebody to play with\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i do not think tom\n",
      "ACTUAL STRING: tell tom i do not care\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: pick up your smile\n",
      "ACTUAL STRING: pick your toys up\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom is not interested\n",
      "ACTUAL STRING: tom is not interested\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom and mary are not married\n",
      "ACTUAL STRING: tom and mary are not canadians\n",
      "BL880EU score: \u001b[1m\u001b[32m0.7598356856515925\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: how do you think it happened\n",
      "ACTUAL STRING: how do you think i feel\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5081327481546147\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i do not want to take out of the offer\n",
      "ACTUAL STRING: i do not want to take risks\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5169731539571706\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i thought that tom would find that interesting\n",
      "ACTUAL STRING: i thought tom would find that interesting\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5946035575013605\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom broke mary is neighbor\n",
      "ACTUAL STRING: tom broke mary is clarinet\n",
      "BL880EU score: \u001b[1m\u001b[32m0.668740304976422\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: he is going to play golf next sunday\n",
      "ACTUAL STRING: he will play golf next sunday\n",
      "BL880EU score: \u001b[1m\u001b[31m0.37\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: everyone laughed over tom\n",
      "ACTUAL STRING: everyone but tom laughed\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: we are later\n",
      "ACTUAL STRING: we are ruined\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i was there\n",
      "ACTUAL STRING: i was dazzled\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: two students are living today\n",
      "ACTUAL STRING: two students are absent today\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i have a lot of questions\n",
      "ACTUAL STRING: i have got a lot of questions\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5115078115793242\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom is out of his work\n",
      "ACTUAL STRING: tom is absorbed in his work\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: things do not need\n",
      "ACTUAL STRING: do not mess things up\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: can you explain something to me\n",
      "ACTUAL STRING: can you explain something to me\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i am not able to do it\n",
      "ACTUAL STRING: i am unable to do it\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: do you still do that\n",
      "ACTUAL STRING: do it again\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom is living a dead or a dead and live\n",
      "ACTUAL STRING: my uncle lived a happy life and died a peaceful death\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i have a lot more books than you do\n",
      "ACTUAL STRING: i have a lot more books than you do\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: we are still not sure\n",
      "ACTUAL STRING: we are still not sure\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: the music all laughed\n",
      "ACTUAL STRING: the students all laughed\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i met tom at a party\n",
      "ACTUAL STRING: i met tom at a party\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: you are interested in the computer\n",
      "ACTUAL STRING: you are interested in computers\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5081327481546147\u001b[0m\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import nltk.translate.bleu_score as bleu\n",
    "test_it = validation[\"italian\"].values[30:60]\n",
    "test_eng = validation[\"english_out\"].apply(lambda a:re.sub('<end>', '', a).strip()).values[30:60]\n",
    "for i in range(30):\n",
    "    input_test_sentence = test_it[i]\n",
    "    input_sentence, pred_string = predict_gen(input_test_sentence)\n",
    "    print(f\"ACTUAL STRING: {test_eng[i]}\")\n",
    "    reference = [test_eng[i].split()] # the original\n",
    "    translation = pred_string.split() # trasilated using model\n",
    "    bs = bleu.sentence_bleu(reference, translation)\n",
    "    print(f'BL880EU score: {colored(bs, \"green\", attrs=[\"bold\"]) if 0.5<=bs<=1 else colored(round(bs, 2), \"red\", attrs=[\"bold\"])}')\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:11<00:00, 14.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "test_it = validation[\"italian\"].values[:1000]\n",
    "test_eng = validation[\"english_out\"].apply(lambda a:re.sub('<end>', '', a).strip()).values[:1000]\n",
    "bss = []\n",
    "for i in tqdm(range(1000)):\n",
    "    input_test_sentence = test_it[i]\n",
    "    input_sentence, pred_string = predict_gen(input_test_sentence)\n",
    "    reference = [test_eng[i].split()] # the original\n",
    "    translation = pred_string.split() # trasilated using model\n",
    "    bs = bleu.sentence_bleu(reference, translation)\n",
    "    bss.append(bs)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVG. BLUE score : 0.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4608461118258671"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB1jRUqZQ9AM"
   },
   "source": [
    "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL-3 with concat scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, TensorBoard, LearningRateScheduler\n",
    "from sklearn.metrics import recall_score, f1_score, roc_curve, auc\n",
    "import datetime\n",
    "\n",
    "filepath=\"model_save_attention_concat/weights-{epoch:02d}-{val_loss:.2f}\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', save_format=\"tf\", save_freq=\"epoch\",  verbose=1, save_best_only=True, mode='auto')\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for 20 EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "1kN9ZWViQNMB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 1.5441\n",
      "Epoch 1: val_loss improved from inf to 1.20801, saving model to model_save_attention_concat\\weights-01-1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-01-1.21\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-01-1.21\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 523s 220ms/step - loss: 1.5441 - val_loss: 1.2080\n",
      "Epoch 2/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.8940\n",
      "Epoch 2: val_loss improved from 1.20801 to 0.95697, saving model to model_save_attention_concat\\weights-02-0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-02-0.96\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-02-0.96\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 480s 218ms/step - loss: 0.8940 - val_loss: 0.9570\n",
      "Epoch 3/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.7229\n",
      "Epoch 3: val_loss improved from 0.95697 to 0.81072, saving model to model_save_attention_concat\\weights-03-0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-03-0.81\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-03-0.81\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 480s 218ms/step - loss: 0.7229 - val_loss: 0.8107\n",
      "Epoch 4/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.6301\n",
      "Epoch 4: val_loss improved from 0.81072 to 0.71272, saving model to model_save_attention_concat\\weights-04-0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-04-0.71\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-04-0.71\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 483s 219ms/step - loss: 0.6301 - val_loss: 0.7127\n",
      "Epoch 5/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.5602\n",
      "Epoch 5: val_loss improved from 0.71272 to 0.67296, saving model to model_save_attention_concat\\weights-05-0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-05-0.67\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-05-0.67\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 481s 218ms/step - loss: 0.5602 - val_loss: 0.6730\n",
      "Epoch 6/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.5103\n",
      "Epoch 6: val_loss improved from 0.67296 to 0.63061, saving model to model_save_attention_concat\\weights-06-0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-06-0.63\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-06-0.63\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 480s 218ms/step - loss: 0.5103 - val_loss: 0.6306\n",
      "Epoch 7/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.4715\n",
      "Epoch 7: val_loss improved from 0.63061 to 0.59546, saving model to model_save_attention_concat\\weights-07-0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-07-0.60\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-07-0.60\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 482s 219ms/step - loss: 0.4715 - val_loss: 0.5955\n",
      "Epoch 8/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.4398\n",
      "Epoch 8: val_loss improved from 0.59546 to 0.57801, saving model to model_save_attention_concat\\weights-08-0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-08-0.58\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-08-0.58\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 485s 220ms/step - loss: 0.4398 - val_loss: 0.5780\n",
      "Epoch 9/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.4145\n",
      "Epoch 9: val_loss improved from 0.57801 to 0.55788, saving model to model_save_attention_concat\\weights-09-0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-09-0.56\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-09-0.56\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 482s 219ms/step - loss: 0.4145 - val_loss: 0.5579\n",
      "Epoch 10/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3916\n",
      "Epoch 10: val_loss improved from 0.55788 to 0.54283, saving model to model_save_attention_concat\\weights-10-0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-10-0.54\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-10-0.54\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 485s 220ms/step - loss: 0.3916 - val_loss: 0.5428\n",
      "Epoch 11/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3715\n",
      "Epoch 11: val_loss improved from 0.54283 to 0.52888, saving model to model_save_attention_concat\\weights-11-0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-11-0.53\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-11-0.53\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 486s 220ms/step - loss: 0.3715 - val_loss: 0.5289\n",
      "Epoch 12/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3535\n",
      "Epoch 12: val_loss improved from 0.52888 to 0.51814, saving model to model_save_attention_concat\\weights-12-0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-12-0.52\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-12-0.52\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 493s 224ms/step - loss: 0.3535 - val_loss: 0.5181\n",
      "Epoch 13/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3374\n",
      "Epoch 13: val_loss improved from 0.51814 to 0.50187, saving model to model_save_attention_concat\\weights-13-0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-13-0.50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-13-0.50\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 489s 222ms/step - loss: 0.3374 - val_loss: 0.5019\n",
      "Epoch 14/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3225\n",
      "Epoch 14: val_loss did not improve from 0.50187\n",
      "2205/2205 [==============================] - 454s 206ms/step - loss: 0.3225 - val_loss: 0.5073\n",
      "Epoch 15/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.3103\n",
      "Epoch 15: val_loss improved from 0.50187 to 0.49649, saving model to model_save_attention_concat\\weights-15-0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-15-0.50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-15-0.50\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 497s 226ms/step - loss: 0.3103 - val_loss: 0.4965\n",
      "Epoch 16/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2993\n",
      "Epoch 16: val_loss improved from 0.49649 to 0.49440, saving model to model_save_attention_concat\\weights-16-0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-16-0.49\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-16-0.49\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 487s 221ms/step - loss: 0.2993 - val_loss: 0.4944\n",
      "Epoch 17/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2898\n",
      "Epoch 17: val_loss improved from 0.49440 to 0.48235, saving model to model_save_attention_concat\\weights-17-0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-17-0.48\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-17-0.48\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 490s 222ms/step - loss: 0.2898 - val_loss: 0.4824\n",
      "Epoch 18/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2805\n",
      "Epoch 18: val_loss did not improve from 0.48235\n",
      "2205/2205 [==============================] - 446s 202ms/step - loss: 0.2805 - val_loss: 0.4940\n",
      "Epoch 19/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2713\n",
      "Epoch 19: val_loss improved from 0.48235 to 0.47935, saving model to model_save_attention_concat\\weights-19-0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-19-0.48\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-19-0.48\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 487s 221ms/step - loss: 0.2713 - val_loss: 0.4793\n",
      "Epoch 20/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2630\n",
      "Epoch 20: val_loss improved from 0.47935 to 0.47667, saving model to model_save_attention_concat\\weights-20-0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-20-0.48\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-20-0.48\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 491s 223ms/step - loss: 0.2630 - val_loss: 0.4767\n",
      "Epoch 21/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2557\n",
      "Epoch 21: val_loss improved from 0.47667 to 0.47429, saving model to model_save_attention_concat\\weights-21-0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-21-0.47\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-21-0.47\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 497s 226ms/step - loss: 0.2557 - val_loss: 0.4743\n",
      "Epoch 22/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2488\n",
      "Epoch 22: val_loss did not improve from 0.47429\n",
      "2205/2205 [==============================] - 449s 204ms/step - loss: 0.2488 - val_loss: 0.4774\n",
      "Epoch 23/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2426\n",
      "Epoch 23: val_loss did not improve from 0.47429\n",
      "2205/2205 [==============================] - 449s 204ms/step - loss: 0.2426 - val_loss: 0.4787\n",
      "Epoch 24/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2372\n",
      "Epoch 24: val_loss improved from 0.47429 to 0.46751, saving model to model_save_attention_concat\\weights-24-0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-24-0.47\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-24-0.47\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 490s 222ms/step - loss: 0.2372 - val_loss: 0.4675\n",
      "Epoch 25/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2323\n",
      "Epoch 25: val_loss improved from 0.46751 to 0.46494, saving model to model_save_attention_concat\\weights-25-0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-25-0.46\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-25-0.46\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 495s 225ms/step - loss: 0.2323 - val_loss: 0.4649\n",
      "Epoch 26/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2277\n",
      "Epoch 26: val_loss improved from 0.46494 to 0.45978, saving model to model_save_attention_concat\\weights-26-0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-26-0.46\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-26-0.46\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 494s 224ms/step - loss: 0.2277 - val_loss: 0.4598\n",
      "Epoch 27/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2233\n",
      "Epoch 27: val_loss did not improve from 0.45978\n",
      "2205/2205 [==============================] - 453s 205ms/step - loss: 0.2233 - val_loss: 0.4626\n",
      "Epoch 28/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2195\n",
      "Epoch 28: val_loss did not improve from 0.45978\n",
      "2205/2205 [==============================] - 461s 209ms/step - loss: 0.2195 - val_loss: 0.4613\n",
      "Epoch 29/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2151\n",
      "Epoch 29: val_loss improved from 0.45978 to 0.45379, saving model to model_save_attention_concat\\weights-29-0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-29-0.45\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-29-0.45\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 497s 226ms/step - loss: 0.2151 - val_loss: 0.4538\n",
      "Epoch 30/30\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2116\n",
      "Epoch 30: val_loss did not improve from 0.45379\n",
      "2205/2205 [==============================] - 453s 205ms/step - loss: 0.2116 - val_loss: 0.4549\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "model_attention_concat = encoder_decoder(vocab_size_ita+1,vocab_size_eng+1,22,25,512,\"concat\",512)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model_attention_concat.compile(optimizer=optimizer,loss=loss_function)\n",
    "train_steps=train.shape[0]//128\n",
    "valid_steps=validation.shape[0]//128\n",
    "history_concat = model_attention_concat.fit(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data=test_dataloader, validation_steps=valid_steps,\n",
    "                   callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Ff1lV0ITM6_p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ca8a8ab6a0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_concat.history['loss']\n",
    "# acc = history.history['acc']\n",
    "val_loss = history_concat.history['val_loss']\n",
    "# val_acc = history.history['val_acc'] \n",
    "# val_iou_score = history.history['val_iou_score']\n",
    "# iou_score = history.history['iou_score']\n",
    "epoch = 30\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/val_loss')\n",
    "plt.title('Learning')\n",
    "plt.plot(range(epoch), loss, label = \"loss\")\n",
    "plt.plot(range(epoch), val_loss, label = \"val_loss\")\n",
    "# plt.plot(range(epoch), acc, label = \"acc\")\n",
    "# plt.plot(range(epoch), iou_score, label = \"iou_score\")\n",
    "# plt.plot(range(epoch), val_iou_score, label = \"val_iou_score\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for 30 EPOCHS MORE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2080\n",
      "Epoch 1: val_loss did not improve from 0.45379\n",
      "2205/2205 [==============================] - 452s 205ms/step - loss: 0.2080 - val_loss: 0.4554\n",
      "Epoch 2/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2042\n",
      "Epoch 2: val_loss did not improve from 0.45379\n",
      "2205/2205 [==============================] - 453s 205ms/step - loss: 0.2042 - val_loss: 0.4539\n",
      "Epoch 3/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.2013\n",
      "Epoch 3: val_loss did not improve from 0.45379\n",
      "2205/2205 [==============================] - 453s 206ms/step - loss: 0.2013 - val_loss: 0.4606\n",
      "Epoch 4/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.1985\n",
      "Epoch 4: val_loss improved from 0.45379 to 0.44704, saving model to model_save_attention_concat\\weights-04-0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-04-0.45\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save_attention_concat\\weights-04-0.45\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C893F7B4C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<__main__.Attention object at 0x000002C89CA6FBB0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class '__main__.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002C9500D5D90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205/2205 [==============================] - 497s 225ms/step - loss: 0.1985 - val_loss: 0.4470\n",
      "Epoch 5/10\n",
      "2205/2205 [==============================] - ETA: 0s - loss: 0.1959\n",
      "Epoch 5: val_loss did not improve from 0.44704\n",
      "2205/2205 [==============================] - 462s 210ms/step - loss: 0.1959 - val_loss: 0.4541\n",
      "Epoch 6/10\n",
      "1642/2205 [=====================>........] - ETA: 1:57 - loss: 0.1920"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13000/3440943120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history_concat_2 = model_attention_concat.fit(train_dataloader, steps_per_epoch=train_steps, epochs=10, validation_data=test_dataloader, validation_steps=valid_steps,\n\u001b[0m\u001b[0;32m      2\u001b[0m                    callbacks=[checkpoint])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_concat_2 = model_attention_concat.fit(train_dataloader, steps_per_epoch=train_steps, epochs=10, validation_data=test_dataloader, validation_steps=valid_steps,\n",
    "                   callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x179fb2ef850>"
      ]
     },
     "execution_count": 947,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_concat_2.history['loss']\n",
    "# acc = history.history['acc']\n",
    "val_loss = history_concat_2.history['val_loss']\n",
    "# val_acc = history.history['val_acc'] \n",
    "# val_iou_score = history.history['val_iou_score']\n",
    "# iou_score = history.history['iou_score']\n",
    "epoch = 30\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/val_loss')\n",
    "plt.title('Learning')\n",
    "plt.plot(range(epoch), loss, label = \"loss\")\n",
    "plt.plot(range(epoch), val_loss, label = \"val_loss\")\n",
    "# plt.plot(range(epoch), acc, label = \"acc\")\n",
    "# plt.plot(range(epoch), iou_score, label = \"iou_score\")\n",
    "# plt.plot(range(epoch), val_iou_score, label = \"val_iou_score\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST Loss:0.447 in 50 EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_concat(input_test_sentence):\n",
    "\n",
    "    '''\n",
    "    A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "    B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "    C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "    D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         Save the attention weights\n",
    "         And get the word using the tokenizer(word index) and then store it in a string.\n",
    "    E. Call plot_attention(#params)\n",
    "    F. Return the predicted sentence\n",
    "    '''\n",
    "    ENCODER_SEQ_LEN = 22\n",
    "    DECODER_SEQ_LEN = 25\n",
    "    max_len_ita = 22\n",
    "    nums = tknizer_ita.texts_to_sequences([input_test_sentence])\n",
    "    nums_padded = pad_sequences(nums, maxlen=max_len_ita, dtype='int32', padding='post')\n",
    "    encoder_output, enc_state_h, enc_state_c = model_attention_concat.layers[0](nums_padded)\n",
    "    pred, alphas = [], []\n",
    "    cur_vec = np.zeros((1, 1))\n",
    "    osd = model_attention_concat.layers[1].onestepdecoder\n",
    "    for i in range(DECODER_SEQ_LEN):\n",
    "        \n",
    "        \n",
    "        output, state_h, state_c, attention_weights, context_vector = osd(cur_vec, encoder_output, enc_state_h, enc_state_c )\n",
    "        \n",
    "        enc_state_h, enc_state_c = state_h, state_c\n",
    "        alphas.append(attention_weights.numpy().flatten())\n",
    "        \n",
    "        \n",
    "        cur_vec = np.reshape(np.argmax(output), (1, 1))\n",
    "        print(f\"at time step {i} the word is \", cur_vec)\n",
    "        \n",
    "        if english_dict[cur_vec[0][0]] == '<end>':\n",
    "            break\n",
    "        pred.append(cur_vec)\n",
    "        \n",
    "        \n",
    "     \n",
    "    pred_string = \"\"\n",
    "\n",
    "    pred_string = \" \".join([ english_dict[i[0][0]] for i in pred])\n",
    "    \n",
    "    print(\"PREDICTED STRING:\",pred_string)\n",
    "    \n",
    "   \n",
    "    \n",
    "    plot_attention(alphas, input_test_sentence, pred_string)\n",
    "    \n",
    "    return  input_test_sentence, pred_string\n",
    "    \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at time step 0 the word is  [[4]]\n",
      "at time step 1 the word is  [[6]]\n",
      "at time step 2 the word is  [[9]]\n",
      "at time step 3 the word is  [[193]]\n",
      "at time step 4 the word is  [[23]]\n",
      "at time step 5 the word is  [[32]]\n",
      "at time step 6 the word is  [[6]]\n",
      "at time step 7 the word is  [[10289]]\n",
      "PREDICTED STRING: tom is a father of mary is\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_sentence: è il padre di tom\n",
      "English predict: tom is a father of mary is\n",
      "English actual: that is tom is father\n"
     ]
    }
   ],
   "source": [
    "index = 200\n",
    "input_test_sentence = validation[\"italian\"].values[index]\n",
    "actual = validation[\"english_out\"].values[index]\n",
    "input_sentence, pred_string = predict_concat(input_test_sentence)\n",
    "import re\n",
    "print(f\"Input_sentence: {input_sentence}\")\n",
    "print(f\"English predict: {pred_string}\")\n",
    "print(f\"English actual: {re.sub('<end>', '', actual).strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLUE SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTED STRING: she is a teacher\n",
      "ACTUAL STRING: you are a teacher\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: are not you going to eat it\n",
      "ACTUAL STRING: are not you going to eat it\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i would like to leave the meat that you to sit at that time before my house\n",
      "ACTUAL STRING: i would like to drastically decrease the amount of time it takes me to clean the house\n",
      "BL880EU score: \u001b[1m\u001b[31m0.17\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i think you are jealous\n",
      "ACTUAL STRING: i think you are selfish\n",
      "BL880EU score: \u001b[1m\u001b[32m0.668740304976422\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: it is going to have fun to have with to\n",
      "ACTUAL STRING: it will be fun to have somebody to play with\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tell tom he does not care\n",
      "ACTUAL STRING: tell tom i do not care\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: pick up your company\n",
      "ACTUAL STRING: pick your toys up\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom is not interested\n",
      "ACTUAL STRING: tom is not interested\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom and mary are not canadian\n",
      "ACTUAL STRING: tom and mary are not canadians\n",
      "BL880EU score: \u001b[1m\u001b[32m0.7598356856515925\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: how do you think that me\n",
      "ACTUAL STRING: how do you think i feel\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5081327481546147\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i do not want to take any bet\n",
      "ACTUAL STRING: i do not want to take risks\n",
      "BL880EU score: \u001b[1m\u001b[32m0.6803749333171202\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i thought tom will find that interesting\n",
      "ACTUAL STRING: i thought tom would find that interesting\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom broke mary is car\n",
      "ACTUAL STRING: tom broke mary is clarinet\n",
      "BL880EU score: \u001b[1m\u001b[32m0.668740304976422\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: he will play golf on sunday\n",
      "ACTUAL STRING: he will play golf next sunday\n",
      "BL880EU score: \u001b[1m\u001b[32m0.537284965911771\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: everyone laughed tom is hiding\n",
      "ACTUAL STRING: everyone but tom laughed\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: we are expecting\n",
      "ACTUAL STRING: we are ruined\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i was being\n",
      "ACTUAL STRING: i was dazzled\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i am two students today\n",
      "ACTUAL STRING: two students are absent today\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i have a lot of questions\n",
      "ACTUAL STRING: i have got a lot of questions\n",
      "BL880EU score: \u001b[1m\u001b[32m0.5115078115793242\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom is being out of work\n",
      "ACTUAL STRING: tom is absorbed in his work\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: do not do things\n",
      "ACTUAL STRING: do not mess things up\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: can you explain something to me\n",
      "ACTUAL STRING: can you explain something to me\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i am not able to do it\n",
      "ACTUAL STRING: i am unable to do it\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: do you still do that\n",
      "ACTUAL STRING: do it again\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: tom is used to many drunk in a a famous writer\n",
      "ACTUAL STRING: my uncle lived a happy life and died a peaceful death\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i have a lot more books than you do\n",
      "ACTUAL STRING: i have a lot more books than you do\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: we are not yet sure\n",
      "ACTUAL STRING: we are still not sure\n",
      "BL880EU score: \u001b[1m\u001b[31m0.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: the students all laughed\n",
      "ACTUAL STRING: the students all laughed\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: i met tom at a party\n",
      "ACTUAL STRING: i met tom at a party\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n",
      "PREDICTED STRING: you are interested in computers\n",
      "ACTUAL STRING: you are interested in computers\n",
      "BL880EU score: \u001b[1m\u001b[32m1.0\u001b[0m\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import nltk.translate.bleu_score as bleu\n",
    "test_it = validation[\"italian\"].values[30:60]\n",
    "test_eng = validation[\"english_out\"].apply(lambda a:re.sub('<end>', '', a).strip()).values[30:60]\n",
    "for i in range(30):\n",
    "    input_test_sentence = test_it[i]\n",
    "    input_sentence, pred_string = predict_concat(input_test_sentence)\n",
    "    print(f\"ACTUAL STRING: {test_eng[i]}\")\n",
    "    reference = [test_eng[i].split()] # the original\n",
    "    translation = pred_string.split() # trasilated using model\n",
    "    bs = bleu.sentence_bleu(reference, translation)\n",
    "    print(f'BL880EU score: {colored(bs, \"green\", attrs=[\"bold\"]) if 0.5<=bs<=1 else colored(round(bs, 2), \"red\", attrs=[\"bold\"])}')\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [02:05<00:00,  8.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "test_it = validation[\"italian\"].values[:1000]\n",
    "test_eng = validation[\"english_out\"].apply(lambda a:re.sub('<end>', '', a).strip()).values[:1000]\n",
    "bss = []\n",
    "for i in tqdm(range(1000)):\n",
    "    input_test_sentence = test_it[i]\n",
    "    input_sentence, pred_string = predict_concat(input_test_sentence)\n",
    "    reference = [test_eng[i].split()] # the original\n",
    "    translation = pred_string.split() # trasilated using model\n",
    "    bs = bleu.sentence_bleu(reference, translation)\n",
    "    bss.append(bs)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVG. Blue scores : 0.497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49700195512744866"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_attention_general.save('model_attention_gen',save_format='tf')\n",
    "# model_attention_concat.save('model_attention_concat',save_format='tf')\n",
    "# model_attention_dot.save('model_attention_dot',save_format='tf')\n",
    "# loaded_model1 = tf.keras.models.load_model('model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Seq2SeqImplementation__Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
