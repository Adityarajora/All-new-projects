{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa032160",
   "metadata": {},
   "source": [
    "# In this notebook, I'll try to apply TRANSFORMER model for a CHATBOT from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698a1320",
   "metadata": {},
   "source": [
    "## Overview\n",
    "***\n",
    "*A chatbot or chatterbot is a software application used to conduct an on-line chat conversation via text or text-to-speech, in lieu of providing direct contact with a live human agent chatbot is a type of software that can help human by automating conversations and interact with them through messaging platforms. here are different approaches and tools that you can use when building chatbots. Depending on the use case you want to address, some technologies are more appropriate than others. Combining artificial intelligence forms such as natural language processing, machine learning, and semantic understanding may be the best option to achieve the desired results.*\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94feefe",
   "metadata": {},
   "source": [
    "## How to build a Chatbot for our task?\n",
    "***\n",
    "ChatBots are usually Task specific means if there a chatbot which serves only food delivery app have trained on a dataset which\n",
    "completely different from the dataset on which chatbot which serves online healthcare app. Similary, for this kaggle problem\n",
    "we have provided with movie dataset which may feel that its not specific to any task, but actually it is specific to how people\n",
    "will interect generally as these movie dialogues are nothing but daily life conversation between people however, that chatbot\n",
    "may reply things which sounds too much dramatic and filmy like some dialogue of Tom cruise, shah rukh khan etc.\n",
    "\n",
    "We can approch this problem by applying Neural network models like encoder-decoder architecture with some attention mechanism.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425a8749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import numpy as np\n",
    "import codecs\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import ast\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import Progbar\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97982f",
   "metadata": {},
   "source": [
    "## Loading cleaned data that I have preprared while EDA and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0645f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well i thought we would start with pronunciati...</td>\n",
       "      <td>not the hacking and gagging and spitting part ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not the hacking and gagging and spitting part ...</td>\n",
       "      <td>okay then how bout we try out some french cuis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you are asking me out  that is so cute what is...</td>\n",
       "      <td>forget it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no no it is my fault  we did not have a proper...</td>\n",
       "      <td>cameron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gosh if only we could find kat a boyfriend</td>\n",
       "      <td>let me see what i can do</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  well i thought we would start with pronunciati...   \n",
       "1  not the hacking and gagging and spitting part ...   \n",
       "2  you are asking me out  that is so cute what is...   \n",
       "3  no no it is my fault  we did not have a proper...   \n",
       "4         gosh if only we could find kat a boyfriend   \n",
       "\n",
       "                                              answer  \n",
       "0  not the hacking and gagging and spitting part ...  \n",
       "1  okay then how bout we try out some french cuis...  \n",
       "2                                          forget it  \n",
       "3                                            cameron  \n",
       "4                           let me see what i can do  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = joblib.load('data_cleaned')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af0edc",
   "metadata": {},
   "source": [
    "## Dividing into TWO, train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d494f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(data, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebf65780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size_ans, vocab_size_ques:29605,29583\n"
     ]
    }
   ],
   "source": [
    "vocab_ans = list(set(\" \".join(train['answer'].values).split()))\n",
    "vocab_ques = list(set(\" \".join(train['question'].values).split()))\n",
    "vocab_size_ans, vocab_size_ques = len(vocab_ans), len(vocab_ques)\n",
    "print(f\"vocab_size_ans, vocab_size_ques:{vocab_size_ans},{ vocab_size_ques}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289182c9",
   "metadata": {},
   "source": [
    "## Using tfds SubwordTextEncoder, it will create tokens\n",
    "#### example Multiplication -> Multi, pli, cat, i, on \n",
    "#### Advantages: \n",
    "    1. Reduces vocab size => faster learning\n",
    "    2. Reduces chances of missing word in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f322ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_a = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    train['answer'], target_vocab_size=2**15) \n",
    "\n",
    "tokenizer_q = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    train['question'], target_vocab_size=2**15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "609b2718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer_q:27513\n",
      "tokenizer_a:27358\n"
     ]
    }
   ],
   "source": [
    "print(f\"tokenizer_q:{tokenizer_q.vocab_size}\")\n",
    "print(f\"tokenizer_a:{tokenizer_a.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02392cc3",
   "metadata": {},
   "source": [
    "#### Examples of subword tokenization in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cf67e110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [27171, 13788, 10452, 642, 24725, 4386]\n",
      "The original string: Encoder decoder\n",
      "27171---->E\n",
      "13788---->nc\n",
      "10452---->ode\n",
      "642---->r \n",
      "24725---->deco\n",
      "4386---->der\n",
      "================================================================================\n",
      "Tokenized string is [27326, 21076, 7692, 15421, 27371]\n",
      "The original string: Encoder decoder\n",
      "27326---->E\n",
      "21076---->nco\n",
      "7692---->der \n",
      "15421---->decode\n",
      "27371---->r\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Encoder decoder'\n",
    "\n",
    "tokenized_string = tokenizer_a.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_a.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "for token in tokenized_string:\n",
    "    print(str(token) + \"---->\" + tokenizer_a.decode([token]))\n",
    "\n",
    "print(\"=\"*80)\n",
    "tokenized_string = tokenizer_q.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_q.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "for token in tokenized_string:\n",
    "    print(str(token) + \"---->\" + tokenizer_q.decode([token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9e30ce",
   "metadata": {},
   "source": [
    "###### 0-27512 for questions\n",
    "\n",
    "###### 0-27357 for answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9469ee",
   "metadata": {},
   "source": [
    "* **Attaching token number '27513' representing \\<start> and '27514' representing \\<end> QUESTIONS**\n",
    "* **Attaching token number '27358' representing \\<start> and '27359' representing \\<end> ANSWERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aeb6d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(ques, ans):\n",
    "    ques = [tokenizer_q.vocab_size] + tokenizer_q.encode(ques.numpy()) + [tokenizer_q.vocab_size+1]\n",
    "    ans = [tokenizer_a.vocab_size] + tokenizer_a.encode(ans.numpy()) + [tokenizer_a.vocab_size+1]\n",
    "    return ques, ans\n",
    "\n",
    "def tf_encode(ques, ans):\n",
    "    result_ques, result_ans = tf.py_function(encode, [ques, ans], [tf.int64, tf.int64])\n",
    "    result_ques.set_shape([None])\n",
    "    result_ans.set_shape([None])\n",
    "    return result_ques, result_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc78baed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and the fifty is all gone huh who is the ten for \n",
      " the websters\n",
      "tf.Tensor(\n",
      "[27513    17     4   691     3    46   448   501    63     3     4   356\n",
      "   260 27514], shape=(14,), dtype=int64)\n",
      "tf.Tensor([27358     5 16677 27359], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(train['question'].values[0],\"\\n\",train['answer'].values[0])\n",
    "question, answer = tf_encode(train['question'].values[0],train['answer'].values[0])\n",
    "print(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1413123",
   "metadata": {},
   "source": [
    "### Creating train_dataset/test_dataset object from Dataframe + padding\n",
    "\n",
    "###### prefetch: If I'm at epoch-20 then prefetch prepares the Batch for epoch-21, so when epoch-21 start, it will make available the batch in no time, basically enhancing speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54bb56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(dict(train))\n",
    "train_dataset = train_dataset.map(lambda x:tf_encode(x['question'], x['answer']))\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(20000).padded_batch(64, padded_shapes=([None],[None])) \n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "436c73c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices(dict(validation))\n",
    "val_dataset = val_dataset.map(lambda x:tf_encode(x['question'], x['answer']))\n",
    "val_dataset = val_dataset.padded_batch(64, padded_shapes=([None],[None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "85844a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 27), dtype=int64, numpy=\n",
       "array([[27513,  6199,     2, ...,     0,     0,     0],\n",
       "       [27513,  6259, 13965, ...,     0,     0,     0],\n",
       "       [27513,    64,   255, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [27513,    24,     3, ...,     0,     0,     0],\n",
       "       [27513, 12292,  8857, ...,     0,     0,     0],\n",
       "       [27513,    63,    48, ...,     0,     0,     0]], dtype=int64)>"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question, answer = next(iter(train_dataset))\n",
    "question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf8241",
   "metadata": {},
   "source": [
    "### Positional encoding function where 'i' -> embedding dimn index, 'pos' -> word index in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500b25e",
   "metadata": {},
   "source": [
    "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae35c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Positional encoding\n",
    "\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis,:]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d393354",
   "metadata": {},
   "source": [
    "## 1. Pad Masking\n",
    "#### Making all the padded tokens, self attention/attention calculation of a word with those paddings will be ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecbd402",
   "metadata": {},
   "source": [
    "\n",
    "* Here output dimn -> (batch_size, 1, 1, seq_len) \n",
    "          \n",
    "*  for each 8 attention heads, for each query word it will be multiplied, thats why creating 1, 1 in the middle\n",
    "\n",
    "##### (batch_size, 8, query_word_len, seq_len) * (batch_size, 1, 1, seq_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628afe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking\n",
    "\n",
    "'''Mask all the pad tokens in the batch of sequence. \n",
    "It ensures that the model does not treat padding as the input. \n",
    "The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise.\n",
    "'''\n",
    "def create_padding_mask(seq):\n",
    "    \"\"\"\n",
    "    seq: padded sentence length (5)\n",
    "    \"\"\"\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    # Adding 2, 3 dimn using tf.newaxis, 2-> As this mask will be multiplied with each attention head and 3-> for each word in a sentance\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "# create_padding_mask(np.array([[1,2,3,0,0,0],[1,2,3,0,0,1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9aceca",
   "metadata": {},
   "source": [
    "## 2. Looakahead mask\n",
    "\n",
    "for the first word, its self attention calculation with be ignored with proceeding words i.e. second, third word and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d26dea25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looakahead mask\n",
    "\n",
    "\"\"\"The look-ahead mask is used to mask the future tokens in a sequence. \n",
    "In other words, the mask indicates which entries should not be used.\n",
    "\"\"\"\n",
    "def create_look_ahead_mask(size):\n",
    "    \"\"\"\n",
    "    The look-ahead mask is used to mask the future tokens in a sequence\n",
    "    \"\"\"\n",
    "    #band_part with this setting creates lower triangular matrix that's why subtracting from 1\n",
    "    # [[0., 1., 1.],\n",
    "    #  [0., 0., 1.],\n",
    "    #  [0., 0., 0.]] output with size:3\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "#example\n",
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896ca7e",
   "metadata": {},
   "source": [
    "## 3. SELF-ATTENTION calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04daf49a",
   "metadata": {},
   "source": [
    "![image](images/attenion_formula.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f55e44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth) # NOTE: depth=dk\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\" \n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "    # scale matmul_qk. underroot d_model i.e. underroot(100)\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    # add the mask to the scaled tensor. \n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  # -1e9 ~ (-INFINITY) => where ever mask is set, make its logit value close to -INF\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798eca41",
   "metadata": {},
   "source": [
    "## 4. MultiHeadAttention Calculation\n",
    "#### Its nothing but a RESHAPING !! :)\n",
    "example : \n",
    "1. if we have (64, 10, 512)->(BATCH, #words, embeddding) as input, after passiing it though dense layer of size 512 we will get (64, 10, 512)\n",
    "2. We have three such dense layers representing/for Q, K, V encodings.\n",
    "3. (64, 10, 512) -> reshape -> (64, 8, 10 ,64) -> (BATCH, attention head, #words, encode)\n",
    "    '64' is representing encoding of 512 -> 64 dimension\n",
    "4. (64, 8, 10 ,64)->self-attention-code->(64, 8, 10 ,10) called attention weights, (64, 8, 10 ,64)\n",
    "5. Concatenate such that 8*64 will be new dimension -> (64, 10, 512)\n",
    "    \n",
    "    **Beware embedding dimn must be divisible by no. of heads and always embedding_dimn/heads => encodin_dimn(here 64)**\n",
    "    \n",
    "    **NICE HACK** (-_-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f41cf3c",
   "metadata": {},
   "source": [
    "![image](images/multi_head.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab0b6ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model  # typically 512\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809f3721",
   "metadata": {},
   "source": [
    "## 5. ENCODER layer\n",
    "\n",
    "#### -> self Multihead attention -> Residual+Norm -> Feed forward neural network -> Residual+Norm\n",
    "\n",
    "![image](images/encoder_layer.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c9b69f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff): #dff = 512\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model) # with Attention\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model) #with Attention\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "d18de1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d49552e",
   "metadata": {},
   "source": [
    "## 6. DECODER LAYER\n",
    "#### -> self multihead attention -> residual+norm -> multihead attention(between E & D) -> residual+norm -> feed forward NN -> residual+norm\n",
    "\n",
    "![image](images/decoder_layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3061bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "         \n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x) \n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2123ca",
   "metadata": {},
   "source": [
    "## 7. ENCODER \n",
    "#### Nothing but repetation of Encoder layer :-) + Input embedding vector + positional encoding\n",
    "\n",
    "![image](images/encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98960a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]   #x:(batch, seq_len)\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) \n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd0dcc2",
   "metadata": {},
   "source": [
    "## 8. DECODER\n",
    "#### Nothing but Repetation of decoder layers + posisional encoder + embedding layer\n",
    "\n",
    "![image](images/decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4232ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50318f4f",
   "metadata": {},
   "source": [
    "## 9. TRANSFORMER\n",
    "\n",
    "#### Nothing but encoder+decoder+dense layer\n",
    "##### (64,10,512) -> dense_layer -> (64,10,vocab_size)\n",
    "\n",
    "![image](images/transformer.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ba6c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db99e050",
   "metadata": {},
   "source": [
    "#### So to create a transformer architecture which is now everywhere in NLP models, we require only 9 STEPs :-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ad95ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer_a = joblib.load(\"tokenizer_a\")\n",
    "# tokenizer_q = joblib.load(\"tokenizer_q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0583e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb699bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_q.vocab_size + 2\n",
    "target_vocab_size = tokenizer_a.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dd6833",
   "metadata": {},
   "source": [
    "## Custom learning rate, proposed in the paper\n",
    "#### First learning rate will be high and then after some epochs it will be decreasing ONLY\n",
    "\n",
    "![image](images/lr.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af0bd674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95ed1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e3f318",
   "metadata": {},
   "source": [
    "### See, increasing and then decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a02400de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c461fb",
   "metadata": {},
   "source": [
    "##### Custom losss function, same as sparse categorical cross entropy but considers only no padded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba02438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b9a90f",
   "metadata": {},
   "source": [
    "### Creating pad mask(encoder), pad mask(decoder), lookahead mask(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b61f4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644505ce",
   "metadata": {},
   "source": [
    "## Saving model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a9ba0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints_test/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c3cdf4",
   "metadata": {},
   "source": [
    "## Using gradient tape for getting derivatives of loss functions w.r.t. weights then applyiing to optimizer => BACKPROPAGATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e0dc634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp) \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                     True, \n",
    "                                     enc_padding_mask, \n",
    "                                     combined_mask, \n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf410f58",
   "metadata": {},
   "source": [
    "## Creating sample transformer to know the no. of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0d0ea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_5 (Encoder)         multiple                  4315008   \n",
      "                                                                 \n",
      " decoder_5 (Decoder)         multiple                  4560384   \n",
      "                                                                 \n",
      " dense_293 (Dense)           multiple                  3529440   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,404,832\n",
      "Trainable params: 12,404,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "input_vocab_size = tokenizer_q.vocab_size + 2\n",
    "target_vocab_size = tokenizer_a.vocab_size + 2\n",
    "dropout_rate = 0.1\n",
    "\n",
    "sample_transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 27), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 27), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "sample_transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d653136",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "input_vocab_size = tokenizer_q.vocab_size + 2\n",
    "target_vocab_size = tokenizer_a.vocab_size + 2\n",
    "dropout_rate = 0.1\n",
    "\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "a47d4b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/20\n",
      "111552/111527 [==============================] - 304s 3ms/step - loss: 5.6714 - acc: 0.0692\n",
      "\n",
      "epoch 2/20\n",
      "111552/111527 [==============================] - 219s 2ms/step - loss: 5.5175 - acc: 0.0746\n",
      "\n",
      "epoch 3/20\n",
      "111552/111527 [==============================] - 157s 1ms/step - loss: 5.4285 - acc: 0.0776\n",
      "\n",
      "epoch 4/20\n",
      "111552/111527 [==============================] - 155s 1ms/step - loss: 5.3675 - acc: 0.0797\n",
      "\n",
      "epoch 5/20\n",
      "111552/111527 [==============================] - 156s 1ms/step - loss: 5.3132 - acc: 0.0813\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-1\n",
      "\n",
      "epoch 6/20\n",
      "111552/111527 [==============================] - 157s 1ms/step - loss: 5.2668 - acc: 0.0827\n",
      "\n",
      "epoch 7/20\n",
      "111552/111527 [==============================] - 157s 1ms/step - loss: 5.2267 - acc: 0.0840\n",
      "\n",
      "epoch 8/20\n",
      "111552/111527 [==============================] - 157s 1ms/step - loss: 5.1926 - acc: 0.0851\n",
      "\n",
      "epoch 9/20\n",
      "111552/111527 [==============================] - 157s 1ms/step - loss: 5.1626 - acc: 0.0863\n",
      "\n",
      "epoch 10/20\n",
      "111552/111527 [==============================] - 157s 1ms/step - loss: 5.1361 - acc: 0.0873\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train\\ckpt-2\n",
      "\n",
      "epoch 11/20\n",
      "111552/111527 [==============================] - 157s 1ms/step - loss: 5.1137 - acc: 0.0883\n",
      "\n",
      "epoch 12/20\n",
      "111552/111527 [==============================] - 154s 1ms/step - loss: 5.0942 - acc: 0.0891\n",
      "\n",
      "epoch 13/20\n",
      "111552/111527 [==============================] - 155s 1ms/step - loss: 5.0781 - acc: 0.0898\n",
      "\n",
      "epoch 14/20\n",
      "111552/111527 [==============================] - 154s 1ms/step - loss: 5.0637 - acc: 0.0904\n",
      "\n",
      "epoch 15/20\n",
      "111552/111527 [==============================] - 155s 1ms/step - loss: 5.0511 - acc: 0.0910\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train\\ckpt-3\n",
      "\n",
      "epoch 16/20\n",
      "111552/111527 [==============================] - 157s 1ms/step - loss: 5.0399 - acc: 0.0916\n",
      "\n",
      "epoch 17/20\n",
      "111552/111527 [==============================] - 157s 1ms/step - loss: 5.0301 - acc: 0.0921\n",
      "\n",
      "epoch 18/20\n",
      "111552/111527 [==============================] - 157s 1ms/step - loss: 5.0213 - acc: 0.0925\n",
      "\n",
      "epoch 19/20\n",
      "111552/111527 [==============================] - 156s 1ms/step - loss: 5.0136 - acc: 0.0930\n",
      "\n",
      "epoch 20/20\n",
      "111552/111527 [==============================] - 158s 1ms/step - loss: 5.0065 - acc: 0.0934\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train\\ckpt-4\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "batch_size = 64\n",
    "metrics_names = ['loss', 'acc'] \n",
    "train_loss.reset_states()\n",
    "train_accuracy.reset_states()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
    "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
    " \n",
    "    # inp -> question, tar -> answer\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        \n",
    "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
    "        \n",
    "        pb_i.add(batch_size, values=values) \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "addc165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/5\n",
      "111552/111527 [==============================] - 169s 2ms/step - loss: 4.9995 - acc: 0.0938\n",
      "\n",
      "epoch 2/5\n",
      "111552/111527 [==============================] - 154s 1ms/step - loss: 4.9930 - acc: 0.0941\n",
      "\n",
      "epoch 3/5\n",
      "111552/111527 [==============================] - 215s 2ms/step - loss: 4.9866 - acc: 0.0945\n",
      "\n",
      "epoch 4/5\n",
      "111552/111527 [==============================] - 489s 4ms/step - loss: 4.9803 - acc: 0.0948\n",
      "\n",
      "epoch 5/5\n",
      "111552/111527 [==============================] - 487s 4ms/step - loss: 4.9743 - acc: 0.0951\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-5\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "batch_size = 64\n",
    "metrics_names = ['loss', 'acc'] \n",
    "# train_loss.reset_states()\n",
    "# train_accuracy.reset_states()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
    "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
    " \n",
    "    # inp -> question, tar -> answer\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        \n",
    "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
    "        \n",
    "        pb_i.add(batch_size, values=values) \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca700ca",
   "metadata": {},
   "source": [
    "# With those hyperparameters it seems model is not learning at all, as there is no progress in 25 EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "3c6542bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 27 \n",
    "def evaluate(inp_sentence):\n",
    "    start_token = [tokenizer_q.vocab_size]\n",
    "    end_token = [tokenizer_q.vocab_size + 1]\n",
    "\n",
    "    # inp sentence is portuguese, hence adding the start and end token\n",
    "    inp_sentence = start_token + tokenizer_q.encode(inp_sentence) + end_token\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "    # as the target is english, the first word to the transformer should be the\n",
    "    # english start token.\n",
    "    decoder_input = [tokenizer_a.vocab_size]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "#         print(predictions.shape,\"aa\",predictions[: ,-1:, :].shape)\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "#         print(predicted_id, output)\n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == tokenizer_a.vocab_size+1: \n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "dcfbf0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_sentence = \"i am doing great\"\n",
    "a, b = evaluate(inp_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d36412",
   "metadata": {},
   "source": [
    "# RESULTS are ABSURD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "7ee9871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thel\n",
      "thel\n",
      "thel\n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n",
      "luc \n"
     ]
    }
   ],
   "source": [
    "for i in a[1:]:\n",
    "    print(tokenizer_a.decode([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45aebc4",
   "metadata": {},
   "source": [
    " ## Lets try with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a79abb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_5 (Encoder)         multiple                  4315008   \n",
      "                                                                 \n",
      " decoder_5 (Decoder)         multiple                  4560384   \n",
      "                                                                 \n",
      " dense_293 (Dense)           multiple                  3529440   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,404,832\n",
      "Trainable params: 12,404,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_q.vocab_size + 2\n",
    "target_vocab_size = tokenizer_a.vocab_size + 2\n",
    "dropout_rate = 0.1\n",
    "temp_input = tf.random.uniform((64, 27), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 27), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "sample_transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5709905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_6 (Encoder)         multiple                  8098048   \n",
      "                                                                 \n",
      " decoder_6 (Decoder)         multiple                  8585728   \n",
      "                                                                 \n",
      " dense_326 (Dense)           multiple                  7031520   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,715,296\n",
      "Trainable params: 23,715,296\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "d_model = 256\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "input_vocab_size = tokenizer_q.vocab_size + 2\n",
    "target_vocab_size = tokenizer_a.vocab_size + 2\n",
    "dropout_rate = 0.1\n",
    "\n",
    "sample_transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 27), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 27), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "sample_transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5656e",
   "metadata": {},
   "source": [
    "### Now the trainable parameters has increased from 12M to 24M, Lets test this!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "27d76c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/20\n",
      "111552/111527 [==============================] - 184s 2ms/step - loss: 5.2070 - acc: 0.0921\n",
      "\n",
      "epoch 2/20\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 4.9807 - acc: 0.0979\n",
      "\n",
      "epoch 3/20\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 4.8595 - acc: 0.1010\n",
      "\n",
      "epoch 4/20\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 4.7736 - acc: 0.1033\n",
      "\n",
      "epoch 5/20\n",
      "111552/111527 [==============================] - 145s 1ms/step - loss: 4.7041 - acc: 0.1053\n",
      "Saving checkpoint for epoch 5 at ./checkpoints2/train\\ckpt-1\n",
      "\n",
      "epoch 6/20\n",
      "111552/111527 [==============================] - 144s 1ms/step - loss: 4.6442 - acc: 0.1072\n",
      "\n",
      "epoch 7/20\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 4.5910 - acc: 0.1089\n",
      "\n",
      "epoch 8/20\n",
      "111552/111527 [==============================] - 145s 1ms/step - loss: 4.5422 - acc: 0.1107\n",
      "\n",
      "epoch 9/20\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 4.4968 - acc: 0.1123\n",
      "\n",
      "epoch 10/20\n",
      "111552/111527 [==============================] - 145s 1ms/step - loss: 4.4542 - acc: 0.1139\n",
      "Saving checkpoint for epoch 10 at ./checkpoints2/train\\ckpt-2\n",
      "\n",
      "epoch 11/20\n",
      "111552/111527 [==============================] - 148s 1ms/step - loss: 4.4140 - acc: 0.1155\n",
      "\n",
      "epoch 12/20\n",
      "111552/111527 [==============================] - 144s 1ms/step - loss: 4.3760 - acc: 0.1171\n",
      "\n",
      "epoch 13/20\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 4.3402 - acc: 0.1186\n",
      "\n",
      "epoch 14/20\n",
      "111552/111527 [==============================] - 145s 1ms/step - loss: 4.3065 - acc: 0.1201\n",
      "\n",
      "epoch 15/20\n",
      "111552/111527 [==============================] - 145s 1ms/step - loss: 4.2753 - acc: 0.1216\n",
      "Saving checkpoint for epoch 15 at ./checkpoints2/train\\ckpt-3\n",
      "\n",
      "epoch 16/20\n",
      "111552/111527 [==============================] - 146s 1ms/step - loss: 4.2467 - acc: 0.1230\n",
      "\n",
      "epoch 17/20\n",
      "111552/111527 [==============================] - 144s 1ms/step - loss: 4.2203 - acc: 0.1245\n",
      "\n",
      "epoch 18/20\n",
      "111552/111527 [==============================] - 144s 1ms/step - loss: 4.1958 - acc: 0.1258\n",
      "\n",
      "epoch 19/20\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 4.1724 - acc: 0.1271\n",
      "\n",
      "epoch 20/20\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 4.1498 - acc: 0.1285\n",
      "Saving checkpoint for epoch 20 at ./checkpoints2/train\\ckpt-4\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "batch_size = 64\n",
    "metrics_names = ['loss', 'acc'] \n",
    "train_loss.reset_states()\n",
    "train_accuracy.reset_states()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
    "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
    " \n",
    "    # inp -> question, tar -> answer\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        \n",
    "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
    "        \n",
    "        pb_i.add(batch_size, values=values) \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "8990f5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/30\n",
      "111552/111527 [==============================] - 146s 1ms/step - loss: 4.1279 - acc: 0.1297\n",
      "\n",
      "epoch 2/30\n",
      "111552/111527 [==============================] - 148s 1ms/step - loss: 4.1067 - acc: 0.1310\n",
      "\n",
      "epoch 3/30\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 4.0860 - acc: 0.1322\n",
      "\n",
      "epoch 4/30\n",
      "111552/111527 [==============================] - 144s 1ms/step - loss: 4.0660 - acc: 0.1334\n",
      "\n",
      "epoch 5/30\n",
      "111552/111527 [==============================] - 146s 1ms/step - loss: 4.0465 - acc: 0.1346\n",
      "Saving checkpoint for epoch 5 at ./checkpoints2/train\\ckpt-5\n",
      "\n",
      "epoch 6/30\n",
      "111552/111527 [==============================] - 147s 1ms/step - loss: 4.0276 - acc: 0.1358\n",
      "\n",
      "epoch 7/30\n",
      "111552/111527 [==============================] - 149s 1ms/step - loss: 4.0091 - acc: 0.1369\n",
      "\n",
      "epoch 8/30\n",
      "111552/111527 [==============================] - 149s 1ms/step - loss: 3.9912 - acc: 0.1381\n",
      "\n",
      "epoch 9/30\n",
      "111552/111527 [==============================] - 147s 1ms/step - loss: 3.9736 - acc: 0.1392\n",
      "\n",
      "epoch 10/30\n",
      "111552/111527 [==============================] - 148s 1ms/step - loss: 3.9566 - acc: 0.1402\n",
      "Saving checkpoint for epoch 10 at ./checkpoints2/train\\ckpt-6\n",
      "\n",
      "epoch 11/30\n",
      "111552/111527 [==============================] - 148s 1ms/step - loss: 3.9399 - acc: 0.1413\n",
      "\n",
      "epoch 12/30\n",
      "111552/111527 [==============================] - 148s 1ms/step - loss: 3.9237 - acc: 0.1423\n",
      "\n",
      "epoch 13/30\n",
      "111552/111527 [==============================] - 148s 1ms/step - loss: 3.9078 - acc: 0.1434\n",
      "\n",
      "epoch 14/30\n",
      "111552/111527 [==============================] - 149s 1ms/step - loss: 3.8923 - acc: 0.1444\n",
      "\n",
      "epoch 15/30\n",
      "111552/111527 [==============================] - 149s 1ms/step - loss: 3.8773 - acc: 0.1453\n",
      "Saving checkpoint for epoch 15 at ./checkpoints2/train\\ckpt-7\n",
      "\n",
      "epoch 16/30\n",
      "111552/111527 [==============================] - 149s 1ms/step - loss: 3.8624 - acc: 0.1463\n",
      "\n",
      "epoch 17/30\n",
      "111552/111527 [==============================] - 148s 1ms/step - loss: 3.8478 - acc: 0.1473\n",
      "\n",
      "epoch 18/30\n",
      "111552/111527 [==============================] - 151s 1ms/step - loss: 3.8336 - acc: 0.1482\n",
      "\n",
      "epoch 19/30\n",
      "111552/111527 [==============================] - 153s 1ms/step - loss: 3.8196 - acc: 0.1491\n",
      "\n",
      "epoch 20/30\n",
      "111552/111527 [==============================] - 151s 1ms/step - loss: 3.8059 - acc: 0.1500\n",
      "Saving checkpoint for epoch 20 at ./checkpoints2/train\\ckpt-8\n",
      "\n",
      "epoch 21/30\n",
      "111552/111527 [==============================] - 151s 1ms/step - loss: 3.7925 - acc: 0.1509\n",
      "\n",
      "epoch 22/30\n",
      "111552/111527 [==============================] - 153s 1ms/step - loss: 3.7793 - acc: 0.1518\n",
      "\n",
      "epoch 23/30\n",
      "111552/111527 [==============================] - 150s 1ms/step - loss: 3.7663 - acc: 0.1526\n",
      "\n",
      "epoch 24/30\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.7536 - acc: 0.1534\n",
      "\n",
      "epoch 25/30\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.7411 - acc: 0.1543\n",
      "Saving checkpoint for epoch 25 at ./checkpoints2/train\\ckpt-9\n",
      "\n",
      "epoch 26/30\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.7288 - acc: 0.1551\n",
      "\n",
      "epoch 27/30\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.7167 - acc: 0.1559\n",
      "\n",
      "epoch 28/30\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.7048 - acc: 0.1567\n",
      "\n",
      "epoch 29/30\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.6931 - acc: 0.1574\n",
      "\n",
      "epoch 30/30\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.6816 - acc: 0.1582\n",
      "Saving checkpoint for epoch 30 at ./checkpoints2/train\\ckpt-10\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "batch_size = 64\n",
    "metrics_names = ['loss', 'acc'] \n",
    "# train_loss.reset_states()\n",
    "# train_accuracy.reset_states()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
    "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
    " \n",
    "    # inp -> question, tar -> answer\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        \n",
    "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
    "        \n",
    "        pb_i.add(batch_size, values=values) \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364afa5",
   "metadata": {},
   "source": [
    "## Learning is slow, but not stagnant (-__-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "47943fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 51/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.6703 - acc: 0.1589\n",
      "\n",
      "epoch 52/100\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.6591 - acc: 0.1597\n",
      "\n",
      "epoch 53/100\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.6481 - acc: 0.1604\n",
      "\n",
      "epoch 54/100\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.6373 - acc: 0.1611\n",
      "\n",
      "epoch 55/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.6266 - acc: 0.1618\n",
      "Saving checkpoint for epoch 55 at ./checkpoints2/train\\ckpt-11\n",
      "\n",
      "epoch 56/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.6161 - acc: 0.1625\n",
      "\n",
      "epoch 57/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.6057 - acc: 0.1632\n",
      "\n",
      "epoch 58/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.5955 - acc: 0.1639\n",
      "\n",
      "epoch 59/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.5855 - acc: 0.1646\n",
      "\n",
      "epoch 60/100\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.5755 - acc: 0.1652\n",
      "Saving checkpoint for epoch 60 at ./checkpoints2/train\\ckpt-12\n",
      "\n",
      "epoch 61/100\n",
      "111552/111527 [==============================] - 144s 1ms/step - loss: 3.5657 - acc: 0.1659\n",
      "\n",
      "epoch 62/100\n",
      "111552/111527 [==============================] - 144s 1ms/step - loss: 3.5561 - acc: 0.1665\n",
      "\n",
      "epoch 63/100\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.5465 - acc: 0.1671\n",
      "\n",
      "epoch 64/100\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.5371 - acc: 0.1678\n",
      "\n",
      "epoch 65/100\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.5278 - acc: 0.1684\n",
      "Saving checkpoint for epoch 65 at ./checkpoints2/train\\ckpt-13\n",
      "\n",
      "epoch 66/100\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.5186 - acc: 0.1690\n",
      "\n",
      "epoch 67/100\n",
      "111552/111527 [==============================] - 265s 2ms/step - loss: 3.5094 - acc: 0.1696\n",
      "\n",
      "epoch 68/100\n",
      "111552/111527 [==============================] - 364s 3ms/step - loss: 3.5004 - acc: 0.1702\n",
      "\n",
      "epoch 69/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.4914 - acc: 0.1708\n",
      "\n",
      "epoch 70/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.4825 - acc: 0.1714\n",
      "Saving checkpoint for epoch 70 at ./checkpoints2/train\\ckpt-14\n",
      "\n",
      "epoch 71/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.4737 - acc: 0.1719\n",
      "\n",
      "epoch 72/100\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.4650 - acc: 0.1725\n",
      "\n",
      "epoch 73/100\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.4564 - acc: 0.1730\n",
      "\n",
      "epoch 74/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.4479 - acc: 0.1736\n",
      "\n",
      "epoch 75/100\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.4394 - acc: 0.1741\n",
      "Saving checkpoint for epoch 75 at ./checkpoints2/train\\ckpt-15\n",
      "\n",
      "epoch 76/100\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.4311 - acc: 0.1747\n",
      "\n",
      "epoch 77/100\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.4229 - acc: 0.1752\n",
      "\n",
      "epoch 78/100\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.4148 - acc: 0.1757\n",
      "\n",
      "epoch 79/100\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.4068 - acc: 0.1762\n",
      "\n",
      "epoch 80/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3989 - acc: 0.1768\n",
      "Saving checkpoint for epoch 80 at ./checkpoints2/train\\ckpt-16\n",
      "\n",
      "epoch 81/100\n",
      "111552/111527 [==============================] - 140s 1ms/step - loss: 3.3912 - acc: 0.1773\n",
      "\n",
      "epoch 82/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3837 - acc: 0.1778\n",
      "\n",
      "epoch 83/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3762 - acc: 0.1783\n",
      "\n",
      "epoch 84/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3689 - acc: 0.1787\n",
      "\n",
      "epoch 85/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3617 - acc: 0.1792\n",
      "Saving checkpoint for epoch 85 at ./checkpoints2/train\\ckpt-17\n",
      "\n",
      "epoch 86/100\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.3546 - acc: 0.1797\n",
      "\n",
      "epoch 87/100\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.3476 - acc: 0.1802\n",
      "\n",
      "epoch 88/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3407 - acc: 0.1807\n",
      "\n",
      "epoch 89/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3339 - acc: 0.1811\n",
      "\n",
      "epoch 90/100\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.3273 - acc: 0.1816\n",
      "Saving checkpoint for epoch 90 at ./checkpoints2/train\\ckpt-18\n",
      "\n",
      "epoch 91/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3206 - acc: 0.1820\n",
      "\n",
      "epoch 92/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3141 - acc: 0.1825\n",
      "\n",
      "epoch 93/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3077 - acc: 0.1829\n",
      "\n",
      "epoch 94/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.3012 - acc: 0.1834\n",
      "\n",
      "epoch 95/100\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2949 - acc: 0.1838\n",
      "Saving checkpoint for epoch 95 at ./checkpoints2/train\\ckpt-19\n",
      "\n",
      "epoch 96/100\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2886 - acc: 0.1843\n",
      "\n",
      "epoch 97/100\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2824 - acc: 0.1847\n",
      "\n",
      "epoch 98/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.2763 - acc: 0.1851\n",
      "\n",
      "epoch 99/100\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2702 - acc: 0.1855\n",
      "\n",
      "epoch 100/100\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.2642 - acc: 0.1860\n",
      "Saving checkpoint for epoch 100 at ./checkpoints2/train\\ckpt-20\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "batch_size = 64\n",
    "metrics_names = ['loss', 'acc'] \n",
    "# train_loss.reset_states()\n",
    "# train_accuracy.reset_states()\n",
    "for epoch in range(50, EPOCHS):\n",
    "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
    "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
    " \n",
    "    # inp -> question, tar -> answer\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        \n",
    "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
    "        \n",
    "        pb_i.add(batch_size, values=values) \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "c533244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 101/150\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2584 - acc: 0.1864\n",
      "\n",
      "epoch 102/150\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2525 - acc: 0.1868\n",
      "\n",
      "epoch 103/150\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2468 - acc: 0.1872\n",
      "\n",
      "epoch 104/150\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2411 - acc: 0.1876\n",
      "\n",
      "epoch 105/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.2355 - acc: 0.1880\n",
      "Saving checkpoint for epoch 105 at ./checkpoints2/train\\ckpt-21\n",
      "\n",
      "epoch 106/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.2300 - acc: 0.1884\n",
      "\n",
      "epoch 107/150\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.2245 - acc: 0.1888\n",
      "\n",
      "epoch 108/150\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.2192 - acc: 0.1892\n",
      "\n",
      "epoch 109/150\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.2139 - acc: 0.1895\n",
      "\n",
      "epoch 110/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.2086 - acc: 0.1899\n",
      "Saving checkpoint for epoch 110 at ./checkpoints2/train\\ckpt-22\n",
      "\n",
      "epoch 111/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.2034 - acc: 0.1903\n",
      "\n",
      "epoch 112/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1983 - acc: 0.1907\n",
      "\n",
      "epoch 113/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1932 - acc: 0.1910\n",
      "\n",
      "epoch 114/150\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.1881 - acc: 0.1914\n",
      "\n",
      "epoch 115/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1831 - acc: 0.1918\n",
      "Saving checkpoint for epoch 115 at ./checkpoints2/train\\ckpt-23\n",
      "\n",
      "epoch 116/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1781 - acc: 0.1921\n",
      "\n",
      "epoch 117/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1732 - acc: 0.1925\n",
      "\n",
      "epoch 118/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1683 - acc: 0.1928\n",
      "\n",
      "epoch 119/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1634 - acc: 0.1932\n",
      "\n",
      "epoch 120/150\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 3.1586 - acc: 0.1936\n",
      "Saving checkpoint for epoch 120 at ./checkpoints2/train\\ckpt-24\n",
      "\n",
      "epoch 121/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1538 - acc: 0.1939\n",
      "\n",
      "epoch 122/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1490 - acc: 0.1942\n",
      "\n",
      "epoch 123/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1442 - acc: 0.1946\n",
      "\n",
      "epoch 124/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1395 - acc: 0.1949\n",
      "\n",
      "epoch 125/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1348 - acc: 0.1953\n",
      "Saving checkpoint for epoch 125 at ./checkpoints2/train\\ckpt-25\n",
      "\n",
      "epoch 126/150\n",
      "111552/111527 [==============================] - 144s 1ms/step - loss: 3.1301 - acc: 0.1956\n",
      "\n",
      "epoch 127/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1255 - acc: 0.1960\n",
      "\n",
      "epoch 128/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1209 - acc: 0.1963\n",
      "\n",
      "epoch 129/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1163 - acc: 0.1966\n",
      "\n",
      "epoch 130/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1118 - acc: 0.1969\n",
      "Saving checkpoint for epoch 130 at ./checkpoints2/train\\ckpt-26\n",
      "\n",
      "epoch 131/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1072 - acc: 0.1973\n",
      "\n",
      "epoch 132/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.1027 - acc: 0.1976\n",
      "\n",
      "epoch 133/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0983 - acc: 0.1979\n",
      "\n",
      "epoch 134/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0938 - acc: 0.1982\n",
      "\n",
      "epoch 135/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0894 - acc: 0.1986\n",
      "Saving checkpoint for epoch 135 at ./checkpoints2/train\\ckpt-27\n",
      "\n",
      "epoch 136/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0850 - acc: 0.1989\n",
      "\n",
      "epoch 137/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0806 - acc: 0.1992\n",
      "\n",
      "epoch 138/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0763 - acc: 0.1995\n",
      "\n",
      "epoch 139/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0720 - acc: 0.1998\n",
      "\n",
      "epoch 140/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0677 - acc: 0.2001\n",
      "Saving checkpoint for epoch 140 at ./checkpoints2/train\\ckpt-28\n",
      "\n",
      "epoch 141/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0635 - acc: 0.2004\n",
      "\n",
      "epoch 142/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0593 - acc: 0.2007\n",
      "\n",
      "epoch 143/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0550 - acc: 0.2010\n",
      "\n",
      "epoch 144/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0509 - acc: 0.2013\n",
      "\n",
      "epoch 145/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0467 - acc: 0.2016\n",
      "Saving checkpoint for epoch 145 at ./checkpoints2/train\\ckpt-29\n",
      "\n",
      "epoch 146/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0426 - acc: 0.2019\n",
      "\n",
      "epoch 147/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0385 - acc: 0.2022\n",
      "\n",
      "epoch 148/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0344 - acc: 0.2025\n",
      "\n",
      "epoch 149/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0304 - acc: 0.2028\n",
      "\n",
      "epoch 150/150\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 3.0263 - acc: 0.2031\n",
      "Saving checkpoint for epoch 150 at ./checkpoints2/train\\ckpt-30\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 150\n",
    "batch_size = 64\n",
    "metrics_names = ['loss', 'acc'] \n",
    "# train_loss.reset_states()\n",
    "# train_accuracy.reset_states()\n",
    "for epoch in range(100, EPOCHS):\n",
    "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
    "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
    " \n",
    "    # inp -> question, tar -> answer\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        \n",
    "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
    "        \n",
    "        pb_i.add(batch_size, values=values) \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "7ebb9b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 151/200\n",
      "111552/111527 [==============================] - 140s 1ms/step - loss: 3.0223 - acc: 0.2033\n",
      "\n",
      "epoch 152/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.0183 - acc: 0.2036\n",
      "\n",
      "epoch 153/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.0144 - acc: 0.2039\n",
      "\n",
      "epoch 154/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.0105 - acc: 0.2042\n",
      "\n",
      "epoch 155/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.0066 - acc: 0.2045\n",
      "Saving checkpoint for epoch 155 at ./checkpoints2/train\\ckpt-31\n",
      "\n",
      "epoch 156/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 3.0027 - acc: 0.2047\n",
      "\n",
      "epoch 157/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9989 - acc: 0.2050\n",
      "\n",
      "epoch 158/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9950 - acc: 0.2053\n",
      "\n",
      "epoch 159/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9912 - acc: 0.2056\n",
      "\n",
      "epoch 160/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9875 - acc: 0.2058\n",
      "Saving checkpoint for epoch 160 at ./checkpoints2/train\\ckpt-32\n",
      "\n",
      "epoch 161/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9837 - acc: 0.2061\n",
      "\n",
      "epoch 162/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9800 - acc: 0.2063\n",
      "\n",
      "epoch 163/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9763 - acc: 0.2066\n",
      "\n",
      "epoch 164/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9726 - acc: 0.2069\n",
      "\n",
      "epoch 165/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9689 - acc: 0.2071\n",
      "Saving checkpoint for epoch 165 at ./checkpoints2/train\\ckpt-33\n",
      "\n",
      "epoch 166/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9653 - acc: 0.2074\n",
      "\n",
      "epoch 167/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9617 - acc: 0.2077\n",
      "\n",
      "epoch 168/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9581 - acc: 0.2079\n",
      "\n",
      "epoch 169/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9546 - acc: 0.2082\n",
      "\n",
      "epoch 170/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9510 - acc: 0.2084\n",
      "Saving checkpoint for epoch 170 at ./checkpoints2/train\\ckpt-34\n",
      "\n",
      "epoch 171/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9475 - acc: 0.2087\n",
      "\n",
      "epoch 172/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9440 - acc: 0.2089\n",
      "\n",
      "epoch 173/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9406 - acc: 0.2092\n",
      "\n",
      "epoch 174/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.9371 - acc: 0.2094\n",
      "\n",
      "epoch 175/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9337 - acc: 0.2097\n",
      "Saving checkpoint for epoch 175 at ./checkpoints2/train\\ckpt-35\n",
      "\n",
      "epoch 176/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9303 - acc: 0.2099\n",
      "\n",
      "epoch 177/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9269 - acc: 0.2101\n",
      "\n",
      "epoch 178/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9235 - acc: 0.2104\n",
      "\n",
      "epoch 179/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9202 - acc: 0.2106\n",
      "\n",
      "epoch 180/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9168 - acc: 0.2109\n",
      "Saving checkpoint for epoch 180 at ./checkpoints2/train\\ckpt-36\n",
      "\n",
      "epoch 181/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9135 - acc: 0.2111\n",
      "\n",
      "epoch 182/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9102 - acc: 0.2113\n",
      "\n",
      "epoch 183/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9069 - acc: 0.2116\n",
      "\n",
      "epoch 184/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9037 - acc: 0.2118\n",
      "\n",
      "epoch 185/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.9004 - acc: 0.2120\n",
      "Saving checkpoint for epoch 185 at ./checkpoints2/train\\ckpt-37\n",
      "\n",
      "epoch 186/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8972 - acc: 0.2123\n",
      "\n",
      "epoch 187/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8941 - acc: 0.2125\n",
      "\n",
      "epoch 188/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8909 - acc: 0.2127\n",
      "\n",
      "epoch 189/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8877 - acc: 0.2129\n",
      "\n",
      "epoch 190/200\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8846 - acc: 0.2132\n",
      "Saving checkpoint for epoch 190 at ./checkpoints2/train\\ckpt-38\n",
      "\n",
      "epoch 191/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.8815 - acc: 0.2134\n",
      "\n",
      "epoch 192/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8784 - acc: 0.2136\n",
      "\n",
      "epoch 193/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8753 - acc: 0.2138\n",
      "\n",
      "epoch 194/200\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8722 - acc: 0.2141\n",
      "\n",
      "epoch 195/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8692 - acc: 0.2143\n",
      "Saving checkpoint for epoch 195 at ./checkpoints2/train\\ckpt-39\n",
      "\n",
      "epoch 196/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.8662 - acc: 0.2145\n",
      "\n",
      "epoch 197/200\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8632 - acc: 0.2147\n",
      "\n",
      "epoch 198/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.8602 - acc: 0.2149\n",
      "\n",
      "epoch 199/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.8572 - acc: 0.2151\n",
      "\n",
      "epoch 200/200\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.8543 - acc: 0.2153\n",
      "Saving checkpoint for epoch 200 at ./checkpoints2/train\\ckpt-40\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "batch_size = 64\n",
    "metrics_names = ['loss', 'acc'] \n",
    "# train_loss.reset_states()\n",
    "# train_accuracy.reset_states()\n",
    "for epoch in range(150, EPOCHS):\n",
    "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
    "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
    " \n",
    "    # inp -> question, tar -> answer\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        \n",
    "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
    "        \n",
    "        pb_i.add(batch_size, values=values) \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "fa114565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 201/300\n",
      "111552/111527 [==============================] - 140s 1ms/step - loss: 2.8513 - acc: 0.2156\n",
      "\n",
      "epoch 202/300\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.8484 - acc: 0.2158\n",
      "\n",
      "epoch 203/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8455 - acc: 0.2160\n",
      "\n",
      "epoch 204/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8426 - acc: 0.2162\n",
      "\n",
      "epoch 205/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8398 - acc: 0.2164\n",
      "Saving checkpoint for epoch 205 at ./checkpoints2/train\\ckpt-41\n",
      "\n",
      "epoch 206/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8369 - acc: 0.2166\n",
      "\n",
      "epoch 207/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8341 - acc: 0.2168\n",
      "\n",
      "epoch 208/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8312 - acc: 0.2170\n",
      "\n",
      "epoch 209/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8284 - acc: 0.2172\n",
      "\n",
      "epoch 210/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8256 - acc: 0.2174\n",
      "Saving checkpoint for epoch 210 at ./checkpoints2/train\\ckpt-42\n",
      "\n",
      "epoch 211/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8228 - acc: 0.2176\n",
      "\n",
      "epoch 212/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8201 - acc: 0.2178\n",
      "\n",
      "epoch 213/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8173 - acc: 0.2180\n",
      "\n",
      "epoch 214/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.8146 - acc: 0.2182\n",
      "\n",
      "epoch 215/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8118 - acc: 0.2184\n",
      "Saving checkpoint for epoch 215 at ./checkpoints2/train\\ckpt-43\n",
      "\n",
      "epoch 216/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8091 - acc: 0.2186\n",
      "\n",
      "epoch 217/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8064 - acc: 0.2188\n",
      "\n",
      "epoch 218/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8037 - acc: 0.2190\n",
      "\n",
      "epoch 219/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.8011 - acc: 0.2192\n",
      "\n",
      "epoch 220/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7984 - acc: 0.2194\n",
      "Saving checkpoint for epoch 220 at ./checkpoints2/train\\ckpt-44\n",
      "\n",
      "epoch 221/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7958 - acc: 0.2195\n",
      "\n",
      "epoch 222/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7931 - acc: 0.2197\n",
      "\n",
      "epoch 223/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7905 - acc: 0.2199\n",
      "\n",
      "epoch 224/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7879 - acc: 0.2201\n",
      "\n",
      "epoch 225/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7853 - acc: 0.2203\n",
      "Saving checkpoint for epoch 225 at ./checkpoints2/train\\ckpt-45\n",
      "\n",
      "epoch 226/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7827 - acc: 0.2205\n",
      "\n",
      "epoch 227/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7802 - acc: 0.2207\n",
      "\n",
      "epoch 228/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7776 - acc: 0.2208\n",
      "\n",
      "epoch 229/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7751 - acc: 0.2210\n",
      "\n",
      "epoch 230/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7726 - acc: 0.2212\n",
      "Saving checkpoint for epoch 230 at ./checkpoints2/train\\ckpt-46\n",
      "\n",
      "epoch 231/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7700 - acc: 0.2214\n",
      "\n",
      "epoch 232/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7675 - acc: 0.2216\n",
      "\n",
      "epoch 233/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7651 - acc: 0.2217\n",
      "\n",
      "epoch 234/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7626 - acc: 0.2219\n",
      "\n",
      "epoch 235/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7601 - acc: 0.2221\n",
      "Saving checkpoint for epoch 235 at ./checkpoints2/train\\ckpt-47\n",
      "\n",
      "epoch 236/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7577 - acc: 0.2223\n",
      "\n",
      "epoch 237/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7552 - acc: 0.2225\n",
      "\n",
      "epoch 238/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7528 - acc: 0.2226\n",
      "\n",
      "epoch 239/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7504 - acc: 0.2228\n",
      "\n",
      "epoch 240/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7481 - acc: 0.2230\n",
      "Saving checkpoint for epoch 240 at ./checkpoints2/train\\ckpt-48\n",
      "\n",
      "epoch 241/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7457 - acc: 0.2231\n",
      "\n",
      "epoch 242/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7433 - acc: 0.2233\n",
      "\n",
      "epoch 243/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7410 - acc: 0.2235\n",
      "\n",
      "epoch 244/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7386 - acc: 0.2237\n",
      "\n",
      "epoch 245/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7363 - acc: 0.2238\n",
      "Saving checkpoint for epoch 245 at ./checkpoints2/train\\ckpt-49\n",
      "\n",
      "epoch 246/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7339 - acc: 0.2240\n",
      "\n",
      "epoch 247/300\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.7316 - acc: 0.2242\n",
      "\n",
      "epoch 248/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7292 - acc: 0.2243\n",
      "\n",
      "epoch 249/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7269 - acc: 0.2245\n",
      "\n",
      "epoch 250/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7245 - acc: 0.2247\n",
      "Saving checkpoint for epoch 250 at ./checkpoints2/train\\ckpt-50\n",
      "\n",
      "epoch 251/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7222 - acc: 0.2248\n",
      "\n",
      "epoch 252/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7199 - acc: 0.2250\n",
      "\n",
      "epoch 253/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7175 - acc: 0.2252\n",
      "\n",
      "epoch 254/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7152 - acc: 0.2253\n",
      "\n",
      "epoch 255/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7129 - acc: 0.2255\n",
      "Saving checkpoint for epoch 255 at ./checkpoints2/train\\ckpt-51\n",
      "\n",
      "epoch 256/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7107 - acc: 0.2256\n",
      "\n",
      "epoch 257/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7084 - acc: 0.2258\n",
      "\n",
      "epoch 258/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7062 - acc: 0.2260\n",
      "\n",
      "epoch 259/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.7039 - acc: 0.2261\n",
      "\n",
      "epoch 260/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.7017 - acc: 0.2263\n",
      "Saving checkpoint for epoch 260 at ./checkpoints2/train\\ckpt-52\n",
      "\n",
      "epoch 261/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6994 - acc: 0.2264\n",
      "\n",
      "epoch 262/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6972 - acc: 0.2266\n",
      "\n",
      "epoch 263/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6950 - acc: 0.2267\n",
      "\n",
      "epoch 264/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6928 - acc: 0.2269\n",
      "\n",
      "epoch 265/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6906 - acc: 0.2271\n",
      "Saving checkpoint for epoch 265 at ./checkpoints2/train\\ckpt-53\n",
      "\n",
      "epoch 266/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6884 - acc: 0.2272\n",
      "\n",
      "epoch 267/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6862 - acc: 0.2274\n",
      "\n",
      "epoch 268/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6841 - acc: 0.2275\n",
      "\n",
      "epoch 269/300\n",
      "111552/111527 [==============================] - 144s 1ms/step - loss: 2.6819 - acc: 0.2277\n",
      "\n",
      "epoch 270/300\n",
      "111552/111527 [==============================] - 144s 1ms/step - loss: 2.6797 - acc: 0.2278\n",
      "Saving checkpoint for epoch 270 at ./checkpoints2/train\\ckpt-54\n",
      "\n",
      "epoch 271/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6776 - acc: 0.2280\n",
      "\n",
      "epoch 272/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6754 - acc: 0.2281\n",
      "\n",
      "epoch 273/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6733 - acc: 0.2283\n",
      "\n",
      "epoch 274/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6711 - acc: 0.2284\n",
      "\n",
      "epoch 275/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6690 - acc: 0.2286\n",
      "Saving checkpoint for epoch 275 at ./checkpoints2/train\\ckpt-55\n",
      "\n",
      "epoch 276/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6668 - acc: 0.2287\n",
      "\n",
      "epoch 277/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6647 - acc: 0.2289\n",
      "\n",
      "epoch 278/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6626 - acc: 0.2290\n",
      "\n",
      "epoch 279/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6605 - acc: 0.2292\n",
      "\n",
      "epoch 280/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6584 - acc: 0.2293\n",
      "Saving checkpoint for epoch 280 at ./checkpoints2/train\\ckpt-56\n",
      "\n",
      "epoch 281/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6563 - acc: 0.2295\n",
      "\n",
      "epoch 282/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6542 - acc: 0.2296\n",
      "\n",
      "epoch 283/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6521 - acc: 0.2298\n",
      "\n",
      "epoch 284/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6500 - acc: 0.2299\n",
      "\n",
      "epoch 285/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6480 - acc: 0.2301\n",
      "Saving checkpoint for epoch 285 at ./checkpoints2/train\\ckpt-57\n",
      "\n",
      "epoch 286/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6459 - acc: 0.2302\n",
      "\n",
      "epoch 287/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6439 - acc: 0.2304\n",
      "\n",
      "epoch 288/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6418 - acc: 0.2305\n",
      "\n",
      "epoch 289/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6398 - acc: 0.2306\n",
      "\n",
      "epoch 290/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6378 - acc: 0.2308\n",
      "Saving checkpoint for epoch 290 at ./checkpoints2/train\\ckpt-58\n",
      "\n",
      "epoch 291/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6357 - acc: 0.2309\n",
      "\n",
      "epoch 292/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6337 - acc: 0.2311\n",
      "\n",
      "epoch 293/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6317 - acc: 0.2312\n",
      "\n",
      "epoch 294/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6298 - acc: 0.2313\n",
      "\n",
      "epoch 295/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6278 - acc: 0.2315\n",
      "Saving checkpoint for epoch 295 at ./checkpoints2/train\\ckpt-59\n",
      "\n",
      "epoch 296/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6258 - acc: 0.2316\n",
      "\n",
      "epoch 297/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6239 - acc: 0.2318\n",
      "\n",
      "epoch 298/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6220 - acc: 0.2319\n",
      "\n",
      "epoch 299/300\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.6201 - acc: 0.2320\n",
      "\n",
      "epoch 300/300\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6182 - acc: 0.2322\n",
      "Saving checkpoint for epoch 300 at ./checkpoints2/train\\ckpt-60\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 300\n",
    "batch_size = 64\n",
    "metrics_names = ['loss', 'acc'] \n",
    "# train_loss.reset_states()\n",
    "# train_accuracy.reset_states()\n",
    "for epoch in range(200, EPOCHS):\n",
    "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
    "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
    " \n",
    "    # inp -> question, tar -> answer\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        \n",
    "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
    "        \n",
    "        pb_i.add(batch_size, values=values) \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "88154466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 301/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6134 - acc: 0.2325\n",
      "\n",
      "epoch 302/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6115 - acc: 0.2326\n",
      "\n",
      "epoch 303/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6096 - acc: 0.2328\n",
      "\n",
      "epoch 304/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6078 - acc: 0.2329\n",
      "\n",
      "epoch 305/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.6059 - acc: 0.2330\n",
      "Saving checkpoint for epoch 305 at ./checkpoints2/train\\ckpt-61\n",
      "\n",
      "epoch 306/350\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.6041 - acc: 0.2331\n",
      "\n",
      "epoch 307/350\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.6023 - acc: 0.2333\n",
      "\n",
      "epoch 308/350\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.6005 - acc: 0.2334\n",
      "\n",
      "epoch 309/350\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.5986 - acc: 0.2335\n",
      "\n",
      "epoch 310/350\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.5968 - acc: 0.2337\n",
      "Saving checkpoint for epoch 310 at ./checkpoints2/train\\ckpt-62\n",
      "\n",
      "epoch 311/350\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.5950 - acc: 0.2338\n",
      "\n",
      "epoch 312/350\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.5932 - acc: 0.2339\n",
      "\n",
      "epoch 313/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5914 - acc: 0.2340\n",
      "\n",
      "epoch 314/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5896 - acc: 0.2342\n",
      "\n",
      "epoch 315/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5878 - acc: 0.2343\n",
      "Saving checkpoint for epoch 315 at ./checkpoints2/train\\ckpt-63\n",
      "\n",
      "epoch 316/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5861 - acc: 0.2344\n",
      "\n",
      "epoch 317/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5843 - acc: 0.2345\n",
      "\n",
      "epoch 318/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5825 - acc: 0.2346\n",
      "\n",
      "epoch 319/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5808 - acc: 0.2348\n",
      "\n",
      "epoch 320/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5790 - acc: 0.2349\n",
      "Saving checkpoint for epoch 320 at ./checkpoints2/train\\ckpt-64\n",
      "\n",
      "epoch 321/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5773 - acc: 0.2350\n",
      "\n",
      "epoch 322/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5755 - acc: 0.2351\n",
      "\n",
      "epoch 323/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5738 - acc: 0.2352\n",
      "\n",
      "epoch 324/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5721 - acc: 0.2354\n",
      "\n",
      "epoch 325/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5704 - acc: 0.2355\n",
      "Saving checkpoint for epoch 325 at ./checkpoints2/train\\ckpt-65\n",
      "\n",
      "epoch 326/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5686 - acc: 0.2356\n",
      "\n",
      "epoch 327/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5670 - acc: 0.2357\n",
      "\n",
      "epoch 328/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5653 - acc: 0.2358\n",
      "\n",
      "epoch 329/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5636 - acc: 0.2360\n",
      "\n",
      "epoch 330/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5619 - acc: 0.2361\n",
      "Saving checkpoint for epoch 330 at ./checkpoints2/train\\ckpt-66\n",
      "\n",
      "epoch 331/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5602 - acc: 0.2362\n",
      "\n",
      "epoch 332/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5586 - acc: 0.2363\n",
      "\n",
      "epoch 333/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5569 - acc: 0.2364\n",
      "\n",
      "epoch 334/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5553 - acc: 0.2365\n",
      "\n",
      "epoch 335/350\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.5536 - acc: 0.2367\n",
      "Saving checkpoint for epoch 335 at ./checkpoints2/train\\ckpt-67\n",
      "\n",
      "epoch 336/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5520 - acc: 0.2368\n",
      "\n",
      "epoch 337/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5504 - acc: 0.2369\n",
      "\n",
      "epoch 338/350\n",
      "111552/111527 [==============================] - 141s 1ms/step - loss: 2.5488 - acc: 0.2370\n",
      "\n",
      "epoch 339/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5472 - acc: 0.2371\n",
      "\n",
      "epoch 340/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5456 - acc: 0.2372\n",
      "Saving checkpoint for epoch 340 at ./checkpoints2/train\\ckpt-68\n",
      "\n",
      "epoch 341/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5440 - acc: 0.2374\n",
      "\n",
      "epoch 342/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5424 - acc: 0.2375\n",
      "\n",
      "epoch 343/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5408 - acc: 0.2376\n",
      "\n",
      "epoch 344/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5393 - acc: 0.2377\n",
      "\n",
      "epoch 345/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5377 - acc: 0.2378\n",
      "Saving checkpoint for epoch 345 at ./checkpoints2/train\\ckpt-69\n",
      "\n",
      "epoch 346/350\n",
      "111552/111527 [==============================] - 142s 1ms/step - loss: 2.5362 - acc: 0.2379\n",
      "\n",
      "epoch 347/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5347 - acc: 0.2380\n",
      "\n",
      "epoch 348/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5332 - acc: 0.2381\n",
      "\n",
      "epoch 349/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5316 - acc: 0.2383\n",
      "\n",
      "epoch 350/350\n",
      "111552/111527 [==============================] - 143s 1ms/step - loss: 2.5301 - acc: 0.2384\n",
      "Saving checkpoint for epoch 350 at ./checkpoints2/train\\ckpt-70\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 350\n",
    "batch_size = 64\n",
    "metrics_names = ['loss', 'acc'] \n",
    "# train_loss.reset_states()\n",
    "# train_accuracy.reset_states()\n",
    "for epoch in range(300, EPOCHS):\n",
    "    print(\"\\nepoch {}/{}\".format(epoch+1,EPOCHS))\n",
    "    pb_i = Progbar(train.shape[0], stateful_metrics=metrics_names)\n",
    " \n",
    "    # inp -> question, tar -> answer\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        \n",
    "        values=[('loss',train_loss.result()), ('acc',train_accuracy.result())]\n",
    "        \n",
    "        pb_i.add(batch_size, values=values) \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe7b10",
   "metadata": {},
   "source": [
    "# EPOCH:350, I think its enough, let's check what type of REPLIES that CHATBOT is generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "id": "578270c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(tokenizer_q, \"tokenizer_q\")\n",
    "# joblib.dump(tokenizer_a, \"tokenizer_a\")\n",
    "# transformer.save_weights('transformer_model/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c93b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    sentence = sentence.split(\" \")\n",
    "    predicted_sentence = predicted_sentence.split(\" \")\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "\n",
    "\n",
    "def plot_attention_weights(attention,tokenizer_q, tokenizer_a, sentence, result, layer):\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    sentence = tokenizer_q.encode(sentence)\n",
    "\n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "    #(1, 8, 5, 4) --> (8, 5, 4)\n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights [:-1, :]\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "        fontdict = {'fontsize': 10}\n",
    "        \n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)-1))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        x = ['<start>']+[tokenizer_q.decode([i]) for i in sentence]+['<end>']\n",
    "        y = [tokenizer_a.decode([i]) for i in result if i < tokenizer_a.vocab_size]\n",
    "        ax.set_xticklabels([''] + x, fontdict=fontdict, rotation=90)\n",
    "        ax.set_yticklabels([''] + y, fontdict=fontdict)\n",
    "\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "MAX_LENGTH = 27 \n",
    "\n",
    "def evaluate(inp_sentence, model,  tokenizer_q, tokenizer_a):\n",
    "    start_token = [tokenizer_q.vocab_size]\n",
    "    end_token = [tokenizer_q.vocab_size + 1]\n",
    "\n",
    "    # All questions has the start and end token\n",
    "    inp_sentence = start_token + tokenizer_q.encode(inp_sentence) + end_token\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "    # 'answers' start token : 27358\n",
    "    decoder_input = [tokenizer_a.vocab_size]\n",
    "    decoder_input = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, decoder_input)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = model(encoder_input, \n",
    "                                                     decoder_input,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == tokenizer_a.vocab_size+1:\n",
    "            print(f\"=============\\nGot end token\\n=============\")\n",
    "            return tf.squeeze(decoder_input, axis=0), attention_weights\n",
    "\n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        decoder_input = tf.concat([decoder_input, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(decoder_input, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f3aad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reply(sentence, transformer,  tokenizer_q, tokenizer_a, plot=''):\n",
    "    result, attention_weights = evaluate(sentence, transformer,  tokenizer_q, tokenizer_a)\n",
    "#     print(\"Attention_Blocks:\", list(attention_weights.keys()))\n",
    "    predicted_sentence = tokenizer_a.decode([i for i in result \n",
    "                                            if i < tokenizer_a.vocab_size])  \n",
    "  \n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights,tokenizer_q, tokenizer_a, sentence, result, plot)\n",
    "    return sentence, predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "1b5f1253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Attention_Blocks: ['decoder_layer1_block1', 'decoder_layer1_block2', 'decoder_layer2_block1', 'decoder_layer2_block2']\n",
      "Input: i was told ten thousand in each pack\n",
      "Predicted translation: you did not count it\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHgAAAHTCAYAAABcEa/JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABWBElEQVR4nO3deZhldX3v+/e35wm6AVsRIrbggIiA2g444TxrgmI0l6PB4ZBochHvURNjbswxxyRqcjyKJyYYZz3GOVFzHBIuglOCTAIiDlE4zsxTd9ND9ff+sVdj9VBVe1Prt/b+rXq/nqefqtq167N+tWvvT6/61tprR2YiSZIkSZKkei0a9wIkSZIkSZI0Pw54JEmSJEmSKueAR5IkSZIkqXIOeCRJkiRJkirngEeSJEmSJKlyDngkSZIkSZIq54BHkiRJkiSpcg54JEmSJEmSKueAR5IkSZIkqXIOeCRJkiRJkirngEeSJEmSJKlyS8a9AGkuEXEpkDN9PjOP6XA5khYAe0dSl+wcSV2yc/rLAY9q8Izm7e81bz/YvD0Z2Nz9ciQtAPaOpC7ZOZK6ZOf0VGTOOLiTJkpEfC0zHzHXZZLUFntHUpfsHEldsnP6x3PwqCarI+KRuz6IiIcDq8e4Hkn9Z+9I6pKdI6lLdk7P+BQt1eQlwHsiYm3z8Y3Ai8e3HEkLgL0jqUt2jqQu2Tk941O0VJ2I2J/Bffemca9F0sJg70jqkp0jqUt2Tn844FE1ImI58BxgA9OOPsvMN4xrTZL6zd6R1CU7R1KX7Jz+8Slaqsk/ATcBFwBbx7wWSQuDvSOpS3aOpC7ZOT3T6yN4IiKATwOvzczvjHs9mp+IuCwzjx73OqTZ2Dv9Yu9o0tk5/WLnaNLZOf1i5/RP319F60nARuCl416IWvH1iLj/uBchzcHe6Rd7R5POzukXO0eTzs7pFzunZ/p+BM/HgPcAbweOyswdY16S5iEiLgfuCfyIwSGEAWRmHjPWhUnT2Dv9Yu9o0tk5/WLnaNLZOf1i5/RPb8/BExF3Au6XmV+IiH8FTgQ+PuZlaX6eOu4FSLOxd3rJ3tHEsnN6yc7RxLJzesnO6Zk+P0XrhcBHmvffC7xkjGtRCzLzqsy8CtgC5LR/6lBEnBgRa8a9jgll7/SMvTN+ds6s7JyesXPGz86ZlZ3TM3bOZGizd/o84HkRg+IhM78J3DUi7jbeJWk+IuJZEfF9BocQngNcCXx+rItaYCLiCOBjwH8a91omlL3TM/bOeNk5c7JzesbOGS87Z052Ts/YOePXdu/0csATEeuAd2TmT6dd/CrgTuNZkVryZ8DDgO9l5j2AxwNfG++SFpwXA29q3moae6e37J3xsnNmYOf0lp0zXnbODOyc3rJzxq/V3unlgCczbwQu2+OyfwFWjWVBasv2zLwOWBQRizLzbOC4Ma9pwYiIxcBzGRTQTRFx7JiXNFHsnd6yd8bEzpmdndNbds6Y2Dmzs3N6y84ZoxK908sBT+OMIS9TPW5snpt4LvDhiHgb4Jn7u/M04OuZeQuDV0/w5TH3Zu/0j70zPnbO3Oyc/rFzxsfOmZud0z92zni13ju9e5n0iDgeeDhwOvDWaZ/aHzgxM53GVyoiVjM4Adgi4GRgLfDhZuqswiLiH4G/zsyvRMQK4NvAfTNz23hXNn72Tn/ZO+Nj58zMzukvO2d87JyZ2Tn9ZeeMV4ne6eMRPMuANQxeAn6/af9uBk4a47rUkszcAXyDwUnAbh7vahaG5nnX6zLzKwCZeRvwCeBx41zXBLF3es7e6ZadMyc7p+fsnG7ZOXOyc3rOzuleqd7p3RE8cPtz2T6amRZOj0TEBcCjgAOAfwPOBzZn5sljXZiEvdNX9o4mlZ3TT3aOJpWd0092Tv8sGfcCSsjMqYg4cNzrUOsiMzdHxEuAMzLzzRFx0bgX1XcR8cDZPp+ZF3a1lklm7/SWvdMxO2c4dk5v2Tkds3OGY+f0lp0zBiV7p5cDnsZFEfEZ4OPApl0XZuanxrckzVM0zwE+GXhJc1mf78OT4q+btyuAjcC3gACOAf4deOSY1jWJ7J3+sXe6Z+cMz87pHzune3bO8Oyc/rFzxqNY7/T5h3cgcB27P4ctAQuoXqcDrwU+nZnfjojDgbPHu6TRRMShwN2Z9tjLzHPHt6K5ZeZjASLiH4BTM/PS5uOjgVeNc20TyN7pn9OpuHfsnN6zc/rndOycTtk5I7Fz+ud0Ku4csHf21Mtz8EiTKCLeBDwPuByYai7OzHxWS/kbMvPKPS57cGZ+s6X8izPzuLkukzQZ7BxJXSrdOc02ivWOnSPVx32dfWT2dcDTvMzYS4D7MTj0CYDMfPHYFqV5iYizGfyVYDeZWcUrHETEd4FjMnNrofwLgWdm5k+bj08A3pGZ928p/yMMDsf9EIOfw38C1mTmb7WR3wf2Tv/U3Dt2Tv/ZOf1j58y5jWK9Y+fMzc7pn5o7B9zX2Zc+P0Xrg8AVwJOBNzB4XuF3xroizdf0w9VWAM8BdoxpLXfED4GlQKkdn98B/jEingk8EPhz4Gkt5r8IeBnwiubjc4F3tpjfB/ZO/9TcO3ZO/9k5/WPnzK5k79g5c7Nz+qfmzgH3dfbS5yN4LsrMB0TEJZl5TEQsBb5YyzRSw4mIczLzhHGvYzYRcQaDieyhwLHAWUwrocw8rcVtHQ/8HXAb8PTMvKatbM3N3lkYJr137JyFw85ZGOycvbZn74yJnbMwTHrngPs6s+nzETzbm7c3Nicr+gWwYXzLGV5EvBn4b8AW4AsM7rSnZ+aH5pFZ/UtA7vHSjIuABwEHj2k5ozi/eXsB8Jm2wyPis+x+aOUq4Cbg3RFBi89BfQTwp+x9ErPD28jviSp7x86ZWaW9Y+csHHbO7rnV946ds29d9I6dMxQ7Z/dcO2d83NeZKbPHR/C8FPgkcH/gfcAa4P/NzL8b57qGsevEShFxIvAbwCuBszPz2Hlk7job+j5fii0zJ/4lICPiRwweaMHg0MEfAW/IzK+OdWFDiojVwG2ZOdV8vBhYnpmb55k764Q9M8+ZT/607VzB4L54Ab86iRmZeV0b+X1Qa+/YOTOruXfsnP6zc/bKrb537JwZs4v3jp0zNztnr1w7Z8zc19lbn4/gOSszb2DwPLbDASLiHuNd0tCWNm+fBnwkM6+PiHkFZg9eAjIza/n5zeQs4AnArc3HK4EvAQ+fT+iugmnu3z/PzNuaj1cCd5lP9h5uyszPt5jXR7X2jp0zg8p7x87pPztnmj70jp2zbx31jp0zNztnGjtnIrivs4c+D3g+yeBESNN9gsFhZ5Pus800bwvw8ohYz+A5f204clf5AGTmZRFxXEvZRMRyBifn2sDuh5m9oYXspQxOQvXo5qIvA3+Xmdtn/KLJsiIzd5UPmXlrRKxqMf/j7F5mU81lD24p/+yIeAvwKXZ/juvEH37aoVp7x86ZOb/m3rFz+s/O2bdivWPnzKp050DZ3rFz5mbn7Fu1+zqVdw64r7OX3g14IuJIBi/dtzYinj3tU/sz7eX8Jllm/mFEvAm4OTOnImIT8OstxX8nIv6e3V+Krc2z3/8Tg+cnXkD7ZzN/J4MJ/N80H7+gueylLW+nlE0R8cBdD9iIeBCD/2jasiQzt+36IDO3RcSyFvMf2rzdOO2yBBb8ifVq7x07Z1Y1946d01N2zpxK9o6dM7PSnQNle8fOmYGdM6ea93Vq7hxwX2cvvRvwAPcBngGsA5457fJbgP88jgXdQYcCT4yI6aX5gRZyS78E5K9l5lNazJvuwXs8V/b/i4hvFdpWCacDH4+InzUf3xV4Xov510TEszLzMwAR8evAtW2F7zoMVfvUh96xc/at5t45HTunr+yc2ZXsHTtnZqdTtnOgYO/YObOyc2ZX875OzZ0D7uvspc8nWT4+M78x7nXcERHxeuAxwFHA/waeCnw1M08a57qGERFnAmdMP0yxxewLgedm5n80Hx8OfCIzZz2D/SRpDoO8D4MTmV3R5uGPEXEE8GHgkCb/x8ALM/MHLeXfBfhz4JDMfGpEHAUcn5nvbiO/D2rtHTtn1vyqe8fO6Tc7p3t2zuxKdk6TX6x37Jy52Tnj4e9Xs3NfZ4/MHg94irwcXhci4lIG670oM49tfvB/n5nPnONL58qc8Yedmcfc0ew9tnM5cE8GZ2DfyuCBkG3kR8TjgfcCP2xy7w68KDPPnvULJ0hz0rWjmHY4a2a29deDXdtYw+CxfUvLuZ9ncPu/rrlfLmFwH71/m9upWa29Y+fMml9179g5/Wbn7DO3aO/YObPronOa7bTeO3bO3OycfeZWva9Te+eA+zp76uNTtHZ5Uma+JgYvh/cT4LnA2QyeGznptmTmzojYERH7A1fTnKl+Hp7RwrqG8dRSwZl5VkTci90ntCWe/17ETH89oL3DQ4mIpzN4jvSKaF4dIFs68SNwp8z8WES8tsndERFTc33RAlNr79g5M6i5d+ycBcHO2V0XvWPnzKCLzmm2U6p37Jy52Tm7q35fp+bOAfd19qXPA54iL4fXkfMjYh3wLgYn07oVOG8+gZl51a73m6n1rjN/n5eZV88ne8/tRMQjgXtl5ntjcJb6NW3lMzhL/wYG991jI6LIX4YKOYlf/fXgRbv+etBWeET8LbAKeGyTexLzvN/sYVNEHETzl4qIeBiDE77pV2rtHTtndrX2jp3Tf3bONF30jp0zq6KdA8V7x86Zm50zTY/2dWrtHHBfZy99forWXwK/weAQwocwOCnY5zLzobN82cSJiA3A/pl5SUt5vwm8hcFL4AXwKODVmfmJlvJfz+As4PfJzHtHxCHAxzPzES1kfxA4AriYwUvUweDwxNPmmz1tGw9n75cgbKXgIuK8zHxIRFzAoCRuAS7LzPu1lH9JZh4z7e0a4FOZ+aSW8h8InAEcDVwGrAdOauu+2Qd96B07Z6/8or1j58yab+fMwc6ZMbNY79TeOc02ivRO6c5ptlGsd+ycudk5M2ZWu69Tc+c02e7r7KG3R/Dk3i+Ht5l2Xw6vmIj4APAV4CuZeUXL8a9jcLb0q5ttrQf+FWilgIATgQcAFwJk5s8iYr+WsjcCR2WhqeRMBUd7h/gV+evBNLteEnBzU/zXAfdoKzwzL4yIE/jVIZzfzZZPnli7WnvHzplVsd6xc2Zn58zNzplRyd6ptnOgeO+U7hwo2Dt2ztzsnBnVvK9Tc+eA+zp76eWAJyJWMTiEbfpLvB3Er+5Uk+59wCOBM2JwJvOLgXMz820tZC/a45DB64BFLeTusi0zMyJ2HWa2usXsy4CDgZ+3mDld0YLLzJc37/5tRHyBlv96AHyuKbg3Myg4aOkQxT0eU99uLjssIqYy86dtbKN2lffO+7BzZlKyd+ycGdg5c7NzZlWyd2ruHCjYOx10DhTqHTtnbnbOrGre16m2c8B9nX3mFrqtxyoGL5V2BXBMZm5qLvsS8EeZef5YFzekiFjM4HmcjwV+l8HJwY5sIfctwDHAR5qLngdcmpmvmW92k/8q4F7AE4G/AF7M4Dm6b59H5mcZTHr3A45jMJW9/eRfmfmseSx5+nY+DpyWmUUKLiICOBk4PDPfEBGHAQdnZitT5ohYCbyMwWGhyeAvFe/MzNtayK7+MVVa7beRnbNXbvHesXNmza768dSF2m+jUp3TZBfrnZo7p9lOsd4p3TnNNor0Tu2Ppy7UfhvV2jlNvr9fzZzvvs6euX0c8ABExF8Bl2fme5of9D9l5gPGva5hRMRZwGrgGwzuRF/NFk/UFRHPZjDFDgbT60+3ld3kPxF4UpP/xcz8l3nmnTDb5zPznPnkT9vO2ZQtuHcCO4HHZeZ9I+IA4EuZ+eA5vnTY/I8xeN7prlcy+C1gXWb+Zkv51T6mulLrbWTn7DOzeO/YOXPmV/l46lKtt1Hpzmm2Uax3au2cZjvFeqd05zTbKNY7tT6eulTrbVR75zT5/n6173z3dfaUmb38BxzJ4HmWAH/MYHI49nUNufa3AucC/wL8KfA4YGVL2W8a5rJJzO9g7Sfs61+L+Rc2by+adtm3WszfK6vl/GofU139q/U2snPGk2/nzJlf5eOpy3+13kYlO6fJr3lfpNp9ndKdM1NeW9uo9fHU5b9ab6OaO6d0fs2d0+S7r7PHvzafGzhRsjmBVkTcm8Gk7YPjXdHwMvOVmfloBifUug54L3BjS/FP3MdlT20pu3R+0bVn5jn7+tdWPrC9OTx01/Nn1zOYOLflohi8tB5N/kOBr7UVXvNjqiu13kZ2znjy7ZzZ1fp46lKtt1HhzoGK90VK5xfundKdAwV7p9bHU5dqvY0q75zS+TV3Drivs5denmR5mnczOAnSJZl5w3zDIuKrmfnIiLiF5k6061MMXk5u//luo9nO7zN4nt+DgKuA9zA4nHA+mS8DXg4cHhHTTzy1Hy3cSUvmd7D2Tn6uwNuBTwN3jog3AicxmNS25aHACyPi/zQfHwZ8JyIuZfB9HNPCNlp9TPVUa7eRndPPfDtnJHbO3OycX+XWvC/Sh32d0p0D5XvHzplbdb9f1dg5pfN70jngvs5eensOHmDXmal/DjwnM/913OsZVkS8msFhhBdk5o6WMtcCBzA4MdcfTvvULZl5/STnl157lyLiSODxDMrtrMz8TovZd5/t85l5VQvbqPIx1aUabyM7p/v8rtg5/VfjbVSic5rcavdF7Jyh84v2To2Pp67VeBvV2Dml8/vSOeC+zl55fR7wSJIkSZIkLQS9PQePJEmSJEnSQrEgBjwRcar53WeXzq957aXza157X/jz7T679vya1146386ZW823f835Na+9dL5r7zd/vv3Mr3ntpfNrWfuCGPAApUu65nzX3s/8mtfeF/58u8+uPb/mtZfOt3PmVvPtX3N+zWsvne/a+82fbz/za1576fwq1r5QBjySJEmSJEm9VeVJlhevWp1L1x049PWnNm9i8arVw28gRlvP1KZNLF49XP6yNdtGCwe23bSFZWtXDnXdrbctHSl76tZNLF4z/G2zZNNoN86O2zaxZMVw+Tv2G+2+OHXLJhbvN/zal1+5eaT87WxlKcuHvv7WDatGyh91/fff/9qhr3vNdVOsP2jx0Nf/9i/WD31dgKktm1i8cvi133b1T67NzNE2MmHudODi3HC34R9fo/4Mvn/F2qGvu21qC8sWD9cJAMRoj9ttU5tZtni0+/Pw2SOuHWBq5/D5O7ewbNEI+YuH/xnB6LdNbt069HVH7RyAWL5s6Ovekds+lwx/+2zfvomlS4fvhYPvMfyLdNx0/Q7WHrhk6Ov/8qfbuen6HSP+bz5Zli1bnStWHDD09bdt28SyZSPs64zwuNq+YzNLl4zQCYtH+/vhyGvfOdr+wqj3zdg+NfR1t+3czLJFw9822/cfbT9tlP0ogKU3bBkpf9vO21i2aMXw6xlyfxRGXztAjnDXGTV/yW0j/F+yfRPLRrjP3HbbjWzbPuJO8oRZvGZ1LjlwhN+vbr2VxWvWDH39Fb/cPtJ6Rvn/dpT/qwC279jE0iUjdMLO4e87UHY/auT8UfcBd2xm2Sh9P2Ifj3zbLBp1/ZtYNsLPtmT2bXca7X456u/l236879+vht9bmiBL1x3Ihpf+P8Xyp5aXG3od9vCfFMsG+MH37lo0/07njXZHHcV1J4w+/BrFvU65oGj+9//rg4rmn/ekdxfLPvZNLy+WDXDZ//h/5v0SguO24W5LOe+LdyuW//Tjn1kse9QhxqhyxP98R3bLpnLZa/crlw1M/eDKovmL7z7rq3fO29RBw++8j+q/fOgjxbJP+/UfFcvuyooVB7Bx4+8Vy19y0/DDx1HtWDfaoHJUi24bfgBzRyz9xY3Fsn/5uEOKZQPc+ePfLpp/w1OPKpq/bU25/08O/O5txbK/ef7/LJbdlSUHHshd/+AVxfLv+9c/L5Y9tX74P5LdEYtuLXffAUYewowil5X9dT82l/u/BCBXjDYUnyTffcm6ovlXnfaqff5+5VO0JEmSJEmSKueAR5IkSZIkqXIOeCRJkiRJkirngEeSJEmSJKlyDngkSZIkSZIq54BHkiRJkiSpcg54JEmSJEmSKueAR5IkSZIkqXIOeCRJkiRJkirXyoAnIv4sIl4x7eM3RsRpMfCWiLgsIi6NiOc1n39MRHxu2vXfERGntLEWSf1n50jqmr0jqUt2jqQ7YklLOe8GPgW8LSIWAc8HHgI8GzgOOBa4E/DNiDj3jmwgIk4FTgVYsvaAFpYsqWLFOwd2753DDm2rLiVVqtN9neXL181/xZJq1mnnLD5g3fxXLGnsWjmCJzOvBK6LiAcATwIuyszrgEcCH8nMqcz8JXAO8OA7uI0zM3NjZm5cvGp1G8uWVKkuOqfZzu29s/6gxW0sXVKlut7XWbbMfR1pIev896s1a9pauqQxavNP0n8PnAIcDLynuSxmuO4Odh8urWhxHZIWBjtHUtfsHUldsnMkjaTNkyx/GngKgwnyF5vLzgWeFxGLI2I98GjgPOAq4KiIWB4Ra4HHt7gOSQuDnSOpa/aOpC7ZOZJG0toRPJm5LSLOBm7MzKnm4k8DxwPfAhJ4TWb+AiAiPgZcAnwfuKitdUhaGOwcSV2zdyR1yc6RNKrWBjzNyb8eBjx312WZmcCrm3+7yczXAK9pa/uSFhY7R1LX7B1JXbJzJI2qrZdJPwr4AXBWZn6/jUxJmomdI6lr9o6kLtk5ku6IVo7gyczLgcPbyJKkudg5krpm70jqkp0j6Y5o8yTLkiRJkiRJGgMHPJIkSZIkSZVzwCNJkiRJklS51l5Fq0uLdsCKa7NY/g3HTs19pTvoh5ccWiwb4ND7Xl00/9qrDy6WfcjBNxTLBlh03FFF81ftf1vR/Aee/7xi2Uu2lHs89cX3v7uOpz36xGL5Nx5/l2LZK6/eXiwb4Lr7LS+af/C/3VIs+8dP2K9YNsCv/cV/FM3/4QvK3W8Atm3YWiz7bU98WrHsX/7kQ8WyO3PLZhZ/+cJi8XH0kcWyc1EUywaYWll293XJrZuLZd9Y7mYH4KCbby6av+ngsn8bvvUe5fbB73RmwVcNzy3lsjuy4qdbuM8fXV4sP+9212LZm+62qlg2wNKblxXNX/Hjm4pl//zR64plA9zljG8Uzb/htx9WNP/ax5Xbz7nP7327WDbAVTNc7hE8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZUrPuCJiD+NiFc1778hIp6wj+s8JiI+V3otkvrPzpHUJTtHUtfsHUkzWdLlxjLzT7rcnqSFzc6R1CU7R1LX7B1J0xU5giciXhcR342IfwXuM+3y90XESc37T4mIKyLiq8CzS6xD0sJg50jqkp0jqWv2jqRhtH4ET0Q8CHg+8IAm/0Lggj2uswJ4F/A44AfAR4fIPRU4FWDpmgPaXbSkapXqnObrbu+dFUv2b2/RkqrVWeewqr1FS6paF79frYjV7S5a0liUOILnUcCnM3NzZt4MfGYf1zkS+FFmfj8zE/jQXKGZeWZmbszMjUtWWkCSblekc2D33lm2eGWLS5ZUsU46ZynLW1yypMoV//1qWaxoecmSxqHUSZazpetI0jDsHEldsnMkdc3ekTSnEgOec4ETI2JlROwHPHMf17kCuEdEHNF8/FsF1iFpYbBzJHXJzpHUNXtH0lBaPwdPZl4YER8FLgauAr6yj+vc1jzn858j4lrgq8DRba9FUv/ZOZK6ZOdI6pq9I2lYRV4mPTPfCLxxH5efMu39LzB4rqgkzYudI6lLdo6krtk7koZR6hw8kiRJkiRJ6ogDHkmSJEmSpMo54JEkSZIkSaqcAx5JkiRJkqTKOeCRJEmSJEmqXJFX0Spt51LYcnAUy7/3+28rlv2j31hdLBtg8z/epWj++qunimX/jxf+Q7FsgFff+eVF849cf2XR/DPu/o/Fsh93wWuKZffF1kMX84M/279Y/oZ3lOsdMstlA+sv3lk0f9vaZcWyD/vn64tlA2x5+oOL5t/tS1uK5sdUufvOd/7rQcWyb/uTKndvdnPA/bbznE9eXSz/U/cvdxst/W7lfz9cuaJY9BF/cF6xbICthTvnrv/j34vml3TfC8rd5y85uVh0Z+519K18/ot7vfp6a5586AOKZa+6onDnZNn9nKkot/67fPcHxbIBlhxc9nfPA97/b2Xz31duP+dNV5Zd+5fuvu/LK/8fWJIkSZIkSQ54JEmSJEmSKueAR5IkSZIkqXIOeCRJkiRJkirngEeSJEmSJKlyDngkSZIkSZIq54BHkiRJkiSpcg54JEmSJEmSKjf2AU9EnBIRh4x7HZIWBjtHUtfsHUldsnOkhWvsAx7gFMACktSVU7BzJHXrFOwdSd05BTtHWpBaHfBExIaI+E5EvCsivh0RX4qIlc3njouIf4uISyLi0xFxQEScBGwEPhwRF++6riQNw86R1DV7R1KX7BxJoyhxBM+9gP+ZmfcDbgSe01z+AeAPMvMY4FLg9Zn5CeB84OTMPC4zt8wUGhGnRsT5EXH+1KZNBZYtqVJFOgf26J2b7R1Jtyu+r3PrDdvLfgeSalK8c665bqrsdyCpEyUGPD/KzIub9y8ANkTEWmBdZp7TXP5+4NGjhGbmmZm5MTM3Ll69ur3VSqpdkc6BPXpnf3tH0u2K7+usOWBpe6uVVLvinbP+oMXtrVbS2JQY8Gyd9v4UsKTANiRpFztHUtfsHUldsnMkDaWTkyxn5k3ADRHxqOaiFwC7ps23APt1sQ5JC4OdI6lr9o6kLtk5kvaly+nvbwN/GxGrgB8CL2ouf19z+Rbg+LnOiSFJQ7JzJHXN3pHUJTtH0m5aHfBk5pXA0dM+/qtp718MPGwfX/NJ4JNtrkPSwmDnSOqavSOpS3aOpFF08hQtSZIkSZIkleOAR5IkSZIkqXIOeCRJkiRJkirngEeSJEmSJKlyDngkSZIkSZIq1+XLpLcml+9kx703F8v/8fY1xbJ3rJ4qlg2w+ZCyM7ubH7WtWPbJHzi9WDbAzsdl0fyrzr9n0fyn/69XF8ve/khfPXMuy3+8g3u96ppi+dc84e7FsrftH8WyB/lF41n7o53Fsq87+sBi2QCHnHlx0fz/84rjiuav+mW53rzva35YLPuGa8v9X9WVFYu2c+TynxXLzx13LpZdu6mpgvtqO8vuB1KuLpv8wusv6IgVNxTLXr5oR7Hsrvx4+ypO//nGYvmxuFg0WfIx24FYXO7GySxbCt8/7fCi+fd43dVF80v6y58+tfAW3rXPSz2CR5IkSZIkqXIOeCRJkiRJkirngEeSJEmSJKlyDngkSZIkSZIq54BHkiRJkiSpcg54JEmSJEmSKueAR5IkSZIkqXIOeCRJkiRJkirngEeSJEmSJKlyYx/wRMTpEbFq3OuQtDDYOZK6Zu9I6pKdIy1cYx/wAKcDFpCkrpyOnSOpW6dj70jqzunYOdKCNOeAJyJeGBGXRMS3IuKDzWV3j4izmsvPiojDmsvfFxEnTfvaW5u3j4mIL0fEJyLiioj4cAycBhwCnB0RZ5f5FiXVxM6R1DV7R1KX7BxJpcw64ImI+wGvAx6XmccCr2g+9Q7gA5l5DPBh4O1DbOsBDKbJRwGHA4/IzLcDPwMem5mPnWMtp0bE+RFx/s5bNg2xOUm1maTOadZze+9s27ll5O9H0uSbpN6Z3jk3XTd1h74fSZNtUjtnyw1b79D3I2myzHUEz+OAT2TmtQCZeX1z+fHA/2re/yDwyCG2dV5m/iQzdwIXAxtGWWhmnpmZGzNz46L9Vo/ypZLqMTGd02z/9t5ZtmjlqF8uqQ4T0zvTO2ftQYtH+VJJ9ZjIzll5wPJRvlTShJprwBNADpGz6zo7dmVGRADLpl1n+lh4Clgy5BolLRx2jqSu2TuSumTnSCpmrgHPWcBvRsRBABFxYHP514HnN++fDHy1ef9K4EHN+78OLB1iDbcA+w25Xkn9ZudI6pq9I6lLdo6kYmYd8GTmt4E3AudExLeA/9586jTgRRFxCfACfvXc0XcBJ0TEecBDgWFOlnMm8HlPAibJzpHUNXtHUpfsHEklzXkYX2a+H3j/HpddyeD5o3te95fAw6Zd9Nrm8i8DX552vd+f9v4ZwBkjrVpSb9k5krpm70jqkp0jqZQ5XyZdkiRJkiRJk80BjyRJkiRJUuUc8EiSJEmSJFXOAY8kSZIkSVLlHPBIkiRJkiRVbs5X0ZpES28I7vrRZcXyrz26WDQvePRXy4UDn/joCUXz/+hBny2W/TcHPKZYNsC6168smv/D/xJF829cUm79d/uHpcWyAX5UNL0bhx55A2/87KeL5b/2vuUeu7GsXF8CZGbR/EXrDyqWvfbHPyuWDfCD9x9VNP+I3z6/aD65s1j0iy//XrHs7504zKsIT7b9Ah69olz+G8tFa4xWX/bzovk7iqaXdfjyXxbLXh7bi2V35c5LbuH/vtOXi+X/Ho8plh2LFxfLBsidZfdzYnG5Yy5ye9m13+Mzhf+/LbyPWdLT73RJ0fyPznC5R/BIkiRJkiRVzgGPJEmSJElS5RzwSJIkSZIkVc4BjyRJkiRJUuUc8EiSJEmSJFXOAY8kSZIkSVLlHPBIkiRJkiRVzgGPJEmSJElS5SZiwBMRX2/eboiI/2vc65HUb3aOpC7ZOZK6Zu9IC9NEDHgy8+HNuxsAC0hSUXaOpC7ZOZK6Zu9IC9NEDHgi4tbm3b8EHhURF0fEK8e5Jkn9ZedI6pKdI6lr9o60MC0Z9wL28IfAqzLzGeNeiKQFwc6R1CU7R1LX7B1pAZmII3iGERGnRsT5EXH+jq2bxr0cSQvA9N654fqd416OpJ6b3jnXXDc17uVI6rnpnXO9+zlSL1Qz4MnMMzNzY2ZuXLJ89biXI2kBmN47BxxYTV1KqtT0zll/0OJxL0dSz03vnAPdz5F6YdIeybcA+417EZIWDDtHUpfsHElds3ekBWTSBjyXADsi4lueBExSB+wcSV2ycyR1zd6RFpCJOMlyZq5p3m4HHj/m5UjqOTtHUpfsHElds3ekhWnSjuCRJEmSJEnSiBzwSJIkSZIkVc4BjyRJkiRJUuUc8EiSJEmSJFXOAY8kSZIkSVLlHPBIkiRJkiRVLjJz3GsYWURcA1w1wpfcCbi20HJqz3ft/cyftLXfPTPXl1pMFyasdybt5zsp2bXn17z20vl2ztwm6fZfSPk1r710/kJau53Tvkn6+S6k/JrXXjp/0ta+z96pcsAzqog4PzM3mt9tdun8mtdeOr/mtfeFP9/us2vPr3ntpfPtnLnVfPvXnF/z2kvnu/Z+8+fbz/ya1146v5a1+xQtSZIkSZKkyjngkSRJkiRJqtxCGfCcaf5Yskvn17z20vk1r70v/Pl2n117fs1rL51v58yt5tu/5vya114637X3mz/ffubXvPbS+VWsfUGcg0fdiIhbM3PNtI9PATZm5u+3kP1l4FWZef4el/8+cDpwBLA+M0ue+ErSBBlT53wY2AhsB84Dficzt893e5Im35g6590MOieA7wGnZOat892epDqMo3emff4M4EXTt6/Jt1CO4FF/fQ14AqOd9V+S7qgPA0cC9wdWAi8d73Ik9dwrM/PYzDwG+D/AvH+pk6S5RMRGYN2416HROeBRJyJifUR8MiK+2fx7RHP5QyLi6xFxUfP2Ps3lKyPiHyLikoj4KINfpPaSmRdl5pXdfSeSalCwc/53NhgcwfNrnX1TkiZWwc65ubl+NNfx0HtJQLneiYjFwFuA13T2zag1S8a9APXKyoi4eNrHBwKfad5/G/DWzPxqRBwGfBG4L3AF8OjM3BERTwD+HHgO8DJgc2YeExHHABd29U1IqsbYOicilgIvAF7R5jckaaKNpXMi4r3A04DLgf/S8vckabKNo3d+H/hMZv58MFtWTRzwqE1bMvO4XR/seo5o8+ETgKOmlcT+EbEfsBZ4f0Tci8FfpZY2n3808HaAzLwkIi4pvnpJtRln5/wNcG5mfqWF70NSHcbSOZn5ouYv6mcAzwPe29Y3JGniddo7EXEI8FzgMW1/I+qGAx51ZRFwfGZumX5hc/KuszPzxIjYAHx52qc9DFnSHVWscyLi9cB64HfaWaqkHii6n5OZU81TKl6NAx5JAyV65wHAPYEfNIOjVRHxg8y8Z2urVlGeg0dd+RLTTgwYEcc1764Fftq8f8q0658LnNxc92jgmOIrlNQnRTonIl4KPBn4rczc2eqKJdWs9c6JgXvueh94JoOnXkgSFOidzPznzDw4Mzdk5gYGT+lyuFMRBzzqymnAxuakXpcDv9tc/mbgLyLia8Diadd/J7CmOXTwNQxOZrqXiDgtIn7C4ESnl0TE3xf7DiTVpEjnAH8L3AX4RkRcHBF/Umb5kipTonOCwdMsLgUuBe4KvKHUNyCpOqX2dVSxGLwQiCRJkiRJkmrlETySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVLkl416ANJeIuBTImT6fmcd0uBxJC4C9I6lLdo6kLtk5/eWARzV4RvP295q3H2zengxs7n45khYAe0dSl+wcSV2yc3oqMmcc3EkTJSK+lpmPmOsySWqLvSOpS3aOpC7ZOf3jOXhUk9UR8chdH0TEw4HVY1yPpP6zdyR1yc6R1CU7p2d8ipZq8hLgPRGxtvn4RuDF41uOpAXA3pHUJTtHUpfsnJ7xKVqqTkTsz+C+e9O41yJpYbB3JHXJzpHUJTunPxzwqBoRsRx4DrCBaUefZeYbxrUmSf1m70jqkp0jqUt2Tv/4FC3V5J+Am4ALgK1jXoukhcHekdQlO0dSl+ycnun1ETwREcCngddm5nfGvR7NT0RclplHj3sd0mzsnX6xdzTp7Jx+sXM06eycfrFz+qfvr6L1JGAj8NJxL0St+HpE3H/ci5DmYO/0i72jSWfn9Iudo0ln5/SLndMzfT+C52PAe4C3A0dl5o4xL0nzEBGXA/cEfsTgEMIAMjOPGevCpGnsnX6xdzTp7Jx+sXM06eycfrFz+qe35+CJiDsB98vML0TEvwInAh8f87I0P08d9wKk2dg7vWTvaGLZOb1k52hi2Tm9ZOf0TJ+fovVC4CPN++8FXjLGtagFmXlVZl4FbAFy2j91KCJOjIg1417HhLJ3esbeGT87Z1Z2Ts/YOeNn58zKzukZO2cytNk7fR7wvIhB8ZCZ3wTuGhF3G++SNB8R8ayI+D6DQwjPAa4EPj/WRS0wEXEE8DHgP417LRPK3ukZe2e87Jw52Tk9Y+eMl50zJzunZ+yc8Wu7d3o54ImIdcA7MvOn0y5+FXCn8axILfkz4GHA9zLzHsDjga+Nd0kLzouBNzVvNY2901v2znjZOTOwc3rLzhkvO2cGdk5v2Tnj12rv9HLAk5k3Apftcdm/AKvGsiC1ZXtmXgcsiohFmXk2cNyY17RgRMRi4LkMCuimiDh2zEuaKPZOb9k7Y2LnzM7O6S07Z0zsnNnZOb1l54xRid7p5YCnccaQl6keNzbPTTwX+HBEvA3wzP3deRrw9cy8hcGrJ/jymHuzd/rH3hkfO2dudk7/2DnjY+fMzc7pHztnvFrvnd69THpEHA88HDgdeOu0T+0PnJiZTuMrFRGrGZwAbBFwMrAW+HAzdVZhEfGPwF9n5lciYgXwbeC+mbltvCsbP3unv+yd8bFzZmbn9JedMz52zszsnP6yc8arRO/08QieZcAaBi8Bv9+0fzcDJ41xXWpJZu4AvsHgJGA3j3c1C0PzvOt1mfkVgMy8DfgE8LhxrmuC2Ds9Z+90y86Zk53Tc3ZOt+ycOdk5PWfndK9U7/TuCB64/blsH81MC6dHIuIC4FHAAcC/AecDmzPz5LEuTMLe6St7R5PKzuknO0eTys7pJzunf5aMewElZOZURBw47nWodZGZmyPiJcAZmfnmiLho3Ivqu4h44Gyfz8wLu1rLJLN3esve6ZidMxw7p7fsnI7ZOcOxc3rLzhmDkr3TywFP46KI+AzwcWDTrgsz81PjW5LmKZrnAJ8MvKS5rM/34Unx183bFcBG4FtAAMcA/w48ckzrmkT2Tv/YO92zc4Zn5/SPndM9O2d4dk7/2DnjUax3+vzDOxC4jt2fw5aABVSv04HXAp/OzG9HxOHA2eNd0mgi4lDg7kx77GXmueNb0dwy87EAEfEPwKmZeWnz8dHAq8a5tglk7/TP6VTcO3ZO79k5/XM6dk6n7JyR2Dn9czoVdw7YO3vq5Tl4pEkUEW8CngdcDkw1F2dmPqul/A2ZeeUelz04M7/ZUv7FmXncXJdJmgx2jqQule6cZhvFesfOkerjvs4+Mvs64GleZuwlwP0YHPoEQGa+eGyL0rxExNkM/kqwm8ys4hUOIuK7wDGZubVQ/oXAMzPzp83HJwDvyMz7t5T/EQaH436Iwc/hPwFrMvO32sjvA3unf2ruHTun/+yc/rFz5txGsd6xc+Zm5/RPzZ0D7uvsS5+fovVB4ArgycAbGDyv8DtjXZHma/rhaiuA5wA7xrSWO+KHwFKg1I7P7wD/GBHPBB4I/DnwtBbzXwS8DHhF8/G5wDtbzO8De6d/au4dO6f/7Jz+sXNmV7J37Jy52Tn9U3PngPs6e+nzETwXZeYDIuKSzDwmIpYCX6xlGqnhRMQ5mXnCuNcxm4g4g8FE9lDgWOAsppVQZp7W4raOB/4OuA14emZe01a25mbvLAyT3jt2zsJh5ywMds5e27N3xsTOWRgmvXPAfZ3Z9PkInu3N2xubkxX9AtgwvuUMLyLeDPw3YAvwBQZ32tMz80PzyKz+JSD3eGnGRcCDgIPHtJxRnN+8vQD4TNvhEfFZdj+0chVwE/DuiKDF56A+AvhT9j6J2eFt5PdElb1j58ys0t6xcxYOO2f33Op7x87Zty56x84Zip2ze66dMz7u68yU2eMjeF4KfBK4P/A+YA3w/2bm341zXcPYdWKliDgR+A3glcDZmXnsPDJ3nQ19ny/FlpkT/xKQEfEjBg+0YHDo4I+AN2TmV8e6sCFFxGrgtsycaj5eDCzPzM3zzJ11wp6Z58wnf9p2rmBwX7yAX53EjMy8ro38Pqi1d+ycmdXcO3ZO/9k5e+VW3zt2zozZxXvHzpmbnbNXrp0zZu7r7K3PR/CclZk3MHge2+EAEXGP8S5paEubt08DPpKZ10fEvAKzBy8BmZm1/PxmchbwBODW5uOVwJeAh88ndFfBNPfvn2fmbc3HK4G7zCd7Dzdl5udbzOujWnvHzplB5b1j5/SfnTNNH3rHztm3jnrHzpmbnTONnTMR3NfZQ58HPJ9kcCKk6T7B4LCzSffZZpq3BXh5RKxn8Jy/Nhy5q3wAMvOyiDiupWwiYjmDk3NtYPfDzN7QQvZSBiehenRz0ZeBv8vM7TN+0WRZkZm7yofMvDUiVrWY/3F2L7Op5rIHt5R/dkS8BfgUuz/HdeIPP+1Qrb1j58ycX3Pv2Dn9Z+fsW7HesXNmVbpzoGzv2Dlzs3P2rdp9nco7B9zX2UvvBjwRcSSDl+5bGxHPnvap/Zn2cn6TLDP/MCLeBNycmVMRsQn49ZbivxMRf8/uL8XW5tnv/4nB8xMvoP2zmb+TwQT+b5qPX9Bc9tKWt1PKpoh44K4HbEQ8iMF/NG1Zkpnbdn2QmdsiYlmL+Q9t3m6cdlkCC/7EerX3jp0zq5p7x87pKTtnTiV7x86ZWenOgbK9Y+fMwM6ZU837OjV3Drivs5feDXiA+wDPANYBz5x2+S3Afx7Hgu6gQ4EnRsT00vxAC7mlXwLy1zLzKS3mTffgPZ4r+/9FxLcKbauE04GPR8TPmo/vCjyvxfxrIuJZmfkZgIj4deDatsJ3HYaqfepD79g5+1Zz75yOndNXds7sSvaOnTOz0ynbOVCwd+ycWdk5s6t5X6fmzgH3dfbS55MsH5+Z3xj3Ou6IiHg98BjgKOB/A08FvpqZJ41zXcOIiDOBM6Yfpthi9oXAczPzP5qPDwc+kZmznsF+kjSHQd6HwYnMrmjz8MeIOAL4MHBIk/9j4IWZ+YOW8u8C/DlwSGY+NSKOAo7PzHe3kd8HtfaOnTNrftW9Y+f0m53TPTtndiU7p8kv1jt2ztzsnPHw96vZua+zR2aPBzxFXg6vCxFxKYP1XpSZxzY/+L/PzGfO8aVzZc74w87MY+5o9h7buRy4J4MzsG9l8EDINvIj4vHAe4EfNrl3B16UmWfP+oUTpDnp2lFMO5w1M9v668Gubaxh8Ni+peXczzO4/V/X3C+XMLiP3r/N7dSs1t6xc2bNr7p37Jx+s3P2mVu0d+yc2XXROc12Wu8dO2duds4+c6ve16m9c8B9nT318SlauzwpM18Tg5fD+wnwXOBsBs+NnHRbMnNnROyIiP2Bq2nOVD8Pz2hhXcN4aqngzDwrIu7F7hPaEs9/L2Kmvx7Q3uGhRMTTGTxHekU0rw6QLZ34EbhTZn4sIl7b5O6IiKm5vmiBqbV37JwZ1Nw7ds6CYOfsrovesXNm0EXnNNsp1Tt2ztzsnN1Vv69Tc+eA+zr70ucBT5GXw+vI+RGxDngXg5Np3QqcN5/AzLxq1/vN1HrXmb/Py8yr55O953Yi4pHAvTLzvTE4S/2atvIZnKV/A4P77rERUeQvQ4WcxK/+evCiXX89aCs8Iv4WWAU8tsk9iXneb/awKSIOovlLRUQ8jMEJ3/QrtfaOnTO7WnvHzuk/O2eaLnrHzplV0c6B4r1j58zNzpmmR/s6tXYOuK+zlz4/Resvgd9gcAjhQxicFOxzmfnQWb5s4kTEBmD/zLykpbzfBN7C4CXwAngU8OrM/ERL+a9ncBbw+2TmvSPiEODjmfmIFrI/CBwBXMzgJepgcHjiafPNnraNh7P3SxC2UnARcV5mPiQiLmBQErcAl2Xm/VrKvyQzj5n2dg3wqcx8Ukv5DwTOAI4GLgPWAye1dd/sgz70jp2zV37R3rFzZs23c+Zg58yYWax3au+cZhtFeqd05zTbKNY7ds7c7JwZM6vd16m5c5ps93X20NsjeHLvl8PbTLsvh1dMRHwA+Arwlcy8ouX41zE4W/rVzbbWA/8KtFJAwInAA4ALATLzZxGxX0vZG4GjstBUcqaCo71D/Ir89WCaXS8JuLkp/uuAe7QVnpkXRsQJ/OoQzu9myydPrF2tvWPnzKpY79g5s7Nz5mbnzKhk71TbOVC8d0p3DhTsHTtnbnbOjGre16m5c8B9nb30csATEasYHMI2/SXeDuJXd6pJ9z7gkcAZMTiT+cXAuZn5thayF+1xyOB1wKIWcnfZlpkZEbsOM1vdYvZlwMHAz1vMnK5owWXmy5t3/zYivkDLfz0APtcU3JsZFBy0dIjiHo+pbzeXHRYRU5n50za2UbvKe+d92DkzKdk7ds4M7Jy52TmzKtk7NXcOFOydDjoHCvWOnTM3O2dWNe/rVNs54L7OPnML3dZjFYOXSrsCOCYzNzWXfQn4o8w8f6yLG1JELGbwPM7HAr/L4ORgR7aQ+xbgGOAjzUXPAy7NzNfMN7vJfxVwL+CJwF8AL2bwHN23zyPzswwmvfsBxzGYyt5+8q/MfNY8ljx9Ox8HTsvMIgUXEQGcDByemW+IiMOAgzOzlSlzRKwEXsbgsNBk8JeKd2bmbS1kV/+YKq3228jO2Su3eO/YObNmV/146kLtt1Gpzmmyi/VOzZ3TbKdY75TunGYbRXqn9sdTF2q/jWrtnCbf369mzndfZ8/cPg54ACLir4DLM/M9zQ/6nzLzAeNe1zAi4ixgNfANBneir2aLJ+qKiGczmGIHg+n1p9vKbvKfCDypyf9iZv7LPPNOmO3zmXnOfPKnbedsyhbcO4GdwOMy874RcQDwpcx88BxfOmz+xxg873TXKxn8FrAuM3+zpfxqH1NdqfU2snP2mVm8d+ycOfOrfDx1qdbbqHTnNNso1ju1dk6znWK9U7pzmm0U651aH09dqvU2qr1zmnx/v9p3vvs6e8rMXv4DjmTwPEuAP2YwORz7uoZc+1uBc4F/Af4UeBywsqXsNw1z2STmd7D2E/b1r8X8C5u3F0277Fst5u+V1XJ+tY+prv7VehvZOePJt3PmzK/y8dTlv1pvo5Kd0+TXvC9S7b5O6c6ZKa+tbdT6eOryX623Uc2dUzq/5s5p8t3X2eNfm88NnCjZnEArIu7NYNL2wfGuaHiZ+crMfDSDE2pdB7wXuLGl+Cfu47KntpRdOr/o2jPznH39aysf2N4cHrrr+bPrGUyc23JRDF5ajyb/ocDX2gqv+THVlVpvIztnPPl2zuxqfTx1qdbbqHDnQMX7IqXzC/dO6c6Bgr1T6+OpS7XeRpV3Tun8mjsH3NfZSy9PsjzNuxmcBOmSzLxhvmER8dXMfGRE3EJzJ9r1KQYvJ7f/fLfRbOf3GTzP70HAVcB7GBxOOJ/MlwEvBw6PiOknntqPFu6kJfM7WHsnP1fg7cCngTtHxBuBkxhMatvyUOCFEfF/mo8PA74TEZcy+D6OaWEbrT6meqq128jO6We+nTMSO2duds6vcmveF+nDvk7pzoHyvWPnzK26369q7JzS+T3pHHBfZy+9PQcPsOvM1D8HnpOZ/zru9QwrIl7N4DDCCzJzR0uZa4EDGJyY6w+nfeqWzLx+kvNLr71LEXEk8HgG5XZWZn6nxey7z/b5zLyqhW1U+ZjqUo23kZ3TfX5X7Jz+q/E2KtE5TW61+yJ2ztD5RXunxsdT12q8jWrsnNL5fekccF9nr7w+D3gkSZIkSZIWgt6eg0eSJEmSJGmhWBADnog41fzus0vn17z20vk1r70v/Pl2n117fs1rL51v58yt5tu/5vya114637X3mz/ffubXvPbS+bWsfUEMeIDSJV1zvmvvZ37Na+8Lf77dZ9eeX/PaS+fbOXOr+favOb/mtZfOd+395s+3n/k1r710fhVrXygDHkmSJEmSpN6q8iTLy5auzhXL1w19/e3bN7F06eqhr79z2Whzr+1bb2Xp8jXDXfkO3Nyj5MeIP8/t2zaxdNnwt82i20Y78fy2qS0sW7xyuOuuWzpS9tSWTSxeOfzal/5y00j529nKUpYPf/27DL8WgKnNm1i8aoSvWTM1fPbNm1m8/6qhr7/05zH8OoDtOzaxdMnwa79l88+uzcz1I21kwixevTqXrjtw6OtPbdrE4tXD30bLr9029HVHeVwBsGi0Tts2tZlli4e//zBC74y8doCpncPn79zCskUj5C9ZPNJSRr5tJiT7jubvXDr87TPq/7Xb9xu+d0Z9PG2/8XqmNm0ardgmzLJYnitihO85t7I0hv8/K1asGPq623ZsZtmS4e87uWjE/1NGvO+MatT82DpCH++8jWWLhr8tt955+OvC6Pf9ZT8rvK9z8PBrGXk/B9i5bPjrTt16K4vXDLn/DSz/8fC3zaiPp9tyE9tya92ds3R1rli2bujrj7ovOOphBdu2b2JZoV4YOTtG+9Fu27aJZSP8fhVbt4+WP8K+1Pa1IzyogB1bNrFklN+vbtg6Uv6o+2nb1w3/OATYcdsmlqwoc78ZNXvJ5uF/dwPYvmMzS0f4v/aWzT/f5+9XS0ba6oRYsXwdDz3md4vlbzp0xF8+RhDD/55yhyzaXnZgt/qKa4pl//g37losG+CQv/p60fxfnPzwovmccEOx6Lu+sWwV/Mt5r5/3SwiO29J1B3LYy15ZLP+Id/24WHauKddpAOwY7T+wkd14S7nsOw8/tLtDKvwjynS3HbJfseyfnjDaTucofvw3by2W3ZUVsZqHLXlysfw48t7FsncuG21wOqpcXPYA9CXfK9fH//F79ymWDbDhj79RNP9nv112X2fTYeX+P7n36RcUy/63HV8slt2VFcvW8bCjf6dY/tSKgvuahf+vzSVlO2f5f1xdLPvnz7hbsWyAgz/1H0Xzr37mEUXzs+CPdv2FBfdfgX/55p/u8/crn6IlSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlWtlwBMRfxYRr5j28Rsj4rQYeEtEXBYRl0bE85rPPyYiPjft+u+IiFPaWIuk/rNzJHXN3pHUJTtH0h2xpKWcdwOfAt4WEYuA5wMPAZ4NHAccC9wJ+GZEnHtHNhARpwKnAqxYtraFJUuqWPHOgd17Z8naA+a5ZEmV63Zfh1UtLFlSxfz9StLIWhnwZOaVEXFdRDwAuAtwUWZeFxGPBD6SmVPALyPiHODBwM13YBtnAmcC7L/m0Gxj3ZLq1EXnNNu5vXdWHHo3e0dawDrf11l0oJ0jLWCdd85qf7+S+qCtI3gA/h44BTgYeE9zWcxw3R3s/vSwFS2uQ9LCYOdI6pq9I6lLdo6kkbR5kuVPA09hMEH+YnPZucDzImJxRKwHHg2cB1wFHBURyyNiLfD4FtchaWGwcyR1zd6R1CU7R9JIWjuCJzO3RcTZwI3NIYMwKKXjgW8BCbwmM38BEBEfAy4Bvg9c1NY6JC0Mdo6krtk7krpk50gaVWsDnubkXw8DnrvrssxM4NXNv91k5muA17S1fUkLi50jqWv2jqQu2TmSRtXWy6QfBfwAOCszv99GpiTNxM6R1DV7R1KX7BxJd0Rbr6J1OXB4G1mSNBc7R1LX7B1JXbJzJN0RbZ5kWZIkSZIkSWPggEeSJEmSJKlyDngkSZIkSZIq54BHkiRJkiSpcq29THqX7n3EdXzxUx8olv/0Bz2lWDbLl5XLBvKWW4vmx35rimUf9vEfF8sGyKPuXTT/0M/+vGh+vrNc/tu+e1axbID7HlY0vhPLr9nGEX93VbH8Xz7t7sWyV10zVSwbYOnNZfNvfuRdimXv99PtxbIBVl5ethe23qvcbQOw4sc3Fcu+599uLpZ99TXbimV35d7338wXvnh+sfwnH7KjWHZpUTi/ZKNt+ONvFEyHRatWFc0/5M1fL5pf0qv/49Ji2b/3rHJ91pVcEmw9aEWx/Nixs1j2spvKdv7U4rKtM3WXdcWyV/+y3O0OECuWF80vbf+ryu0Hbls3ntvGI3gkSZIkSZIq54BHkiRJkiSpcg54JEmSJEmSKueAR5IkSZIkqXIOeCRJkiRJkirngEeSJEmSJKlyDngkSZIkSZIq54BHkiRJkiSpcsUHPBHxpxHxqub9N0TEE/ZxncdExOdKr0VS/9k5krpk50jqmr0jaSZLutxYZv5Jl9uTtLDZOZK6ZOdI6pq9I2m6IkfwRMTrIuK7EfGvwH2mXf6+iDipef8pEXFFRHwVeHaJdUhaGOwcSV2ycyR1zd6RNIzWBzwR8SDg+cADGBTLg/dxnRXAu4BnAo8CDh4i99SIOD8izr/muql2Fy2pWqU6p/m623tn284t7S1aUrW66hz3dSTt0sXvV9u3bWp30ZLGosQRPI8CPp2ZmzPzZuAz+7jOkcCPMvP7mZnAh+YKzcwzM3NjZm5cf9DilpcsqWJFOgd2751li1a2uGRJFeukc9zXkTRN8d+vli5b3fKSJY1DqZMsZ0vXkaRh2DmSumTnSOqavSNpTiUGPOcCJ0bEyojYj8Fhgnu6ArhHRBzRfPxbBdYhaWGwcyR1yc6R1DV7R9JQWn8Vrcy8MCI+ClwMXAV8ZR/XuS0iTgX+OSKuBb4KHN32WiT1n50jqUt2jqSu2TuShlXkZdIz843AG/dx+SnT3v8Cg+eKStK82DmSumTnSOqavSNpGKXOwSNJkiRJkqSOOOCRJEmSJEmqnAMeSZIkSZKkyjngkSRJkiRJqpwDHkmSJEmSpMo54JEkSZIkSapckZdJL+3WTL52285yG1i2tFz29h3lsoHYf7+i+TtXryyWHb+8rlg2wNVP/LWi+Xf+5BVF8zOzWPYXbz2qWPbAzwvnl7f9gGX89DkbiuUf/DfnFcsuLsr+rWD9pWuLZU9dc02xbIB//tnFRfOffMhxRfOnCmb/4vSHF8ve9uFlxbK7cun167nXh15WLP9eB323WHbpfZFcXLZzYsvWYtk7b7ypWDbA9//0mKL5937j5UXz48ADimW//B+OL5b94xveWiy7Kwcfdh2vescHi+W//d73K5adWfD3Qjo4ImLx4mLRq84v+7vnDc9/WNH8g979b0XzKfj71ZMvu7lYNsA5MzykPIJHkiRJkiSpcg54JEmSJEmSKueAR5IkSZIkqXIOeCRJkiRJkirngEeSJEmSJKlyDngkSZIkSZIq54BHkiRJkiSpcg54JEmSJEmSKjf2AU9EnBIRh4x7HZIWBjtHUtfsHUldsnOkhWvsAx7gFMACktSVU7BzJHXrFOwdSd05BTtHWpBaHfBExIaI+E5EvCsivh0RX4qIlc3njouIf4uISyLi0xFxQEScBGwEPhwRF++6riQNw86R1DV7R1KX7BxJoyhxBM+9gP+ZmfcDbgSe01z+AeAPMvMY4FLg9Zn5CeB84OTMPC4zt8wUGhGnRsT5EXH+jdftLLBsSZUq0jmwe+/s2LKp3HcgqTbF93V23mrnSLpd8c656fqpst+BpE6UGPD8KDMvbt6/ANgQEWuBdZl5TnP5+4FHjxKamWdm5sbM3LjuoEl4ZpmkCVGkc2D33lmycnU7q5XUB8X3dRatsXMk3a5456w9cHF7q5U0NiUmJVunvT8FLCmwDUnaxc6R1DV7R1KX7BxJQ+nkUJjMvAm4ISIe1Vz0AmDXtPkWYL8u1iFpYbBzJHXN3pHUJTtH0r50Of39beBvI2IV8EPgRc3l72su3wIcP9c5MSRpSHaOpK7ZO5K6ZOdI2k2rA57MvBI4etrHfzXt/YuBh+3jaz4JfLLNdUhaGOwcSV2zdyR1yc6RNArPVixJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVLkuXya9NUvZycGLNxfLn/rZL4tlF7coysavWV0se+dNNxfLBtj8lFuK5k+9p+z62TlVLPpey39RLLsvlly9ibu849+L5e986NFzX+kOuuHIVcWyAVZdU+6+CbBkc7n8TXc9olg2wNMfeJei+ZufvaFo/vaV5f5POfjt5R5PV01tKpbdlfsc8As+9/y3FMt/yWseWSyb664vl92FKLgvlVkuG7jP3/ysaP6OG28qmk/B/P960jnFsv/4f1V+n28sptz9c9HqcvsiuW1bsewuLNpvTbHsnYUfs2svv7Fofi5bVjZ/+46i+ePgETySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUubEPeCLi9IhYNe51SFoY7BxJXbN3JHXJzpEWrrEPeIDTAQtIUldOx86R1K3TsXckded07BxpQZpzwBMRL4yISyLiWxHxweayu0fEWc3lZ0XEYc3l74uIk6Z97a3N28dExJcj4hMRcUVEfDgGTgMOAc6OiLPLfIuSamLnSOqavSOpS3aOpFJmHfBExP2A1wGPy8xjgVc0n3oH8IHMPAb4MPD2Ibb1AAbT5KOAw4FHZObbgZ8Bj83Mx86xllMj4vyIOP/663cOsTlJtZmkzmnWc3vvbGfryN+PpMk3Sb3jvo7Uf5PaOTddP3WHvh9Jk2WuI3geB3wiM68FyMzrm8uPB/5X8/4HgUcOsa3zMvMnmbkTuBjYMMpCM/PMzNyYmRsPPHASnlkmqYCJ6Zxm+7f3zlKWj/rlkuowMb3jvo60IExk56w9cPEoXyppQs219xBADpGz6zo7dmVGRADLpl1n+p+/p4AlQ65R0sJh50jqmr0jqUt2jqRi5hrwnAX8ZkQcBBARBzaXfx14fvP+ycBXm/evBB7UvP/rwNIh1nALsN+Q65XUb3aOpK7ZO5K6ZOdIKmbWAU9mfht4I3BORHwL+O/Np04DXhQRlwAv4FfPHX0XcEJEnAc8FNg0xBrOBD7vScAk2TmSumbvSOqSnSOppDkP48vM9wPv3+OyKxk8f3TP6/4SeNi0i17bXP5l4MvTrvf7094/AzhjpFVL6i07R1LX7B1JXbJzJJXiGfwkSZIkSZIq54BHkiRJkiSpcg54JEmSJEmSKueAR5IkSZIkqXIOeCRJkiRJkirngEeSJEmSJKlyc75M+iT63g0H8+SPvbJY/t0fva1Y9rJrNxfLBth+4Mqi+VvXLS2WvfrKW4tlA9z20zVF85dsuFvRfHbuLBZ92sePL5Y98F8K55e3457LufZ/HFEs/y4vuLJY9p1/tKJYNgDLlxWN33nAfsWyl1/0w2LZAHnX9UXz9zv7e0Xzc+vWYtk/+ND9i2Vv/aOvFMvuyuII1i2qcjetfpnjXsEdV/PaC7sty+3D7swolt2VtYuSp6wq1/lvvbXgfn7l9/upbeV+9yx92yzaPlU0f2fB/ZDSjlrx07Fs1yN4JEmSJEmSKueAR5IkSZIkqXIOeCRJkiRJkirngEeSJEmSJKlyDngkSZIkSZIq54BHkiRJkiSpcg54JEmSJEmSKueAR5IkSZIkqXITMeCJiK83bzdExP817vVI6jc7R1KX7BxJXbN3pIVpIgY8mfnw5t0NgAUkqSg7R1KX7BxJXbN3pIVpIgY8EXFr8+5fAo+KiIsj4pXjXJOk/rJzJHXJzpHUNXtHWpiWjHsBe/hD4FWZ+Yw9PxERpwKnAiw+4ICu1yWpn2bsHNi9d5au37/LdUnqp6E7526HLu5yXZL6a6jfrw47dNJ+LZR0R0zEETzDyMwzM3NjZm5cvHr1uJcjaQGY3jtL1q4a93Ik9dz0zjnooGp20SRVanrnrD/IobLUB+49SJIkSZIkVW7SBjy3APuNexGSFgw7R1KX7BxJXbN3pAVk0gY8lwA7IuJbngRMUgfsHEldsnMkdc3ekRaQiTibVmauad5uBx4/5uVI6jk7R1KX7BxJXbN3pIVp0o7gkSRJkiRJ0ogc8EiSJEmSJFXOAY8kSZIkSVLlHPBIkiRJkiRVzgGPJEmSJElS5RzwSJIkSZIkVS4yc9xrGFlEXANcNcKX3Am4ttByas937f3Mn7S13z0z15daTBcmrHcm7ec7Kdm159e89tL5ds7cJun2X0j5Na+9dP5CWrud075J+vkupPya1146f9LWvs/eqXLAM6qIOD8zN5rfbXbp/JrXXjq/5rX3hT/f7rNrz6957aXz7Zy51Xz715xf89pL57v2fvPn28/8mtdeOr+WtfsULUmSJEmSpMo54JEkSZIkSarcQhnwnGn+WLJL59e89tL5Na+9L/z5dp9de37Nay+db+fMrebbv+b8mtdeOt+195s/337m17z20vlVrH1BnINH3YiIWzNzzbSPTwE2Zubvt5D9ZeBVmXn+Hpe/DzgBuKm56JTMvHi+25M0+cbUOQH8N+C5wBTwzsx8+3y3J2nyjalzvgLs13x4Z+C8zPyN+W5PUh3G1DuPB97C4GCQWxn8fvWD+W5P3Vgy7gVILXh1Zn5i3IuQtCCcAtwNODIzd0bEnce8Hkk9lpmP2vV+RHwS+KcxLkfSwvBO4Ncz8zsR8XLgjxns/6gCC+UpWhqziFgfEZ+MiG82/x7RXP6QiPh6RFzUvL1Pc/nKiPiHiLgkIj4KrBzrNyCpKgU752XAGzJzJ0BmXt3JNyRpopXez4mI/YDHAf9Y+nuRVIeCvZPA/s37a4GfFf9m1BqP4FGbVkbExdM+PhD4TPP+24C3ZuZXI+Iw4IvAfYErgEdn5o6IeALw58BzGPwStTkzj4mIY4ALZ9nuGyPiT4CzgD/MzK2tfleSJtU4OucI4HkRcSJwDXBaZn6/7W9M0kQa134OwInAWZl5c3vfjqQKjKN3Xgr874jYAtwMPKztb0rlOOBRm7Zk5nG7Ptj1HNHmwycARw1OXwHA/s1fo9YC74+IezGYFi9tPv9o4O0AmXlJRFwywzZfC/wCWMbgxFR/ALyhpe9H0mQbR+csB27LzI0R8WzgPcCjZriupH4ZR+fs8lvA37fwPUiqyzh655XA0zLz3yPi1cB/ZzD0UQUc8Kgri4DjM3PL9Asj4gzg7Mw8MSI2AF+e9uk5zwCemT9v3t0aEe8FXtXOciVVrkjnAD8BPtm8/2ngvfNfqqQeKNU5RMRBwEMYHMUjSbu03jsRsR44NjP/vbnoo8AXWluxivMcPOrKl4Dbz/YeEcc1764Fftq8f8q0658LnNxc92jgmH2FRsRdm7cB/AZwWXtLllSxIp3D4PwXj2vePwH4XhuLlVS9Up0Dg1ft+1xm3tbSWiX1Q4neuQFYGxH3bj5+IvCd1las4hzwqCunARubk3pdDvxuc/mbgb+IiK8Bi6dd/53AmubQwdcA582Q++GIuBS4FLgTg5cvlqRSnfOXwHOa3vkLPGRZ0kCpzgF4PvCRAmuWVLfWeyczdwD/GfhkRHwLeAHw6oLfg1oWmUMdHSpJkiRJkqQJ5RE8kiRJkiRJlXPAI0mSJEmSVDkHPJIkSZIkSZVzwCNJkiRJklQ5BzySJEmSJEmVc8AjSZIkSZJUOQc8kiRJkiRJlfv/AbrK5WyWgxLgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inp_sentence = \"i was told ten thousand in each pack\"\n",
    "reply(inp_sentence, transformer,  tokenizer_q, tokenizer_a, \"decoder_layer2_block2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3db5f71",
   "metadata": {},
   "source": [
    "## OUTPUTS are not absurd at all, It has LEARNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "298cfd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Attention_Blocks: ['decoder_layer1_block1', 'decoder_layer1_block2', 'decoder_layer2_block1', 'decoder_layer2_block2']\n",
      "Input: i did not sleep well\n",
      "Predicted translation: great bye\n"
     ]
    }
   ],
   "source": [
    "inp_sentence = \"i did not sleep well\"\n",
    "reply(inp_sentence, transformer,  tokenizer_q, tokenizer_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "afd920ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84608</th>\n",
       "      <td>irwin professional journalism time now go back...</td>\n",
       "      <td>i will frank i will something came up okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>you mean with you and that woman chained to ya...</td>\n",
       "      <td>you treat folks special when they company it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125210</th>\n",
       "      <td>why has he bothered you before</td>\n",
       "      <td>is it news to you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24800</th>\n",
       "      <td>i was told ten thousand in each pack</td>\n",
       "      <td>you did not count it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76507</th>\n",
       "      <td>he just wants me to make him cinnamon cookies ...</td>\n",
       "      <td>i think he wants more than your cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81602</th>\n",
       "      <td>no no  you boys are tired</td>\n",
       "      <td>no we are not  jack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "84608   irwin professional journalism time now go back...   \n",
       "6889    you mean with you and that woman chained to ya...   \n",
       "125210                     why has he bothered you before   \n",
       "24800                i was told ten thousand in each pack   \n",
       "76507   he just wants me to make him cinnamon cookies ...   \n",
       "81602                           no no  you boys are tired   \n",
       "\n",
       "                                                   answer  \n",
       "84608          i will frank i will something came up okay  \n",
       "6889    you treat folks special when they company it i...  \n",
       "125210                                  is it news to you  \n",
       "24800                                you did not count it  \n",
       "76507             i think he wants more than your cookies  \n",
       "81602                                 no we are not  jack  "
      ]
     },
     "execution_count": 1075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[400:406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "id": "14569967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23940</th>\n",
       "      <td>south america</td>\n",
       "      <td>we leave miami in an hour soon is we get some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54489</th>\n",
       "      <td>i did not sleep well</td>\n",
       "      <td>do you want to talk about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>really both of you why not</td>\n",
       "      <td>just because</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38692</th>\n",
       "      <td>what department store did they go to</td>\n",
       "      <td>mcintire is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21519</th>\n",
       "      <td>i should not say this but you are pretty gabri...</td>\n",
       "      <td>really i always think myself so ugly no not ug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116659</th>\n",
       "      <td>i do not know</td>\n",
       "      <td>do not know what</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "23940                                       south america   \n",
       "54489                                i did not sleep well   \n",
       "15996                          really both of you why not   \n",
       "38692                what department store did they go to   \n",
       "21519   i should not say this but you are pretty gabri...   \n",
       "116659                                      i do not know   \n",
       "\n",
       "                                                   answer  \n",
       "23940   we leave miami in an hour soon is we get some ...  \n",
       "54489                        do you want to talk about it  \n",
       "15996                                        just because  \n",
       "38692                                         mcintire is  \n",
       "21519   really i always think myself so ugly no not ug...  \n",
       "116659                                   do not know what  "
      ]
     },
     "execution_count": 1070,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.iloc[400:406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "id": "a112d4ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: and the fifty is all gone huh who is the ten for\n",
      "Predicted translation: the chance is impossible\n",
      "Actual: the websters\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: rocky do you have any representation a manager\n",
      "Predicted translation: no  just me\n",
      "Actual: no  just me\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: jeanne let me introduce the king is half brother the dogged lord dunois\n",
      "Predicted translation: then lord have given my lord is name in rome\n",
      "Actual: then lord dunois show me the way to the other side of the river\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: father martineau but i do not see him as a candidate\n",
      "Predicted translation: could there have been anyone else\n",
      "Actual: could there have been anyone else\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: i have not read you your rights\n",
      "Predicted translation: would you mind saying that into your bag\n",
      "Actual: would you mind saying that into your bag\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: is this a good spot\n",
      "Predicted translation: i am not sure look at it  time is it  time to look at it\n",
      "Actual: i am not burying him here\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: my turn what is your favorite song\n",
      "Predicted translation: same time when you were at school\n",
      "Actual: soft and wet by the artist formerly known as prince\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: why do not you dump it mail it off give the fucking fbi a present\n",
      "Predicted translation: why do not you dump the fat lady\n",
      "Actual: why do not you dump the fat lady\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: time to impact\n",
      "Predicted translation: twelve seconds\n",
      "Actual: twelve seconds\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: run for your lives boys  it is that great twogun dogcatcher from kansas\n",
      "Predicted translation: you you seen all the in a to years old man\n",
      "Actual: mcmasters is not it  listen you seen a black stallion with\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "from tqdm import tqdm\n",
    "test_q = train[\"question\"].values[:10]\n",
    "test_a = train[\"answer\"].values[:10]\n",
    "bss = []\n",
    "for i in range(10):\n",
    "    input_test_sentence = test_q[i]\n",
    "    input_sentence, pred_string = reply(input_test_sentence, transformer,  tokenizer_q, tokenizer_a, plot='')\n",
    "    print(\"Actual:\", test_a[i])\n",
    "    reference = [test_a[i].split()] # the original\n",
    "    translation = pred_string.split() # trasilated using model\n",
    "#     bs = bleu.sentence_bleu(reference, translation)\n",
    "#     bss.append(bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c86d5e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: you have been talking to her on the phone for weeks\n",
      "Predicted translation: yes i can imagine that she was there that i am\n",
      "Actual: it was only a few times\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: into our group\n",
      "Predicted translation: leave me at the house\n",
      "Actual: it is really hard to do some kids try for all ofhigh school and never make it\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: we will do that but how are we going to hold him he can change himself into a man he can disappear\n",
      "Predicted translation: where should we be  we still have to move a rock n roll\n",
      "Actual: that is the chance we have to take\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: oh nothing wade how ya doin there\n",
      "Predicted translation: holy cow\n",
      "Actual: stan grossman looked at your proposal says it is pretty sweet\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: i do not understand \n",
      "Predicted translation: i am so scared i did not take you back\n",
      "Actual: did you say rape her\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: you are missing the game for us\n",
      "Predicted translation: you are the one that can not be done\n",
      "Actual: no  i am missing the game for you\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: i took sleeping pills\n",
      "Predicted translation: i should have taken that great life to see your father and him has gone to hell out of there\n",
      "Actual: do you know where you are fran\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: this is all cause of your mom kyle she is such a bitch  agh i mean  she is such a meanie\n",
      "Predicted translation: i know her there would be more to her again  i never met her i am not sure\n",
      "Actual: and she is getting worse\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: the insurance business\n",
      "Predicted translation: jesus christ an old man got that woman in my life\n",
      "Actual: it is a good honest business is not it\n",
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: have you evacuated anyone\n",
      "Predicted translation: or what about us\n",
      "Actual: only that floor\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "from tqdm import tqdm\n",
    "test_q = validation[\"question\"].values[100:110]\n",
    "test_a = validation[\"answer\"].values[100:110]\n",
    "bss = []\n",
    "for i in range(10):\n",
    "    input_test_sentence = test_q[i]\n",
    "    input_sentence, pred_string = reply(input_test_sentence, load_transformer,  tokenizer_q, tokenizer_a, plot='')\n",
    "    print(\"Actual:\", test_a[i])\n",
    "    reference = [test_a[i].split()] # the original\n",
    "    translation = pred_string.split() # trasilated using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5221356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x27e0fd93940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_layers = 2\n",
    "# d_model = 256\n",
    "# dff = 512\n",
    "# num_heads = 8\n",
    "# input_vocab_size = tokenizer_q.vocab_size + 2\n",
    "# target_vocab_size = tokenizer_a.vocab_size + 2\n",
    "# dropout_rate = 0.1\n",
    "\n",
    "# load_transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "#                           input_vocab_size, target_vocab_size, \n",
    "#                           pe_input=input_vocab_size, \n",
    "#                           pe_target=target_vocab_size,\n",
    "#                           rate=dropout_rate)\n",
    "# load_transformer.load_weights('transformer_model/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d2d6845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: i was told ten thousand in each pack\n",
      "Predicted translation: you did not count it\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('i was told ten thousand in each pack', 'you did not count it')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_sentence = \"i was told ten thousand in each pack\"\n",
    "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a, \"decoder_layer2_block2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76541209",
   "metadata": {},
   "source": [
    "* Results are great, better than encoder-decoder with bahadenau attention mechanism\n",
    "* Still we can see the results are not perfect, because the architecture has less parameters plus the dataset is not very big and transformers works close to humans with large data and large trainable parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144f2d50",
   "metadata": {},
   "source": [
    "# On random inputs!\n",
    "### Results are genuine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c357afa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: hi\n",
      "Predicted translation: hi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('hi', 'hi')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_sentence = \"hi\"\n",
    "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8dbf4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: Where have you been\n",
      "Predicted translation: i think you came up with this town again\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Where have you been', 'i think you came up with this town again')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_sentence = \"Where have you been\"\n",
    "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b357781a",
   "metadata": {},
   "source": [
    "#### Making sense haha : ) \"who are you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1d86b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: who are you\n",
      "Predicted translation: i am the guy who is he\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('who are you', 'i am the guy who is he')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_sentence = \"who are you\"\n",
    "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f0fab3",
   "metadata": {},
   "source": [
    "####  Again making sense \"where do you live\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "635f4b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: where do you live\n",
      "Predicted translation: in new york\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('where do you live', 'in new york')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_sentence = \"where do you live\"\n",
    "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88ecdc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: what is your name\n",
      "Predicted translation: my name is sir te i am not the one i am talking about you\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('what is your name',\n",
       " 'my name is sir te i am not the one i am talking about you')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_sentence = \"what is your name\"\n",
    "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5f480ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "Got end token\n",
      "=============\n",
      "Input: why are you angry with me is there anything i did wrong\n",
      "Predicted translation: i did not know you had something to do for me\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('why are you angry with me is there anything i did wrong',\n",
       " 'i did not know you had something to do for me')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_sentence = \"why are you angry with me is there anything i did wrong\"\n",
    "reply(inp_sentence, load_transformer,  tokenizer_q, tokenizer_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57d9937",
   "metadata": {},
   "source": [
    "# Even with this small architecture its working fine, what else it could do If I train it with trainable parameters with more data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
