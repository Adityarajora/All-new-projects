{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f6466e",
   "metadata": {},
   "source": [
    "# Final Data pipeline\n",
    "***\n",
    "Using dataset wthout any normalization and Feature engineering, Light Gradient Boosting Maching algorithm performed\n",
    "really well on the Kaggle test dataset.\n",
    "In the Pipeline using that model only.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4019f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import lightgbm as lgbm\n",
    "import joblib\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "from biosppy.signals import  ecg\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "130a9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(testing=True, test_data=None, training=False, test_data_is_df=True):\n",
    "    \"\"\"\n",
    "    This function train/test LGBM models\n",
    "    parameters:\n",
    "              testing(bool): True/False\n",
    "              test_data(dataframe): pandas dataframe\n",
    "              training(bool)L True/False\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    if (testing) or training:\n",
    "        d = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "        d_ = {0:'A',1:'B',2:'C',3:'D'}\n",
    "        if training:\n",
    "            print(\"\\n<start>Loading dataset....\")\n",
    "            raw = pd.read_csv(\"train.csv\")\n",
    "            print(\"<complete>Loading dataset.\\n\")\n",
    "\n",
    "            Y = raw['event']\n",
    "            X = raw.drop('event',axis=1)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=.2, shuffle=False)\n",
    "            print(f\"X_train.shape:{X_train.shape}\")\n",
    "            print(f\"y_train.shape:{y_train.shape}\")\n",
    "            print(f\"X_test.shape:{X_test.shape}\")\n",
    "            print(f\"y_test.shape:{y_test.shape}\")\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            y_train_num = np.array(list(map(lambda x: d[x], y_train)))\n",
    "            y_test_num =  np.array(list(map(lambda x: d[x], y_test)))\n",
    "\n",
    "            X_train['experiment'] = X_train['experiment'].astype('category')\n",
    "            X_test['experiment'] = X_test['experiment'].astype('category')\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "            train = lgbm.Dataset(X_train, label = y_train_num, categorical_feature=[1])\n",
    "            test = lgbm.Dataset(X_test, label = y_test_num, categorical_feature=[1])\n",
    "\n",
    "   \n",
    "            params = {\n",
    "                      \"objective\" : \"multiclass\", # used for multiclass softmax classifier\n",
    "                      \"metric\" : \"multi_error\",   # Error rate for multiclass classification \n",
    "                      \"boosting\" :'gbdt',         # Using Gardient Boosted Decision Trees\n",
    "                      'num_class':4,              # Number of desired output classes is 4 \n",
    "                      \"num_leaves\" : 30,          # Number of leaves in Tree based algorithms\n",
    "                      \"learning_rate\" : 0.01,     \n",
    "                      \"bagging_fraction\" : 0.9,   # This is randomly select 90% of data without resampling\\\n",
    "                                                  #it will decrease impact of high variance on data\n",
    "                      \"bagging_seed\" : 0,         # Random seeds for bagging\n",
    "                      \"num_threads\" : 4,\n",
    "                      \"colsample_bytree\" : 0.5,   # Subsampling fraction for feature\n",
    "                      'min_data_in_leaf':100,     # Threshold on Data in a leaf\n",
    "                      'min_split_gain':0.00019    # Minmimum gain threshold for splitting the node\n",
    "            }\n",
    "\n",
    "            print('\\n<start>Training Light Gradient Boosting Machine...')\n",
    "            model = lgbm.train(params, \n",
    "                              train_set = train,\n",
    "                              num_boost_round=1000,\n",
    "                              early_stopping_rounds=200,\n",
    "                              verbose_eval=200, \n",
    "                              valid_sets=[train,test]\n",
    "                              )\n",
    "            print('<complete>Training\\n') \n",
    "            \n",
    "            \n",
    "            print(\"\\n<start>Prediction...\")\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            print(\"<complete>Prediction\\n\")\n",
    "\n",
    "\n",
    "            print(\"\\n<start>LOG-LOSS calculation...\")\n",
    "            print(f\"Train log_loss:{log_loss(y_train, y_train_pred)}\")\n",
    "            print(f\"Test log_loss:{log_loss(y_test, y_test_pred)}\")\n",
    "            print(\"<complete>LOG-LOSS calculation\\n\")\n",
    "\n",
    "            conf_mat_val1 = confusion_matrix(np.argmax(y_train_pred, axis=1), y_train_num)\n",
    "            conf_mat_val2 = confusion_matrix(np.argmax(y_test_pred, axis=1), y_test_num)\n",
    "            \n",
    "            \n",
    "            ax = plt.axes()\n",
    "            sns.heatmap(conf_mat_val1, annot=True,fmt=\"d\",cmap='Blues')\n",
    "            ax.set_xlabel('predicted', fontsize=10)\n",
    "            ax.set_ylabel('actual', fontsize=10)\n",
    "            ax.set_title(\"Train confusion matrix\")\n",
    "            ax.set_xticklabels(['A', 'B', 'C', 'D'])\n",
    "            ax.set_yticklabels(['A', 'B', 'C', 'D'],rotation=\"horizontal\")\n",
    "            plt.show()\n",
    "            \n",
    "            ax = plt.axes()\n",
    "            sns.heatmap(conf_mat_val2, annot=True,fmt=\"d\",cmap='Blues')\n",
    "            ax.set_xlabel('predicted', fontsize=10)\n",
    "            ax.set_ylabel('actual', fontsize=10)\n",
    "            ax.set_title(\"Test confusion matrix\")\n",
    "            ax.set_xticklabels(['A', 'B', 'C', 'D'])\n",
    "            ax.set_yticklabels(['A', 'B', 'C', 'D'],rotation=\"horizontal\")\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            print(\"====Dumping model====\")\n",
    "            joblib.dump(model, \"model_final\")\n",
    "                \n",
    "        if testing :\n",
    "            print(\"\\n<start>Testing on provided dataset...\")\n",
    "            model = joblib.load(\"model_final\") if not training else model\n",
    "            cols = [\"id\", 'crew', 'experiment', 'time', 'seat', 'eeg_fp1', 'eeg_f7', 'eeg_f8',\n",
    "           'eeg_t4', 'eeg_t6', 'eeg_t5', 'eeg_t3', 'eeg_fp2', 'eeg_o1', 'eeg_p3',\n",
    "           'eeg_pz', 'eeg_f3', 'eeg_fz', 'eeg_f4', 'eeg_c4', 'eeg_p4', 'eeg_poz',\n",
    "           'eeg_c3', 'eeg_cz', 'eeg_o2', 'ecg', 'r', 'gsr']\n",
    "            \n",
    "            dtypes = [\"int\"]*2 + [\"str\"] + [\"float\"] + [\"int\"] + [\"float\"]*23\n",
    "             \n",
    "            if not test_data_is_df:\n",
    "                if type(test_data) == type(\"s\"):\n",
    "                    col_dtype = list(zip(cols, dtypes)) \n",
    "                    myarray = np.array([test_data.split(\",\")])\n",
    "                    record = np.array(list(map(tuple,myarray)),dtype=col_dtype)\n",
    "                    test_data = pd.DataFrame.from_records(record)  \n",
    "                else:\n",
    "                    return print(\"<Error-3>Something went wrong...Returning!\")\n",
    "                print(\"Test data string being converted into test dataframe!\")      \n",
    "            \n",
    "                \n",
    "            if 'id' in test_data.columns:\n",
    "                test_df = test_data.drop(['id'], axis=1 )\n",
    "            if 'event' in test_data.columns:\n",
    "                test_df = test_data.drop(['event'], axis=1 )\n",
    "            test_df['experiment'] = test_df['experiment'].astype('category')\n",
    "            test_pred = model.predict(test_df)\n",
    "            pred_idx = np.argmax(test_pred, axis=-1)\n",
    "            pred_classes = list(map(lambda x:d_[x], pred_idx))\n",
    "            print(pred_classes[:10])\n",
    "            print(\"<complete>Testing on provided dataset...\\n\")\n",
    "        else:\n",
    "            print(\"No testing?...fine...Returning...!\")\n",
    "          \n",
    "    else:\n",
    "        print(\"<Error-2>Something went wrong...Returning!\")\n",
    "        return \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1beb9dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<start>Testing on provided dataset...\n",
      "Test data string being converted into test dataframe!\n",
      "['A']\n",
      "<complete>Testing on provided dataset...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline(testing=True, test_data=t.loc[range(1000,1010)], training=False)\n",
    "# pipeline(testing=True, test_data=test_str, training=False, test_data_is_df=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc74c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_str = \"0,1,LOFT,0.0,0,17.8995,6.12783,0.994807,-28.2062,-47.695499,-187.080002,-33.183498,-4.22078,8.17816,33.160301000000004,33.8125,21.744699,16.2938,-7.04448,-14.4051,-4.0338400000000005,-0.393799,31.8381,17.0756,-8.13735,-7323.120117,643.1770019999999,594.778992\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa3ff6",
   "metadata": {},
   "source": [
    "##### Load data from here, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c782c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = pd.read_csv('train.csv')\n",
    "# tt = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "434df971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtypes = [\"int64\"]*2 + [\"str\"] + [\"float64\"] + [\"int64\"] + [\"float64\"]*23"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
